{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8517375d",
   "metadata": {},
   "source": [
    "# CHAPTER 5 순환 신경망(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea606d",
   "metadata": {},
   "source": [
    "지금까지 살펴본 신경망은 피드포워드(feed forward)라는 유형의 신경망  \n",
    "피드포워드란 흐름이 단방향인 신경망을 말함  \n",
    "  \n",
    "피드포워드 신경망은 구성이 단순하여 구조를 이해하기 쉽고, 그래서 많은 문제에 응용할 수 있음  \n",
    "하지만 시계열 데이터의 성질(패턴)을 충분히 학습할 수 없다는 단점이 있음  \n",
    "그래서 __순환 신경망(Recurrent Neaural Network, RNN)__이 등장함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e1eb3",
   "metadata": {},
   "source": [
    "## 5.1 확률과 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98feaf",
   "metadata": {},
   "source": [
    "### 5.1.1 word2vec을 확률 관점에서 바라보다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd800cf",
   "metadata": {},
   "source": [
    "<img src='./img/5/cbow_1.png' width=400>  \n",
    "  \n",
    "CBOW 모델의 경우,  \n",
    "$w_1, w_2, \\cdots, w_T$라는 단어열로 표현되는 말뭉치가 있고,  \n",
    "t번째 단어를 '타깃'으로,  \n",
    "그 전후 단어(t-1번째와 t+1번째)를 '맥락'으로 봤을 때  \n",
    "CBOW 모델은 위 그림처럼 맥락 $w_{t-1}$과 $w_{t+1}$로부터 타깃 $w_t$를 추측하는 일을 수행함  \n",
    "  \n",
    "$w_{t-1}$과 $w_{t+1}$가 주어졌을 때 타깃이 $w_t$가 될 확률은 다음과 같다.  \n",
    "  \n",
    "$P(w_t|w_{t-1}, w_{t+1})$  \n",
    "  \n",
    "위 예시는 맥락을 좌우 대칭으로 다뤘음  \n",
    "맥락을 왼쪽 윈도우로만 한정하게 되면 다음과 같다.  \n",
    "  \n",
    "<img src='./img/5/cbow_2.png' width=400>  \n",
    "  \n",
    "$P(w_t|w_{t-2}, w_{t-1})$  \n",
    "  \n",
    "여기에 교차엔트로피 오차 손실함수를 적용하면 다음과 같다.  \n",
    "  \n",
    "$L=-logP(w_t|w_{t-2}, w_{t-1})$  \n",
    "  \n",
    "CBOW 모델의 학습이 수행하는 일은 손실 함수를 최소화하는 가중치 매개변수를 찾는 것임  \n",
    "CBOW 모델을 학습시키는 본래 목적은 맥락으로부터 타깃을 정확하게 추측하는 것이고,  \n",
    "이 목적을 위해 학습을 진행하면, 단어의 의미가 인코딩된 '단어의 분산 표현'을 얻을 수 있음  \n",
    "  \n",
    "여기서, CBOW 모델의 본래 목적인 '맥락으로부터 타깃을 추측하는 것'  \n",
    "즉, 확률 $P(w_t|w_{t-2}, w_{t-1})$는 '언어 모델'에서 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add58c30",
   "metadata": {},
   "source": [
    "### 5.1.2 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e20f4fe",
   "metadata": {},
   "source": [
    "언어 모델(Language Model)을 단어 나열에 확률을 부여함  \n",
    "특정한 단어의 시퀀스에 대해서, 그 시퀀스가 일어날 가능성이 어느 정도인지를 확률로 평가  \n",
    "  \n",
    "언어 모델은 기계번역, 음성인식 등과 새로운 문장을 생성하는 용도로도 이용할 수 있음  \n",
    "확률분포에 따라 다음으로 적합한 단어를 샘플링할 수 있기 때문  \n",
    "  \n",
    "<img src='./img/5/cbow_3.png' width=500>  \n",
    "  \n",
    "$w_1, \\cdots, w_m$이라는 m개 단어로 된 문장이 있을 때, 단어가 $w_1, \\cdots, w_m$순서로 출현할 확률은 $P(w_1, \\cdots, w_m)$으로 나타냄  \n",
    "이 확률은 여러 사건이 동시에 일어날 확률이므로 동시 확률이라고 함  \n",
    "  \n",
    "이 동시 확률은 사후 확률의 총 곱으로 나타낼 수 있음  \n",
    "  \n",
    "$P(w_1, \\cdots, w_m)=P(w_m|w_1, \\cdots, w_{m-1})P(w_{m-1}|w_1, \\cdots, w_{m-2})\\cdots P(w_3|w_2, w_1)P(w_2|w_1)P(w_1)\\\\\n",
    "=\\Pi_{t=1}^mP(w_t|w_1,\\cdots,w_{t-1})$  \n",
    "  \n",
    "이 사후 확률은 타깃 단어보다 왼쪽에 있는 단어를 맥락(조건)으로 했을 때의 확률임  \n",
    "  \n",
    "$P(w_t|w_1,\\cdots, w_{t-1})$을 나타내는 모델을 조건부 언어 모델(conditional Language Model) 또는 '언어 모델'이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146a11a",
   "metadata": {},
   "source": [
    "### 5.1.3 CBOW 모델을 언어 모델로?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de851652",
   "metadata": {},
   "source": [
    "word2vec의 CBOW 모델은 맥락의 크기를 특정 값으로 한정하여 언어모델에 근사하게 나타낼 수 있음  \n",
    "예를 들어 맥락을 왼쪽 2개의 언어로 한정한다면 다음과 같이 쓸 수 있음  \n",
    "  \n",
    "$P(w_1,\\cdots, w_m)=\\Pi_{t=1}^mP(w_t|w_1,\\cdots,w_{t-1})\\approx\\Pi_{t=1}^mP(w_t|w_{t-2},w_{t-1})$  \n",
    "  \n",
    "\\* 마르코프 연쇄(Markov Chain) 또는 마르코프 모델(Markov Model)이란 미래의 상태가 현재 상태에만 의존해 결정되는 것을 말하는 것으로, 이 사상의 확률을 '그 직전' N개의 사건에만 의존할 때, 'N층 마르코프 연쇄'라고 함  \n",
    "위 예시는 직전 2개의 단어에만 의존해 다음 단어가 정해지는 모델이므로 '2층 마르코프 연쇄'라고 할 수 있음  \n",
    "  \n",
    "맥락의 크기를 정함으로써 특정 길이로 '고정'할 수 있음  \n",
    "이렇게 되면 맥락보다 더 왼쪽에 있는 단어의 정보는 무시됨  \n",
    "  \n",
    "예를 들어,  \n",
    "Tom was watching TV in his room. Mary came into the room. Mary said hi to (?)  \n",
    "라는 문제가 있을 때, 문맥(맥락)을 고려하면 '?'는 Tom이 됨.  \n",
    "하지만 맥락을 10으로 한정하게 되면 더 왼쪽에 있는 단어는 무시되기 때문에 정답인 Tom을 기억할 수 없음  \n",
    "  \n",
    "만약 맥락 크기를 더 크게 키운다 하더라도  \n",
    "CBOW(continuous bag-of-wards) 모델은 맥락 안의 단어 순서가 무시되는 bag-of-words 모델이기 때문에 이 문제를 푸는데 적합하지 않음  \n",
    "\\* bag-of-words : '가방 안의 단어', 단어 '순서'는 무시하고 대신 '분포'를 사용함\n",
    "  \n",
    "<img src='./img/5/cbow_4.png' width=500>  \n",
    "  \n",
    "왼쪽 그림과 같이 CBOW 모델은 은닉층에서는 단어 벡터들이 더해지므로 맥락의 단어 순서가 무시됨  \n",
    "  \n",
    "오른쪽 그림처럼 맥락의 단어 벡터를 은닉층에서 연결하는 방식을 사용할 수 있지만,  \n",
    "이 방식을 취하면 맥락의 크기에 비례해 가중치 매개변수도 늘어나는 문제가 있음  \n",
    "(신경 확률론적 언어모델(Neural Probabilistic Language Model)에서 제안한 모델은 이 방식을 취함)  \n",
    "  \n",
    "하지만, RNN은 맥락이 아무리 길더라도 그 맥락의 정보를 기억하는 메커니즘을 갖추고 있음  \n",
    "  \n",
    "< 참고 >  \n",
    "  \n",
    "word2vec은 단어의 분산 표현을 얻을 목적으로 고안된 기법  \n",
    "따라서 보통 이를 언어 모델로 사용하지는 않음  \n",
    "지금은 단지 예시로 보여주기 위해 CBOW 모델을 억지로 언어 모델에 적용한 것!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef699de9",
   "metadata": {},
   "source": [
    "## 5.2 RNN이란"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8398c2",
   "metadata": {},
   "source": [
    "RNN(Recurrent Neural Network, 순환 신경망)의 'Recurrent'는 '몇 번이나 반복해서 일어나는 일'을 뜻함  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58516c",
   "metadata": {},
   "source": [
    "### 5.2.1 순환하는 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb42c8",
   "metadata": {},
   "source": [
    "'순환한다'란 어느 한 지점에서 시작한 것이, 시간을 지나 다시 원래 장소로 돌아오는 것, 그리고 이 과정을 반복하는 것, 즉 '반복해서 되돌아감'을 의미함  \n",
    "  \n",
    "<img src='./img/5/RNN_1.png' width=400>  \n",
    "  \n",
    "RNN은 위 그림처럼 순환하는 경로(닫힌 경로)가 있음(출력이 분기되어 분기된 출력 중 하나는 자기 자신에 입력됨)  \n",
    "순환 경로가 있기에 데이터가 순환되어 과거의 정보를 기억하는 동시에 최신 데이터로 갱신할 수 있음  \n",
    "  \n",
    "RNN은 $x_t$를 입력받는데, 여기서 t는 시각을 뜻함  \n",
    "시계열 데이터$x_0, x_1, \\cdots, x_t, \\cdots$)가 RNN 계층에 입력됨  \n",
    "이 입력에 대응하여 $(h_0, h_1, \\cdots, h_t, \\cdots)$가 출력됨  \n",
    "  \n",
    "문장(단어 순서)를 다루는 경우라면 $x_t$는 각 단어의 분산 표현(단어 벡터)이며, 이 분산 표현이 순서대로 하나씩 RNN 계층에 입력됨  \n",
    "  \n",
    "(오른쪽 그림 : 순환구조를 펼처보기 위해 왼쪽의 계층 그림을 아래에서 위로 흐르도록 수정함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc412ed",
   "metadata": {},
   "source": [
    "### 5.2.2 순환 구조 펼치기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ae209",
   "metadata": {},
   "source": [
    "<img src='./img/5/RNN_2.png' width=500>  \n",
    "  \n",
    "순환구조를 펼치면 위 그림과 같음  \n",
    "  \n",
    "\\* 시계열 데이터는 시간 방향으로 데이터가 나열되므로 인덱스를 가리킬 때는 '시각'이라는 용어를 사용함  \n",
    "ex) '시각 t의 단어', '시각 t의 RNN 계층'처럼 표현하기도 함  \n",
    "  \n",
    "각 시각의 RNN 계층은 그 계층으로의 입력과 1개 전의 RNN 계층으로부터의 출려긍ㄹ 받음  \n",
    "이 두 정보를 이용하여 현 시각의 출력을 계산함  \n",
    "수식은 다음과 같다.  \n",
    "  \n",
    "$h_t=tanh(h_{t-1}W_h+x_tW_x+b)$  \n",
    "  \n",
    "여기서, b는 편향이고, $h_{t-1}$과 $x_t$는 행벡터임  \n",
    "그리고, RNN에는 가중치가 2개 있음  \n",
    "- $W_x$ : 입력 x를 출력 h로 변환하기 위한 가중치\n",
    "- $W_h$ : RNN 출력을 다음 시각의 출력으로 변환하기 위한 가중치  \n",
    "  \n",
    "행렬 곱을 계산하고, 그 합을 tanh 함수를 이용해 변환하여 시각 t의 출력 $h_t$를 계산함  \n",
    "이 $h_t$는 다른 계층을 향해 위쪽으로 출력되는 동시에, 다음 시각의 RNN 계층(자기 자신)을 향해 오른쪽으로도 출력됨  \n",
    "  \n",
    "현재의 출력($h_t)$는 한 시각 이전의 출력($h_{t-1})$에 기초해 계산되므로, RNN 계층을 '상태를 가지는 계층' 혹은 '메모리(기억력)가 있는 계층'이라고 함  \n",
    "  \n",
    "또한 RNN의 출력 $h_t$를 은닉 상태(hidden state) 혹은 은닉 상태 벡터(hidden state vector)라고 함  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6a2fd",
   "metadata": {},
   "source": [
    "### 5.2.3 BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855df41",
   "metadata": {},
   "source": [
    "<img src='./img/5/RNN_3.png' width=500>  \n",
    "  \n",
    "위 그림과 같이 순환 구조를 펼친 후의 RNN에는 (일반적인) 오차역전파법을 적용할 수 있음  \n",
    "여기서의 오차역전파법은 '시간 방향으로 펼친 신경망의 오차역전파법'이란 뜻으로 __BPTT(Backpropagation Through Time)__이라고 함  \n",
    "  \n",
    "하지만 시계열 데이터의 시간 크기가 커지는 것에 비례하여 BPTT가 소비하는 컴퓨팅 자원도 증가하고, 시간 크기가 커지면 역전파 시의 기울기가 불안정해지는 문제가 있음  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa8e2a7",
   "metadata": {},
   "source": [
    "### 5.2.4 Truncated BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b8e3e",
   "metadata": {},
   "source": [
    "<img src='./img/5/Truncated_BPTT_1.png' width=700>  \n",
    "  \n",
    "계층이 길어지면 계산량과 메모리 사용량 뿐만 아니라, 신경망을 하나 통과할 때마다 기울기 값이 조금씩 작아져서 이전 시각 t까지 역전파되기 전에 0이 되어 소멸할 수 있는 문제가 있음  \n",
    "  \n",
    "따라서 큰 시계열 데이터를 취급할 때는 흔히 신경망 연결을 적당한 길이로 끊음  \n",
    "잘라낼 때는 '역전파'의 연결만 끊음 (순전파의 연결은 그대로 유지)  \n",
    "  \n",
    "역전파가 연결되는 일련의 RNN 계층을 '블록'이라고 함  \n",
    "잘라낸 작은 신경망인 각각의 블록 단위로 미래 블록과는 독립적으로 오차역전파법을 수행하며 이러한 기법을 __Truncated BPTT 기법__이라고 함  \n",
    "  \n",
    "지금까지 본 신경망에서 미니배치 학습을 수행할 때는 데이터를 무작위로 선택해 입력했으나,  \n",
    "RNN에서 Truncated BPTT를 수행할 때는 데이터를 '순서대로' 입력해야 함  \n",
    "  \n",
    "ex)  \n",
    "  \n",
    "<img src='./img/5/Truncated_BPTT_2.png' width=400>  \n",
    "  \n",
    "위 그림과 같이 먼저 순전파를 수행하고, 그다음 역전파를 수행함  \n",
    "  \n",
    "<img src='./img/5/Truncated_BPTT_3.png' width=450>  \n",
    "  \n",
    "첫 번째 블록과 마찬가지로 순전파 수행 후 역전파를 수행  \n",
    "여기서부터는 앞 블록의 마지막 은닉 상태($h_9$)가 필요  \n",
    "이를 통해 순전파를 계속 연결함  \n",
    "  \n",
    "위 예시처럼 RNN 학습에서는 데이터를 순서대로 입력하며, 은닉 상태를 계승하면서 학습을 수행함  \n",
    "또한 순전파의 연결을 유지하면서 블록 단위로 오차역전파법을 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321443a",
   "metadata": {},
   "source": [
    "### 5.2.5 Truncated BPTT의 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f1967",
   "metadata": {},
   "source": [
    "<img src='./img/5/Truncated_BPTT_4.png' width=700>  \n",
    "  \n",
    "데이터를 순서대로 입력해야 하므로,  \n",
    "각 미니배치의 시작 위치는 데이터를 주는 시작 위치로 옮겨줘야 함  \n",
    "  \n",
    "또한 데이터를 순서대로 입력하다가 끝에 도달하면 다시 처음부터 입력하도록 해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9d669",
   "metadata": {},
   "source": [
    "## 5.3 RNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3b867",
   "metadata": {},
   "source": [
    "<img src='./img/5/RNN_4.png' width=500>  \n",
    "  \n",
    "여기서 다룰 신경망은 길이가 T인 시계열 데이터를 받음  \n",
    "그리고 각 시각의 은닉 상태 T개를 출력함  \n",
    "  \n",
    "<img src='./img/5/RNN_5.png' width=500>  \n",
    "  \n",
    "입력과 출력을 각각 하나로 묶으면 옆으로 늘어선 일련의 계층을 하나의 계층으로 간주할 수 있음  \n",
    "즉, $(x_0, x_1, \\cdots, x_{T-1})$을 묶은 xs를 입력하면 $(h_0, h_1, \\cdots, h_{T-1})$을 묶은 hs를 출력하는 단일 계층으로 볼 수 있음  \n",
    "  \n",
    "(여기서부터는 한 단계의 작업을 수행하는 계층을 'RNN 계층',  \n",
    "T개 단계분의 작업을 한꺼번에 처리하는 계층을 'Time RNN 계층'으로 표현하겠음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368525df",
   "metadata": {},
   "source": [
    "### 5.3.1 RNN 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d5804",
   "metadata": {},
   "source": [
    "RNN 처리를 한 단계만 수행하는 RNN 클래스 구현  \n",
    "  \n",
    "__순전파__  \n",
    "  \n",
    "$h_t=tanh(h_{t-1}W_h+x_tW_x+b)$  \n",
    "  \n",
    "형상확인은 다음과 같음  \n",
    "  \n",
    "<img src='./img/5/RNN_6.png' width=500>  \n",
    "  \n",
    "($x_t$와 $h_t$에는 각 샘플 데이터를 행 방향에 저장)  \n",
    "- N : 미니배치 크기  \n",
    "- D : 입력 벡터의 차원 수 \n",
    "- H : 은닉 상태 벡터의 차원 수  \n",
    "  \n",
    "<img src='./img/5/RNN_7.png' width=500>  \n",
    "  \n",
    "__역전파__  \n",
    "  \n",
    "<img src='./img/5/RNN_8.png' width=500>  \n",
    "  \n",
    "--------\n",
    "--------\n",
    "  \n",
    "< 참고 >  \n",
    "  \n",
    "tanh 함수  \n",
    "  \n",
    "<img src='./img/5/tanh.png' width=300>  \n",
    "  \n",
    "$y=tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}$  \n",
    "  \n",
    "------\n",
    "  \n",
    "- 분수 함수의 미분\n",
    "  \n",
    "${\\frac{f(x)}{g(x)}}'=\\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}$  \n",
    "  \n",
    "- 네이비어 수(e) 미분  \n",
    "  \n",
    "$\\frac{\\partial{e^x}}{\\partial{x}}=e^x$  \n",
    "  \n",
    "$\\frac{\\partial{e^{-x}}}{\\partial{x}}=-e^{-x}$  \n",
    "  \n",
    "--------\n",
    "  \n",
    "따라서, tanh 함수의 미분은 다음과 같다.  \n",
    "  \n",
    "$\\frac{\\partial{tanh(x)}}{\\partial{x}}=\\frac{(e^x+e^{-x})(e^x+e^{-x})-(e^x-e^{-x})(e^x-e^{-x})}{(e^x+e^{-x})^2}\\\\\n",
    "=1-\\frac{(e^x-e^{-x})(e^x-e^{-x})}{(e^x+e^{-x})^2}\\\\\n",
    "=1-{\\frac{(e^x-e^{-x})}{(e^x+e^{-x})}}^2\\\\\n",
    "=1-tanh(x)^2\\\\\n",
    "=1-y^2$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8260e9",
   "metadata": {},
   "source": [
    "- RNN 클래스  \n",
    "  \n",
    "가중치 2개와 편항 1개를 인수로 받음  \n",
    "  \n",
    "- forward 메서드  \n",
    "    - 아래로부터의 입력 x와 왼쪽으로부터의 입력 h_prev를 인수로 받음\n",
    "    - h_next는 출력(다음 시각 계층으로의 입력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e972a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None # 역전파 계산 시 사용하는 중간데이터를 담음\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a7a94",
   "metadata": {},
   "source": [
    "### 5.3.2 Time RNN 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a5fcc",
   "metadata": {},
   "source": [
    "T개의 RNN 계층으로 구성된 Time RNN 계층 구현  \n",
    "  \n",
    "<img src='./img/5/TimeRnn_1.png' width=500>  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b0ae8",
   "metadata": {},
   "source": [
    "- TimeRNN 클래스  \n",
    "    - h : forward() 메서드를 불렀을 때 마지막 RNN 계층의 은닉 상태를 저장  \n",
    "    - dh : backward()를 불렀을 때 하나 앞 블록의 은닉 상태의 기울기를 저장  \n",
    "  \n",
    "'상태가 있다'란 Time RNN 계층이 은닉 상태를 유지한다는 뜻  \n",
    "아무리 긴 시계열 데이터라도 Time RNN 계층의 순전파를 끊지 않고 전파함  \n",
    "  \n",
    "- forward 메서드  \n",
    "    - xs : T개의 시계열 데이터를 하나로 모은 것(N, T, D)\n",
    "  \n",
    "T회 반복되는 for문 안에서 RNN 계층을 생성하여 각 시각 t의 은닉 상태 h를 계산하고 이를 hs에 해당 인덱스(시각)의 값으로 저장함  \n",
    "  \n",
    "- backward 메서드  \n",
    "    - dhs : 상류(출력 쪽 층)에서부터 전해지는 기울기\n",
    "    - dxs : 하류로 내보내는 기울기\n",
    "    - dh : 이전 시각의 은닉 상태 기울기  \n",
    "  \n",
    "Truncated BPTT를 수행하기 때문에 이 블록 이전 시각의 역전파는 필요하지 않음  \n",
    "t번째 RNN 계층에서는 위로부터의 기울기 $dh_t$와 '한 시각 뒤(미래) 계층'으로부터의 기울기 $dh_{next}$가 전해짐  \n",
    "RNN 계층의 순전파에서는 출력이 2개로 분기되며, 이는 역전파에서는 각 기울기가 합산되어 전파함  \n",
    "따라서 역전파 시 RNN 계층에서는 합산된 기울기($dh_t+dh_{next}$)가 입력됨  \n",
    "  \n",
    "Time RNN 계층 안에는 RNN 계층이 여러 개 있으며 그 RNN 계층들은 똑같은 가중치를 사용  \n",
    "따라서 Time RNN 계층의 (최종) 가중치의 기울기는 각 RNN 계층의 가중치 기울기를 모두 더한 값이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c50c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f') \n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0,0,0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:,t,:] +  dh) # 합산된 기울기\n",
    "            dxs[:,t,:] = dx\n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870003e2",
   "metadata": {},
   "source": [
    "## 5.4 시계열 데이터 처리 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623377c8",
   "metadata": {},
   "source": [
    "RNNLM : RNN을 사용한 언어 모델, RNN Language Model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b265b",
   "metadata": {},
   "source": [
    "### 5.4.1 RNNLM의 전체 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91124c",
   "metadata": {},
   "source": [
    "<img src='./img/5/RNNLM_1.png' width=500>  \n",
    "  \n",
    "- 입력 데이터 : 단어 ID의 배열\n",
    "- Embedding 계층 : 단어 ID를 단어의 분산 표현(단어 벡터)로 변환\n",
    "- RNN 계층 : 단어의 분산 표현을 입력받아 은닉 상태를 다음 층으로(위쪽으로) 출력함과 동시에, 다음 시각의 RNN 계층으로(오른쪽으로) 출력함  \n",
    "- RNN 계층이 위로 출력한 은닉 상태는 Affine 계층을 거쳐 Softmax 계층으로 전해짐  \n",
    "  \n",
    "RNN 계층은 과거의 정보를 응집된 은닉 상태 벡터로 저장해둠  \n",
    "그렇기 때문에 RNNLM은 지금까지 입력된 단어를 기억하고, 그것을 바탕으로 다음에 출현할 단어를 예측할 수 있음  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f89654",
   "metadata": {},
   "source": [
    "### 5.4.2 Time 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77309ac",
   "metadata": {},
   "source": [
    "<img src='./img/5/RNNLM_2.png' width=500>  \n",
    "  \n",
    "- Time Embedding 계층  \n",
    "  \n",
    "순전파 시에 T개의 Embedding 계층을 준비하고 각 embedding 계층이 각 시각의 데이터를 처리함  \n",
    "  \n",
    "- Time Affine 계층  \n",
    "  \n",
    "Affine 계층 T개 준비해서, 각 시각의 데이터를 개별적으로 처리함  \n",
    "  \n",
    "- Time Softmax with Loss 계층  \n",
    "  \n",
    "<img src='./img/5/RNNLM_3.png' width=700>  \n",
    "  \n",
    "시계열 버전의 Softmax 계층과 손실 오차를 구하는 Cross Entropy Error 계층  \n",
    "  \n",
    "위 그림에서 '$x_0, x_1, \\cdots$' 데이터는 아래층에서부터 전해지는 '점수'를,    \n",
    "'$t_0, t_1, \\cdots$' 데이터는 정답 레이블을 나타냄  \n",
    "  \n",
    "T개의 Softmax with Loss 계층 각각이 손실을 산출하고 그 손실들을 합산해 평균한 값이 최종 손실이 됨  \n",
    "  \n",
    "$L=\\frac{1}{T}(L_0+L_1+\\cdots +L_{T-1})$  \n",
    "  \n",
    "(다음에서 구현하는 내용에서는 미니배치에 해당하는 손실의 평균을 구함  \n",
    "데이터 N개짜리 미니배치라면 N개 손실을 더해 다시 N으로 나눠 데이터 1개당 평균 손실을 구함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d60b1d",
   "metadata": {},
   "source": [
    "## 5.5 RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10510818",
   "metadata": {},
   "source": [
    "### 5.5.1 RNNLM 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a7714",
   "metadata": {},
   "source": [
    "<img src='./img/5/SimpleRnnlm_1.png' width=200>  \n",
    "  \n",
    "- SimpleRnnlm 클래스  \n",
    "    - RNN 계층과 Affine 계층에서 'Xavier 초깃값' 사용  \n",
    "        이전 노드가 n개라면 표준편차가 $\\frac{1}{\\sqrt{n}}$인 분포로 값을 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ce219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(v).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다. \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebac7e7",
   "metadata": {},
   "source": [
    "### 5.5.2 언어 모델의 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f855cee",
   "metadata": {},
   "source": [
    "언어 모델은 주어진 과거 단어(정보)로부터 다음에 출현할 단어의 확률분포를 출력함  \n",
    "언어모델의 예측 성능을 평가하는 척도로 __퍼플렉서티(perplexity, 혼란도)__를 자주 이용함  \n",
    "  \n",
    "- 데이터 수 하나  \n",
    "  \n",
    "데이터 수가 하나일 때 퍼플렉서티는 '확률의 역수'임  \n",
    "이 값은 '분기 수(number of branches)'로 해석할 수 있음  \n",
    "분기 수란 다음에 취할 수 있는 선택사항의 수(다음에 출현할 수 있는 단어의 후보 수)를 의미함  \n",
    "따라서 퍼플렉서티는 작을수록 좋음(최솟값은 1.0)  \n",
    "  \n",
    "ex)  \n",
    "퍼플렉서티 = 1.25 : 다음에 출현할 수 있는 단어의 후보를 1개 정도로 좁힘  \n",
    "퍼플렉서티 = 5 : 다음에 출현할 수 있는 단어의 후보가 5개나 남아있음  \n",
    "  \n",
    "- 입력 데이터 여러 개  \n",
    "  \n",
    "$L=-\\frac{1}{N}\\sum_n\\sum_kt_{nk}logy_{nk}$  \n",
    "  \n",
    "$perplexity=e^L$  \n",
    "  \n",
    "- N : 데이터의 총 개수\n",
    "- $t_n$ : 원핫 벡터로 나타낸 정답 레이블($t_nk$ : n개째 데이터의 k번째 값)\n",
    "- $y_{nk}$ : 확률분포(신경망에서는 Softmax의 출력)  \n",
    "- L : 신경망의 손실(교차 엔트로피 오차와 같은 식)  \n",
    "  \n",
    "데이터가 여러 개일 때도,  \n",
    "데이터가 하나일 때 설명한 '확률의 역수', '분기 수', '선택사항의 수' 같은 개념이 그대로 적용됨  \n",
    "즉, 퍼플렉서티가 작아질수록 좋은 모델😃"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c5cb9",
   "metadata": {},
   "source": [
    "### 5.5.3 RNNLM의 학습 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d12c4",
   "metadata": {},
   "source": [
    "PTB 데이터셋 (처음 1,000개 단어만) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b394661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 1 | 퍼플렉서티 387.23\n",
      "| 에폭 2 | 퍼플렉서티 260.65\n",
      "| 에폭 3 | 퍼플렉서티 224.29\n",
      "| 에폭 4 | 퍼플렉서티 214.82\n",
      "| 에폭 5 | 퍼플렉서티 204.87\n",
      "| 에폭 6 | 퍼플렉서티 201.97\n",
      "| 에폭 7 | 퍼플렉서티 197.89\n",
      "| 에폭 8 | 퍼플렉서티 196.22\n",
      "| 에폭 9 | 퍼플렉서티 191.04\n",
      "| 에폭 10 | 퍼플렉서티 192.15\n",
      "| 에폭 11 | 퍼플렉서티 188.13\n",
      "| 에폭 12 | 퍼플렉서티 191.69\n",
      "| 에폭 13 | 퍼플렉서티 189.78\n",
      "| 에폭 14 | 퍼플렉서티 190.05\n",
      "| 에폭 15 | 퍼플렉서티 188.88\n",
      "| 에폭 16 | 퍼플렉서티 186.28\n",
      "| 에폭 17 | 퍼플렉서티 183.56\n",
      "| 에폭 18 | 퍼플렉서티 180.07\n",
      "| 에폭 19 | 퍼플렉서티 180.81\n",
      "| 에폭 20 | 퍼플렉서티 182.14\n",
      "| 에폭 21 | 퍼플렉서티 179.89\n",
      "| 에폭 22 | 퍼플렉서티 175.51\n",
      "| 에폭 23 | 퍼플렉서티 172.42\n",
      "| 에폭 24 | 퍼플렉서티 173.11\n",
      "| 에폭 25 | 퍼플렉서티 171.53\n",
      "| 에폭 26 | 퍼플렉서티 169.46\n",
      "| 에폭 27 | 퍼플렉서티 164.82\n",
      "| 에폭 28 | 퍼플렉서티 163.30\n",
      "| 에폭 29 | 퍼플렉서티 160.23\n",
      "| 에폭 30 | 퍼플렉서티 153.35\n",
      "| 에폭 31 | 퍼플렉서티 154.81\n",
      "| 에폭 32 | 퍼플렉서티 149.82\n",
      "| 에폭 33 | 퍼플렉서티 152.05\n",
      "| 에폭 34 | 퍼플렉서티 145.57\n",
      "| 에폭 35 | 퍼플렉서티 145.66\n",
      "| 에폭 36 | 퍼플렉서티 138.49\n",
      "| 에폭 37 | 퍼플렉서티 133.43\n",
      "| 에폭 38 | 퍼플렉서티 131.40\n",
      "| 에폭 39 | 퍼플렉서티 124.69\n",
      "| 에폭 40 | 퍼플렉서티 121.83\n",
      "| 에폭 41 | 퍼플렉서티 120.54\n",
      "| 에폭 42 | 퍼플렉서티 114.64\n",
      "| 에폭 43 | 퍼플렉서티 108.50\n",
      "| 에폭 44 | 퍼플렉서티 105.04\n",
      "| 에폭 45 | 퍼플렉서티 101.11\n",
      "| 에폭 46 | 퍼플렉서티 99.87\n",
      "| 에폭 47 | 퍼플렉서티 93.24\n",
      "| 에폭 48 | 퍼플렉서티 88.44\n",
      "| 에폭 49 | 퍼플렉서티 86.19\n",
      "| 에폭 50 | 퍼플렉서티 81.28\n",
      "| 에폭 51 | 퍼플렉서티 77.25\n",
      "| 에폭 52 | 퍼플렉서티 73.63\n",
      "| 에폭 53 | 퍼플렉서티 69.45\n",
      "| 에폭 54 | 퍼플렉서티 67.71\n",
      "| 에폭 55 | 퍼플렉서티 64.32\n",
      "| 에폭 56 | 퍼플렉서티 59.89\n",
      "| 에폭 57 | 퍼플렉서티 57.44\n",
      "| 에폭 58 | 퍼플렉서티 53.69\n",
      "| 에폭 59 | 퍼플렉서티 50.70\n",
      "| 에폭 60 | 퍼플렉서티 48.63\n",
      "| 에폭 61 | 퍼플렉서티 47.17\n",
      "| 에폭 62 | 퍼플렉서티 44.54\n",
      "| 에폭 63 | 퍼플렉서티 41.22\n",
      "| 에폭 64 | 퍼플렉서티 38.87\n",
      "| 에폭 65 | 퍼플렉서티 38.58\n",
      "| 에폭 66 | 퍼플렉서티 35.49\n",
      "| 에폭 67 | 퍼플렉서티 34.88\n",
      "| 에폭 68 | 퍼플렉서티 31.69\n",
      "| 에폭 69 | 퍼플렉서티 30.59\n",
      "| 에폭 70 | 퍼플렉서티 28.90\n",
      "| 에폭 71 | 퍼플렉서티 27.68\n",
      "| 에폭 72 | 퍼플렉서티 25.88\n",
      "| 에폭 73 | 퍼플렉서티 24.06\n",
      "| 에폭 74 | 퍼플렉서티 22.73\n",
      "| 에폭 75 | 퍼플렉서티 22.43\n",
      "| 에폭 76 | 퍼플렉서티 19.86\n",
      "| 에폭 77 | 퍼플렉서티 19.41\n",
      "| 에폭 78 | 퍼플렉서티 18.69\n",
      "| 에폭 79 | 퍼플렉서티 17.06\n",
      "| 에폭 80 | 퍼플렉서티 15.93\n",
      "| 에폭 81 | 퍼플렉서티 15.49\n",
      "| 에폭 82 | 퍼플렉서티 14.73\n",
      "| 에폭 83 | 퍼플렉서티 13.49\n",
      "| 에폭 84 | 퍼플렉서티 13.08\n",
      "| 에폭 85 | 퍼플렉서티 12.40\n",
      "| 에폭 86 | 퍼플렉서티 11.43\n",
      "| 에폭 87 | 퍼플렉서티 11.20\n",
      "| 에폭 88 | 퍼플렉서티 10.50\n",
      "| 에폭 89 | 퍼플렉서티 9.79\n",
      "| 에폭 90 | 퍼플렉서티 9.41\n",
      "| 에폭 91 | 퍼플렉서티 9.33\n",
      "| 에폭 92 | 퍼플렉서티 8.76\n",
      "| 에폭 93 | 퍼플렉서티 8.33\n",
      "| 에폭 94 | 퍼플렉서티 7.92\n",
      "| 에폭 95 | 퍼플렉서티 7.91\n",
      "| 에폭 96 | 퍼플렉서티 7.19\n",
      "| 에폭 97 | 퍼플렉서티 6.99\n",
      "| 에폭 98 | 퍼플렉서티 6.43\n",
      "| 에폭 99 | 퍼플렉서티 6.44\n",
      "| 에폭 100 | 퍼플렉서티 6.29\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from ch05.simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5 # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1] # 입력\n",
    "ts = corpus[1:] # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 1. 각 미니배치에서 샘플 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 2. 미니배치 획득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "        \n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "    # 3. 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f' % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f41ef",
   "metadata": {},
   "source": [
    "2 -> time_idx를 1씩 순차적으로 늘리면서 말뭉치에서 time_idx 위치의 데이터를 얻음  \n",
    "말뭉치를 읽는 위치가 말뭉치 크기를 넘어설 경우 말뭉치의 처음으로 돌아와야 하기 때문에 말뭉치의 크기로 나눈 나머지를 인덱스로 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c2de0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "\n",
    "x = np.arange(1, 101)\n",
    "plt.plot(x, ppl_list, label='perplexity')\n",
    "plt.title('퍼플렉서티 추이')\n",
    "plt.xlabel('epochs'); plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a20912",
   "metadata": {},
   "source": [
    "학습을 진행할수록 퍼플렉서티가 순조롭게 낮아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd55ec",
   "metadata": {},
   "source": [
    "### 5.5.4 RNNLM의 Trainer 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40478066",
   "metadata": {},
   "source": [
    "RnnlmTrainer 클래스  \n",
    "    1. 미니배치를 '순차적'으로 만들어  \n",
    "    2. 모델의 순전파와 역전파를 호출하고  \n",
    "    3. 옵티마이저로 가중치를 갱신하고  \n",
    "    4. 퍼플렉서티를 구함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d404d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnlmTrainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.time_idx = None\n",
    "        self.ppl_list = None\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]  # 배치에서 각 샘플을 읽기 시작하는 위치\n",
    "\n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t\n",
    "\n",
    "    def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,\n",
    "            max_grad=None, eval_interval=20):\n",
    "        data_size = len(xs)\n",
    "        max_iters = data_size // (batch_size * time_size)\n",
    "        self.time_idx = 0\n",
    "        self.ppl_list = []\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            for iters in range(max_iters):\n",
    "                batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "                # 기울기를 구해 매개변수 갱신\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # 퍼플렉서티 평가\n",
    "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "                    ppl = np.exp(total_loss / loss_count)\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 퍼플렉서티 %.2f'\n",
    "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl))\n",
    "                    self.ppl_list.append(float(ppl))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.ppl_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.ppl_list, label='train')\n",
    "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\n",
    "        plt.ylabel('퍼플렉서티')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b15daa",
   "metadata": {},
   "source": [
    "RnnlmTrainer 클래스 사용 예시\n",
    "~~~python\n",
    "...\n",
    "from common.trainer import RnnlmTrainer\n",
    "\n",
    "...\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
