{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d15b575",
   "metadata": {},
   "source": [
    "# CHAPTER 3 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c429f6b",
   "metadata": {},
   "source": [
    "'추론 기반 기법'을 이용한 단어의 분산 표현  \n",
    "추론 과정에 신경망을 이용하는데, 여기서 word2vec을 이용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20109fbd",
   "metadata": {},
   "source": [
    "## 3.1 추론 기반 기법과 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e4b1b",
   "metadata": {},
   "source": [
    "### 3.1.1 통계 기반 기법의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3085f9",
   "metadata": {},
   "source": [
    "통계 기반 기법은 주변 단어의 빈도를 기초로 단어를 표현함\n",
    "현업에서 다루는 말뭉치의 어휘 수는 양이 방대하여 이 방식은 대규모 말뭉치를 다룰 때 문제가 발생  \n",
    "    \n",
    "<img src='./img/3/word2vec_1.png' width=500>  \n",
    "  \n",
    "통계 기반 기법은 말뭉치 전체의 통계(동시발생 행렬과 PPMI 등)을 이용해 단 1회의 처리(SVD 등)만에 단어의 분산 표현을 얻는 반면,  \n",
    "추론 기반 기법에서는, 미니배치 학습에서 신경망이 한 번에 소량(미니배치)의 학습 샘플씩 반복해서 학습하며 가중치를 갱신함  \n",
    "따라서, 말뭉치의 어휘 수가 많아 SVD 등 계산량이 큰 작업을 처리하기 어려운 경우에도 신경망을 학습시킬 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8c35e",
   "metadata": {},
   "source": [
    "### 3.1.2 추론 기반 기법 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba2dd3",
   "metadata": {},
   "source": [
    "추론 기반 기법에서는 추론이 주된 작업  \n",
    "  \n",
    "<img src='./img/3/word2vec_2.png' width=300>  \n",
    "  \n",
    "여기서, 추론이란 위 그림과 같이 주변 단어(맥락)가 주어졌을 때 \"?\"에 무슨 단어가 들어가는지를 추측하는 작업을 의미  \n",
    "추론 문제를 반복해서 풀면서 단어의 출현 패턴을 학습함  \n",
    "  \n",
    "<img src='./img/3/word2vec_3.png' width=500>  \n",
    "  \n",
    "추론 기반 기법에서는 신경망 모델을 사용  \n",
    "모델은 맥락 정보를 입력받아 (출현할 수 있는) 각 단어의 출현 확률을 출력함  \n",
    "말뭉치를 사용해 모델이 올바른 추측올 내놓도록 학습을 하고,  \n",
    "단어의 분산 표현을 얻는 것이 추론 기반 기법의 큰 틀  \n",
    "  \n",
    "추론 기반 기법도 통계 기반 기법처럼 분포 가설('단어의 의미는 주변에 의해 형성된다')에 기초함  \n",
    "두 기법 모두 분포 가설에 근거하는 '단어의 동시발생 가능성'을 얼마나 잘 모델링하는가가 중요한 연구 주제임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb5e4e",
   "metadata": {},
   "source": [
    "### 3.1.3 신경망에서의 단어  처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c328c8f",
   "metadata": {},
   "source": [
    "신경망에서 단어를 처리하기 위해 먼저 '고정 길이의 벡터'로 변환해야 함  \n",
    "  \n",
    "ex)\n",
    "<img src='./img/3/word2vec_4.png' width=300>  \n",
    "\n",
    "벡터의 원소 중 하나만 1이고 나머지는 모두 0인 원핫 표현(원핫 벡터)로 변환  \n",
    "단어를 고정 길이 벡터로 변환함으로써 신경망의 입력층 뉴런의 수를 고정할 수 있음  \n",
    "  \n",
    "<img src='./img/3/word2vec_5.png' width=500>  \n",
    "  \n",
    "위 예시의 경우, 입력층의 뉴런은 총 7개  \n",
    "이 7개의 뉴런은 차례로 7개의 단어들에 대응됨  \n",
    "이로써 단어를 벡터로 나타내어 신경망으로 단어를 처리할 수 있음  \n",
    "  \n",
    "<img src='./img/3/word2vec_6.png' width=500>  \n",
    "<img src='./img/3/word2vec_7.png' width=500>  \n",
    "  \n",
    "가중치(매개변수)와 입력층 뉴런과의 가중합이 은닉층의 뉴런이 됨  \n",
    "    \n",
    "< 참고 >  \n",
    "이번 장의 예시에서는 편향을 생략함  \n",
    "편향을 이용하지 않는 완전연결계층은 '행렬 곱' 계산에 해당함  \n",
    "딥러닝 프레임워크들은 일반적으로 완전연결계층을 생성할 때 편향을 이용할지 선택할 수 있도록 함  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0deaa69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88858884 -1.31849453  0.57897869]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0]]) # 입력(원핫 벡터)\n",
    "W = np.random.randn(7,3) # 가중치\n",
    "h = np.matmul(c,W) # 중간 노드(은닉층)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f7a01",
   "metadata": {},
   "source": [
    "c는 원핫 표현이므로 c와 W의 행렬 곱 결과는 결국 가중치의 행벡터 하나를 뽑아낸 것과 같음  \n",
    "(행렬 곱으로 계산하는 다소 비효율적인 부분에 대해서 4장에서 개선할 예정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b4d19",
   "metadata": {},
   "source": [
    "__MatMul 계층__으로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af8550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.58524376  0.45803117  0.58089526]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0]])\n",
    "W = np.random.randn(7,3)\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e87574",
   "metadata": {},
   "source": [
    "## 3.2 단순한 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c9e71",
   "metadata": {},
   "source": [
    "### 3.2.1 CBOW 모델의 추론 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e089a",
   "metadata": {},
   "source": [
    "word2vec에서 사용되는 신경망은 CBOW(continuous bag-of-words)모델과 skip-gram 모델이 있음  \n",
    "CBOW 모델은 맥락으로부터 타깃(target)을 추측하는 용도의 신경망  \n",
    "여기서, '타깃'은 중앙 단어이고 그 주변 단어들이 '맥락'을 의미  \n",
    "  \n",
    "CBOW 모델의 입력은 맥락이며, 맥락은 단어들의 목록임  \n",
    "맥락은 원핫 표현으로 변환하여 사용  \n",
    "  \n",
    "<img src='./img/3/cbow_1.png' width=400>  \n",
    "  \n",
    "CBOW 모델은 위 그림과 같음  \n",
    "입력층이 2개, 은닉층을 거쳐 출력층에 도달함  \n",
    "두 입력층에서 은닉층으로의 변환은 <u>똑같은 완전연결계층(가중치는 $W_{in}$)이 처리함</u>  \n",
    "은닉층에서 출력층 뉴런으로의 변환은 다른 완전연결계층(가중치는 $W_{out}$)이 처리함  \n",
    "  \n",
    "여기서, 입력층이 2개인 이유는 맥락으로 고려할 단어를 2개로 정했기 때문\\!  \n",
    "만약 맥락에 포함시킬 단어가 N개라면 입력층도 N개가 됨  \n",
    "입력층이 여러개인 경우 은닉층 뉴런은 평균하여 계산함  \n",
    "  \n",
    "출력층의 뉴런은 하나하나가 가가각의 단어에 대응하며 각 단어의 '점수'를 뜻함  \n",
    "점수가 높을수록 대응 단어의 출현 확률도 높아짐  \n",
    "점수에 소프트맥스 함수를 적용하면 확률을 얻을 수 있음  \n",
    "  \n",
    "입력층에서 은닉층으로의 변환은 완전연결계층(가중치 $W_{in}$)에 의해 이뤄지며,  \n",
    "이 가중치의 각 행이 해당 단어의 분산표현  \n",
    "학습을 진행할수록 맥락에서 출현하는 단어를 잘 추측하는 방향으로 분산표현이 갱신됨  \n",
    "  \n",
    "은닉층의 뉴런 수를 입력층의 뉴런 수보다 적게 해야 함  \n",
    "이렇게 해야 은닉층에는 단어 예측에 필요한 정보를 '간결하게' 담게 되며, 결과적으로 밀집벡터 표현을 얻을 수 있음  \n",
    "  \n",
    "이것이 word2vec의 전체 그림😃  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d9d2e",
   "metadata": {},
   "source": [
    "<img src='./img/3/cbow_2.png' width=500>  \n",
    "  \n",
    "계층 관점에서 CBOW 모델의 신경망을 보면,  \n",
    "가장 앞 단에는 2개의 MatMul 계층이 있고, 이 두 계층의 출력을 더한 후 0.5를 곱하여 '평균'을 계산함  \n",
    "이 평균값이 은닉층 뉴런이 됨  \n",
    "마지막으로 뉴런에 또 다른 MatMul 계층을 적용하여 '점수'를 출력  \n",
    "  \n",
    "CBOW 모델은 활성화 함수를 사용하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c4ceb",
   "metadata": {},
   "source": [
    "__CBOW 모델의 추론 처리 구현__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6535a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69968619 -0.7433146  -1.98250714 -4.67367092 -0.78297611  2.33807495\n",
      "   2.18039249]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "# 샘플 맥락 데이터\n",
    "c0 = np.array([[1,0,0,0,0,0,0]])\n",
    "c1 = np.array([[0,1,0,0,0,0,0]])\n",
    "\n",
    "# 가중치 초기화\n",
    "W_in = np.random.randn(7,3)\n",
    "W_out = np.random.randn(3,7)\n",
    "\n",
    "# 계층 생성\n",
    "# 입력층 측의 MatMul 계층은 맥락 수만큼 생성\n",
    "# 입력층 측의 MatMul 계층은 가중치 W_in을 공유함\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# 순전파\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer0.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f281e58",
   "metadata": {},
   "source": [
    "### 3.2.2 CBOW 모델의 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e915e07",
   "metadata": {},
   "source": [
    "<img src='./img/3/cbow_3.png' width=500>  \n",
    "  \n",
    "출력층에서 나온 점수를 소프트맥스 함수에 적용하면 '확률'을 얻을 수 있음  \n",
    "이 확률은 맥락(전후 단어)이 주어졌을 때 그 중앙에 어떤 단어가 출현하는지를 나타냄  \n",
    "  \n",
    "CBOW 모델의 학습에서는 올바른 예측을 할 수 있도록 가중치($W_{in}, W_{out}$)를 조정함  \n",
    "단어 출현 패턴을 학습 시 어떤 말뭉치를 사용하느냐에 따라 단어의 분산 표현이 달라질 수 있음  \n",
    "<img src='./img/3/cbow_4.png' width=500>  \n",
    "  \n",
    "이 신경망은 다중 클래스 분류를 수행하는 신경망이므로  \n",
    "소프트맥스 함수를 이용해 점수를 확률로 변환하고, 그 확률과 정답 레이블로부터 교차 엔트로피 오차를 구한 후, 그 값을 손실로 사용해 학습을 진행함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d02d94",
   "metadata": {},
   "source": [
    "### 3.2.3 word2vec의 가중치와 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31126fa",
   "metadata": {},
   "source": [
    "<img src='./img/3/cbow_5.png' width=500>  \n",
    "  \n",
    "word2vec에서 사용되는 신경망에는 두 가지 가중치가 있음\n",
    "- 입력 측 완전연결계층의 가중치($W_{in}$)  \n",
    "    각 행이 각 단어의 분산 표현\n",
    "- 출력 측 완전연결계층의 가중치($W_{out}$)  \n",
    "    단어의 의미가 인코딩된 벡터  \n",
    "    출력 측 가중치는 각 단어의 분산 표현이 열 방향(수직 방향)으로 저장됨  \n",
    "  \n",
    "이 중 최종적으로 이용하는 단어의 분산 표현은  \n",
    "일반적으로 word2vec(특히 skip-gram 모델)에서는 '입력 측의 가중치'만 최종 단어의 분산 표현으로 이용함  \n",
    "  \n",
    "< 참고 >  \n",
    "word2vec과 비슷한 기법인 GloVe에서는 입력 측 가중치와 출력 측 가중치를 더했을 때 좋은 결과를 얻었음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf40a2b",
   "metadata": {},
   "source": [
    "## 3.3 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac8d84",
   "metadata": {},
   "source": [
    "### 3.3.1 맥락과 타깃"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdf4d92",
   "metadata": {},
   "source": [
    "<img src='./img/3/cbow_6.png' width=500>  \n",
    "  \n",
    "CBOW의 경우\n",
    "- 신경망의 입력 : 맥락  \n",
    "- 정답 레이블 : 맥락에 둘러싸인 중앙의 단어, 타깃  \n",
    "  \n",
    "말뭉치에서 '맥락'과 '타깃'을 만드는 작업\n",
    "1. 말뭉치 텍스트를 단어 ID로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000ab0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a9074",
   "metadata": {},
   "source": [
    "2. 단어 ID의 배열인 corpus로부터 맥락과 타깃을 만들어냄\n",
    "  \n",
    "<img src='./img/3/cbow_7.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "054a9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size+1):\n",
    "            if t==0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "        \n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0277d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맥락:\n",
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "타깃:\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "print('맥락:')\n",
    "print(contexts)\n",
    "print('타깃:')\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c71bad",
   "metadata": {},
   "source": [
    "### 3.3.2 원핫 표현으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100a70a",
   "metadata": {},
   "source": [
    "<img src='./img/3/cbow_8.png' width=700>  \n",
    "  \n",
    "이어서, 맥락과 타깃을 단어 ID에서 원핫 표현으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "049402a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    N = corpus.shape[0]\n",
    "\n",
    "    if corpus.ndim == 1:\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1\n",
    "\n",
    "    elif corpus.ndim == 2:\n",
    "        C = corpus.shape[1]\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a04d68",
   "metadata": {},
   "source": [
    "__데이터 준비 과정 정리__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f62136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a992083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맥락:\n",
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]]\n",
      "타깃:\n",
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print('맥락:')\n",
    "print(contexts)\n",
    "print('타깃:')\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277d3476",
   "metadata": {},
   "source": [
    "## 3.4 CBOW 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09824ef",
   "metadata": {},
   "source": [
    "- SimpleCBOW  \n",
    "    입력 측의 맥락을 처리하는 MatMul 계층은 맥락에서 사용하는 단어의 수(윈도우 크기)만큼 만들어야 함  \n",
    "    입력 측 MatMul 계층들은 모두 같은 가중치를 이용함 \n",
    "  \n",
    "- backward\n",
    "    <img src='./img/3/cbow_10.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483bb9a8",
   "metadata": {},
   "source": [
    "__CBOW 모델 구현__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661d6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "        \n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer0.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3bfca",
   "metadata": {},
   "source": [
    "### 3.4.1 학습 코드 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c552dc",
   "metadata": {},
   "source": [
    "- Trainer  \n",
    "    학습데이터로부터 미니배치를 선택한 다음  \n",
    "    신경망에 입력해 기울기를 구하고  \n",
    "    기울기를 Optimizer에 넘겨 매개변수를 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84aba26c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
      "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
      "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
      "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
      "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
      "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
      "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
      "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
      "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
      "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
      "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
      "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
      "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
      "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
      "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
      "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
      "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
      "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
      "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
      "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
      "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
      "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
      "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
      "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
      "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 454 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 455 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 456 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 457 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 458 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 459 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 460 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 461 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 462 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 463 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 464 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 465 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 466 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 467 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 468 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 469 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 470 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 471 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 472 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 473 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 474 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 475 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 476 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 477 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 478 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 479 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 480 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 481 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 482 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 483 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 484 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
      "| 에폭 485 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 486 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 487 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 488 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 489 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 490 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 491 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 492 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 493 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 494 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 495 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 496 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 497 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 498 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 499 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 500 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 501 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 502 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 503 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 504 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 505 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 506 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 507 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 508 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 509 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 510 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 511 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 512 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 513 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 514 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 515 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 516 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 517 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 518 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 519 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 520 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 521 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 522 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 523 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 524 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 525 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 526 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 527 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 528 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 529 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 530 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 531 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 532 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 533 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 534 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 535 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 536 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 537 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 538 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 539 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 540 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 541 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 542 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 543 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 544 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 545 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 546 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 547 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 548 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 549 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 550 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 551 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 552 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 553 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 554 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 555 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
      "| 에폭 556 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 557 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 558 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 559 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 560 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 561 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 562 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 563 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
      "| 에폭 564 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 565 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 566 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 567 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 568 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 569 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 570 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 571 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
      "| 에폭 572 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 573 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 574 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
      "| 에폭 575 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 576 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 577 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 578 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 579 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 580 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 581 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 582 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 583 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 584 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 585 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 586 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 587 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 588 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
      "| 에폭 589 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 590 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 591 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 592 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 593 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
      "| 에폭 594 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 595 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 596 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 597 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 598 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 599 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 600 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 601 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 602 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 603 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 604 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 605 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 606 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 607 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
      "| 에폭 608 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 609 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 610 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 611 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 612 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 613 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 614 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 615 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 616 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 617 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 618 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 619 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 620 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 621 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 622 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 623 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 624 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 625 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 626 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
      "| 에폭 627 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 628 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 629 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 630 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 631 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 632 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 633 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 634 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 635 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 636 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 637 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 638 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 639 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 640 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 641 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 642 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 643 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 644 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 645 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 646 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 647 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 648 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 649 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 650 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 651 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 652 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 653 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 654 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 655 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
      "| 에폭 656 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 657 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 658 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 659 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 660 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 661 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 662 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 663 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 664 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 665 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 666 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 667 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 668 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 669 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 670 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 671 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
      "| 에폭 672 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 673 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 674 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 675 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 676 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 677 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 678 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 679 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 680 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
      "| 에폭 681 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 682 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 683 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 684 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 685 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 686 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 687 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 688 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 689 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 690 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
      "| 에폭 691 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 692 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 693 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 694 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 695 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 696 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 697 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 698 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 699 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 700 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 701 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 702 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 703 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
      "| 에폭 704 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 705 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 706 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 707 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 708 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
      "| 에폭 709 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
      "| 에폭 710 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 711 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 712 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 713 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 714 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 715 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 716 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 717 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 718 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 719 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 720 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 721 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 722 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 723 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 724 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 725 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 726 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 727 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 728 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 729 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 730 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 731 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 732 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
      "| 에폭 733 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 734 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 735 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 736 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 737 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
      "| 에폭 738 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 739 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 740 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
      "| 에폭 741 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 742 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 743 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 744 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 745 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 746 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 747 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 748 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 749 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 750 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 751 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 752 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 753 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 754 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 755 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
      "| 에폭 756 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 757 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 758 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 759 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 760 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 761 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 762 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 763 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 764 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 765 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 766 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 767 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 768 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 769 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 770 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 771 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 772 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 773 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 774 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 775 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 776 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
      "| 에폭 777 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 778 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 779 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 780 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 781 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 782 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 783 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
      "| 에폭 784 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 785 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 786 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
      "| 에폭 787 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
      "| 에폭 788 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 789 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
      "| 에폭 790 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
      "| 에폭 791 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 792 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 793 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 794 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
      "| 에폭 795 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 796 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 797 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 798 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 799 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 800 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 801 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 802 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 803 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 804 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 805 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 806 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
      "| 에폭 807 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
      "| 에폭 808 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 809 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 810 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 811 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 812 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 813 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 814 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 815 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 816 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 817 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 818 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 819 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 820 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 821 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 822 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 823 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 824 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 825 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 826 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
      "| 에폭 827 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
      "| 에폭 828 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 829 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
      "| 에폭 830 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 831 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 832 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
      "| 에폭 833 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 834 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 835 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 836 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 837 |  반복 1 / 2 | 시간 0[s] | 손실 0.20\n",
      "| 에폭 838 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 839 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 840 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 841 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 842 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 843 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
      "| 에폭 844 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 845 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 846 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 847 |  반복 1 / 2 | 시간 0[s] | 손실 0.19\n",
      "| 에폭 848 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 849 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 850 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 851 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
      "| 에폭 852 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 853 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 854 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
      "| 에폭 855 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
      "| 에폭 856 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 857 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 858 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 859 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 860 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 861 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 862 |  반복 1 / 2 | 시간 0[s] | 손실 0.18\n",
      "| 에폭 863 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 864 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
      "| 에폭 865 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 866 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 867 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
      "| 에폭 868 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 869 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 870 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 871 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 872 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 873 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
      "| 에폭 874 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 875 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
      "| 에폭 876 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
      "| 에폭 877 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 878 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
      "| 에폭 879 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 880 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
      "| 에폭 881 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 882 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
      "| 에폭 883 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 884 |  반복 1 / 2 | 시간 0[s] | 손실 0.26\n",
      "| 에폭 885 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 886 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 887 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 888 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
      "| 에폭 889 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 890 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 891 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 892 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 893 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 894 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
      "| 에폭 895 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
      "| 에폭 896 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 897 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 898 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 899 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 900 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
      "| 에폭 901 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 902 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 903 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 904 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 905 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 906 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 907 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 908 |  반복 1 / 2 | 시간 0[s] | 손실 0.16\n",
      "| 에폭 909 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 910 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 911 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
      "| 에폭 912 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 913 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 914 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 915 |  반복 1 / 2 | 시간 0[s] | 손실 0.14\n",
      "| 에폭 916 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
      "| 에폭 917 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 918 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 919 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 920 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 921 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
      "| 에폭 922 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 923 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
      "| 에폭 924 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 925 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 926 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 927 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 928 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
      "| 에폭 929 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 930 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 931 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 932 |  반복 1 / 2 | 시간 0[s] | 손실 0.15\n",
      "| 에폭 933 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 934 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 935 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 936 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
      "| 에폭 937 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
      "| 에폭 938 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 939 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
      "| 에폭 940 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 941 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
      "| 에폭 942 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 943 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
      "| 에폭 944 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 945 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 946 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 947 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 948 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 949 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 950 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 951 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
      "| 에폭 952 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 953 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 954 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 955 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 956 |  반복 1 / 2 | 시간 0[s] | 손실 0.12\n",
      "| 에폭 957 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 958 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 959 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
      "| 에폭 960 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 961 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 962 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 963 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 964 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 965 |  반복 1 / 2 | 시간 0[s] | 손실 0.25\n",
      "| 에폭 966 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 967 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
      "| 에폭 968 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 969 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 970 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 971 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 972 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 973 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 974 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 975 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
      "| 에폭 976 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 977 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 978 |  반복 1 / 2 | 시간 0[s] | 손실 0.11\n",
      "| 에폭 979 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 980 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 981 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 982 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 983 |  반복 1 / 2 | 시간 0[s] | 손실 0.13\n",
      "| 에폭 984 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
      "| 에폭 985 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
      "| 에폭 986 |  반복 1 / 2 | 시간 0[s] | 손실 0.24\n",
      "| 에폭 987 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 988 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 989 |  반복 1 / 2 | 시간 0[s] | 손실 0.21\n",
      "| 에폭 990 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 991 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 992 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 993 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 994 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
      "| 에폭 995 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 996 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 997 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n",
      "| 에폭 998 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
      "| 에폭 999 |  반복 1 / 2 | 시간 0[s] | 손실 0.23\n",
      "| 에폭 1000 |  반복 1 / 2 | 시간 0[s] | 손실 0.22\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you [ 1.6988004  -1.1111257  -0.92101324 -0.96030444 -0.46292794]\n",
      "say [1.272676   1.150973   1.1206589  1.0915618  0.47507647]\n",
      "goodbye [-0.47584322 -0.8252023  -1.066985   -1.0764306  -1.2632858 ]\n",
      "and [1.1194355 0.8509474 0.5668175 0.669281  1.7638085]\n",
      "i [-0.46622515 -0.8064402  -1.0453433  -1.0594838  -1.2672657 ]\n",
      "hello [ 1.6805035  -1.1124326  -0.94366574 -0.9750653  -0.45594916]\n",
      ". [ 1.03731    1.1508136  1.2566137  1.1773102 -1.7481419]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "from ch03.simple_cbow import SimpleCBOW\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d3cd2",
   "metadata": {},
   "source": [
    "학습을 거듭할수록 손실이 줄어드는 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207aaeef",
   "metadata": {},
   "source": [
    "## 3.5 word2vec 보충"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877744a",
   "metadata": {},
   "source": [
    "### 3.5.1 CBOW 모델과 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ff29f",
   "metadata": {},
   "source": [
    "CBOW 모델은 맥락을 주면 타깃 단어가 출현할 확률을 출력  \n",
    "여기서, 말뭉치를 $w_1, w_2, \\cdots, w_T$처럼 단어 시퀀스로 표기하고, t번째 단어에 대해 윈도우 크기가 1이라면  \n",
    "맥락으로 $w_{t-1}$과 $w_{t+1}$이 주어졌을 때 타깃이 $w_{t}$가 될 확률은 다음과 같음  \n",
    "$P(w_t|w_{t-1},w_{t+1})$  \n",
    "  \n",
    "이를 이용하면 CBOW 모델의 손실 함수도 간결하게 표현할 수 있음  \n",
    "  \n",
    "교차 엔트로피 오차 $L=-\\sum_kt_klogy_k$  \n",
    "  \n",
    "- $y_k$ : k번째에 해당하는 사건이 일어날 확률\n",
    "- $t_k$ : 정답 레이블(원핫 벡터)\n",
    "\n",
    "여기서, $t_k$는 $w_t$에 해당하는 원소는 1, 나머지는 0이므로 다음 식을 유도할 수 있음  \n",
    "  \n",
    "$L=-logP(w_t|w_{t-1},w_{t+1})$  \n",
    "  \n",
    "위 식과 같이, CBOW 모델의 손실 함수는 단순히 확률에 log를 취한 다음 마이너스를 붙이면 됨  \n",
    "이를 음의 로그 가능도(negative log likelihood)라고 함  \n",
    "말뭉치 전체로 확장하면 다음 식이 됨  \n",
    "  \n",
    "$L=-\\frac{1}{T}\\sum_{t=1}^TlogP(w_t|w_{t-1},w_{t+1})$  \n",
    "  \n",
    "CBOW 모델의 학습이 수행하는 일은 이 손실 함수의 값을 가능한 작게 만드는 것  \n",
    "또한, 이때의 가중치 매개변수가 우리가 얻고자 하는 단어의 분산 표현임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e044eeb",
   "metadata": {},
   "source": [
    "### 3.5.2 skip-gram 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60fcc6",
   "metadata": {},
   "source": [
    "word2vec에서 사용되는 신경망은 CBOW(continuous bag-of-words)모델과 skip-gram 모델이 있음  \n",
    "    \n",
    "<img src='./img/3/skip-gram_1.png' width=500>  \n",
    "  \n",
    "skip-gram 모델은 CBOW에서 다루는 맥락과 타깃을 역전시킨 모델  \n",
    "중앙의 단어(타깃)로부터 주변의 여러 단어(맥락)을 추측함  \n",
    "  \n",
    "<img src='./img/3/skip-gram_2.png' width=500>  \n",
    "  \n",
    "skip-gram 모델은 입력층은 하나, 출력층은 맥락의 수만큼 존재함  \n",
    "각 출력층에서는 Softmax with Loss 계층 등을 이용해 개별적으로 손실을 구하고 모두 더하여 최종 손실값을 계산함  \n",
    "  \n",
    "확률로 표기를 하면,  \n",
    "중앙 단어(타깃)인 $w_t$로부터 맥락인 $w_{t-1}$과 $w_{t+1}$을 추측  \n",
    "  \n",
    "$P(w_{t-1},w_{t+1}|w_t)$  \n",
    "  \n",
    "여기서, 맥락의 단어들 사이에는 관련성이 없다고 가정하고 다음과 같이 분해하면('조건부 독립'이라고 가정) 다음 식이 되고,  \n",
    "  \n",
    "$P(w_{t-1},w_{t+1}|w_t)=P(w_{t-1}|w_t)P(w_{t+1}|w_t)$  \n",
    "  \n",
    "이어서 이를 교차 엔트로피 오차에 적용하면 손실 함수를 유도할 수 있음  \n",
    "  \n",
    "$L=-logP(w_{t-1},w_{t+1}|w_t)\\\\\n",
    "=-logP(w_{t-1}|w_t)P(w_{t+1}|w_t)\\\\\n",
    "=-(logP(w_{t-1}|w_t)+P(w_{t+1}|w_t))$  \n",
    "  \n",
    "식에서 알 수 있듯, skip-gram 모델의 손실 함수는 맥락별 손실을 구한 다음 모두 더함  \n",
    "말뭉치 전체로 확장하면 손실 함수는 다음과 같음  \n",
    "  \n",
    "$L=-\\frac{1}{T}\\sum_{t=1}^T(logP(w_{t-1}|w_t)+logP(w_{t+1}|w_t))$  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd08556",
   "metadata": {},
   "source": [
    "CBOW 모델과 skip-gram 모델의 비교\n",
    "- 단어 분산 표현의 정밀도 면에서 skip-gram 모델의 결과가 더 좋은 경우가 많음\n",
    "- 말뭉치가 커질수록 저빈도 단어나 유추 문제의 성능 면에서 skip-gram 모델이 더 뛰어난 경향이 있음  \n",
    "- 학습 속도 면에서는 CBOW 모델이 더 빠름\n",
    "    skip-gram 모델은 손실을 맥락의 수만큼 구해야 하므로 계산 비용이 큼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5760555",
   "metadata": {},
   "source": [
    "__skip-gram 구현__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "112a602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "\n",
    "class SimpleSkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layer = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer1 = SoftmaxWithLoss()\n",
    "        self.loss_layer2 = SoftmaxWithLoss()\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        layers = [self.in_layer, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = self.in_layer.forward(target)\n",
    "        s = self.out_layer.forward(h)\n",
    "        l1 = self.loss_layer1.forward(s, contexts[:, 0])\n",
    "        l2 = self.loss_layer2.forward(s, contexts[:, 1])\n",
    "        loss = l1 + l2\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dl1 = self.loss_layer1.backward(dout)\n",
    "        dl2 = self.loss_layer2.backward(dout)\n",
    "        ds = dl1 + dl2\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399215fc",
   "metadata": {},
   "source": [
    "### 3.5.3 통계 기반 vs. 추론 기반"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1babee",
   "metadata": {},
   "source": [
    "단어의 분산 표현을 갱신해야 할 상황이 생긴다면,  \n",
    "통계 기반 기법은 계산을 처음부터 다시 해야 하는 반면,\n",
    "추론 기반 기법(word2vec)은 학습한 가중치를 초깃값으로 사용해 매개변수를 다시 학습할 수 있음  \n",
    "  \n",
    "두 기법으로 얻는 단어의 분산 표현의 성격은  \n",
    "통계 기반 기법은 주로 단어의 유사성이 인코딩되고,  \n",
    "추론 기반 기법(특히 skip-gram 모델)에서는 단어의 유사성은 물론, 한층 복잡한 단어 사이의 패턴까지 파악되어 인코딩 됨  \n",
    "  \n",
    "하지만, __추론 기반 기법과 통계 기반 기법은 우열을 가릴 수 없음__  \n",
    "  \n",
    "그리고 추론 기반 기법과 통계 기반 기법은 서로 관련이 되어 있음  \n",
    "skip-gram과 (다음 장에서 다루는) 네거티브 샘플링을 이용한 모델은 모두 말뭉치 전체의 동시발생 행렬에 특수한 행렬 분해를 적용한 것과 같음  \n",
    "  \n",
    "word2vec 이후 추론 기반 기법과 통계 기반 기법을 융합한 GloVe 기법도 등장했음  \n",
    "GloVe는 말뭉치 전체의 통계 정보를 손실 함수에 도입해 미니배치를 학습함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
