------------------------------------------------------------------------------------------------  
  
# 밑바닥부터 시작하는 딥러닝3  

<center><img src='https://user-images.githubusercontent.com/86215668/149923993-4f0b248e-bf72-4b8e-9d32-0c11da18d352.jpg' width=200/></center>   

   
------------------------------------------------------------------------------------------------  


   
### 제1고지 미분 자동 계산   
   
1단계 상자로서의 변수   
2단계 변수를 낳는 함수   
3단계 함수 연결   
4단계 수치 미분   
5단계 역전파 이론   
6단계 수동 역전파   
7단계 역전파 자동화   
8단계 재귀에서 반복문으로   
9단계 함수를 더 편리하게   
10단계 테스트   
   
   
### 제2고지 자연스러운 코드로   
    
11단계 가변 길이 인수(순전파 편)   
12단계 가변 길이 인수(개선 편)   
13단계 가변 길이 인수(역전파 편)   
14단계 같은 변수 반복 사용   
15단계 복잡한 계산 그래프(이론 편)   
16단계 복잡한 계산 그래프(구현 편)   
17단계 메모리 관리와 순환 참조   
18단계 메모리 절약 모드   
19단계 변수 사용성 개선   
20단계 연산자 오버로드(1)   
21단계 연산자 오버로드(2)   
22단계 연산자 오버로드(3)   
23단계 패키지로 정리   
24단계 복잡한 함수의 미분   
   
   
### 제3고지 고차 미분 계산   
   
25단계 계산 그래프 시각화(1)   
26단계 계산 그래프 시각화(2)   
27단계 테일러 급수 미분   
28단계 함수 최적화   
29단계 뉴턴 방법으로 푸는 최적화(수동 계산)   
30단계 고차 미분(준비 편)   
31단계 고차 미분(이론 편)   
32단계 고차 미분(구현 편)   
33단계 뉴턴 방법으로 푸는 최적화(자동 계산)   
34단계 sin 함수 고차 미분   
35단계 고차 미분 계산 그래프   
36단계 고차 미분 이외의 용도   
   
   
### 제4고지 신경망 만들기   
   
37단계 텐서를 다루다   
38단계 형상 변환 함수   
39단계 합계 함수   
40단계 브로드캐스트 함수   
41단계 행렬의 곱   
42단계 선형 회귀   
43단계 신경망   
44단계 매개변수를 모아두는 계층   
45단계 계층을 모아두는 계층   
46단계 Optimizer로 수행하는 매개변수 갱신   
47단계 소프트맥스 함수와 교차 엔트로피 오차   
48단계 다중 클래스 분류   
49단계 Dataset 클래스와 전처리   
50단계 미니배치를 뽑아주는 DataLoader   
51단계 MNIST 학습   
   
   
### 제5고지 DeZero의 도전   
   
52단계 GPU 지원   
53단계 모델 저장 및 읽어오기   
54단계 드롭아웃과 테스트 모드   
55단계 CNN 메커니즘(1)   
56단계 CNN 메커니즘(2)   
57단계 conv2d 함수와 pooling 함수   
58단계 대표적인 CNN(VGG16)   
59단계 RNN을 활용한 시계열 데이터 처리   
60단계 LSTM과 데이터 로더   
   
   
### APPENDIX A 인플레이스 연산(14단계 보충)   
   
### APPENDIX B get_item 함수 구현(47단계 보충)   
   
### APPENDIX C 구글 콜랩에서 실행
