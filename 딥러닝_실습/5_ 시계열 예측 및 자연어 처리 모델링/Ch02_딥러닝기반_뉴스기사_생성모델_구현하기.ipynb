{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[문제]딥러닝_기반_뉴스기사_생성_모델_구현하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoHyunjeong/Deep_learning/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5/5_%20%EC%8B%9C%EA%B3%84%EC%97%B4%20%EC%98%88%EC%B8%A1%20%EB%B0%8F%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EB%AA%A8%EB%8D%B8%EB%A7%81/Ch02_%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%80%E1%85%B5%E1%84%87%E1%85%A1%E1%86%AB_%E1%84%82%E1%85%B2%E1%84%89%E1%85%B3%E1%84%80%E1%85%B5%E1%84%89%E1%85%A1_%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF_%E1%84%80%E1%85%AE%E1%84%92%E1%85%A7%E1%86%AB%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6iOz3KxXkGK"
      },
      "source": [
        "# 주제 : 뉴스기사 생성 모델 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jioUvCUIXnhe"
      },
      "source": [
        "이번 튜토리얼에서는 LSTM layer를 활용하여 가짜 뉴스기사 생성기를 만들어 보도록 하겠습니다. 튜토리얼을 진행하면서 **한글 자연어 전처리, 학습을 위한 데이터셋 구축, 그리고 LSTM 텍스트 생성기 모델** 완성을 학습하실 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEsQyK6GErgR"
      },
      "source": [
        "## Step 1. 데이터 불러오기 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeYlgTdfEzV3"
      },
      "source": [
        "### 문제 01. 필요한 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okTryvaYEfVZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KIbKYuU1B1k"
      },
      "source": [
        "### 문제 02. 데이터 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVq4fqx-1B1l"
      },
      "source": [
        "- 한글 뉴스기사 데이터셋을 받습니다.\n",
        "- 한글 뉴스기사 200개의 데이터셋입니다.\n",
        "- IT 관련 기사 데이터셋입니다. IT 관련 뉴스기사를 학습 시키므로, 향후 예측시 IT 관련된 뉴스기사가 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://bit.ly/3n7iHQX')"
      ],
      "metadata": {
        "id": "_-eTRZhcyOxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TSSuSuBeyYAw",
        "outputId": "cbc70518-1d02-436f-822b-10fb56214de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-458843f9-9457-4c04-80ac-4a2cb17560c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“갤럭시S9 20만 원대, 아이폰6S 0원!” 모비톡, 가정의 달 이벤트\\t'갤럭시...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LG 그램’, 100만대 판매기념 한정판 나왔다\\tLG전자가 ‘그램’ 노트북 누적판...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“이게 정말 LG폰이에요?”…G7 씽큐, 기분 좋은 스타트\\t20일 서울 신촌역 앞...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>애플 \"10억불\"vs 삼성 \"2800만불\"…배상액 종지부 '눈앞'\\t삼성-애플 '둥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>삼성전자, 5G 국제 표준 주도한다\\t삼성전자가 5세대(5G) 이동통신 1차 표준 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-458843f9-9457-4c04-80ac-4a2cb17560c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-458843f9-9457-4c04-80ac-4a2cb17560c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-458843f9-9457-4c04-80ac-4a2cb17560c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text\n",
              "0  “갤럭시S9 20만 원대, 아이폰6S 0원!” 모비톡, 가정의 달 이벤트\\t'갤럭시...\n",
              "1  LG 그램’, 100만대 판매기념 한정판 나왔다\\tLG전자가 ‘그램’ 노트북 누적판...\n",
              "2  “이게 정말 LG폰이에요?”…G7 씽큐, 기분 좋은 스타트\\t20일 서울 신촌역 앞...\n",
              "3  애플 \"10억불\"vs 삼성 \"2800만불\"…배상액 종지부 '눈앞'\\t삼성-애플 '둥...\n",
              "4  삼성전자, 5G 국제 표준 주도한다\\t삼성전자가 5세대(5G) 이동통신 1차 표준 ..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # IT 관련 기사 데이터셋 200개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCrwrbMpyfHE",
        "outputId": "1ace466b-4569-4655-b502-176749147952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_BEtxR91B1l"
      },
      "source": [
        "- 전처리를 진행합니다.\n",
        "- re 모듈을 사용하며 regular expression 문법을 사용하여, 한글, 영어, 숫자를 제외한 모든 문자는 제거합니다.\n",
        "- 문장의 끝에는 '#'를 추가하여, 신문 기사의 끝이라는 표기를 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obn2pKB01B1m"
      },
      "source": [
        "def clean_sentence(sentence):\n",
        "    # 한글, 영어, 숫자를 제외한 모든 문자는 제거합니다.\n",
        "    sentence = re.sub(r'[^0-9a-zA-Zㄱ-ㅎㅏ-ㅣ가-힣 ]',r'', sentence)\n",
        "    # 문장의 끝을 표기합니다.\n",
        "    sentence += ' #'\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCLu-i8n1B1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "71014d07-8202-469e-993e-2514ef1c9403"
      },
      "source": [
        "clean_sentence('abcef가나다^^$%@12시 땡^^!??')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcef가나다12시 땡 #'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flSsfU4n3P4p"
      },
      "source": [
        "데이터프레임의 `text`에 `clean_sentece`를 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SytnQm_T1B1n"
      },
      "source": [
        "# 코드를 입력하세요\n",
        "df['text'] = df['text'].apply(clean_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXvn4fH61B1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "968b6b13-3a54-499d-db7a-128dafcb7716"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9aed5c78-da48-4832-8d8b-47dbe14cdc62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>갤럭시S9 20만 원대 아이폰6S 0원 모비톡 가정의 달 이벤트갤럭시노트8 갤럭시S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LG 그램 100만대 판매기념 한정판 나왔다LG전자가 그램 노트북 누적판매 100만...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이게 정말 LG폰이에요G7 씽큐 기분 좋은 스타트20일 서울 신촌역 앞 한 휴대폰 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>애플 10억불vs 삼성 2800만불배상액 종지부 눈앞삼성애플 둥근모서리 디자인특허침...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>삼성전자 5G 국제 표준 주도한다삼성전자가 5세대5G 이동통신 1차 표준 완성을 위...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9aed5c78-da48-4832-8d8b-47dbe14cdc62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9aed5c78-da48-4832-8d8b-47dbe14cdc62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9aed5c78-da48-4832-8d8b-47dbe14cdc62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text\n",
              "0  갤럭시S9 20만 원대 아이폰6S 0원 모비톡 가정의 달 이벤트갤럭시노트8 갤럭시S...\n",
              "1  LG 그램 100만대 판매기념 한정판 나왔다LG전자가 그램 노트북 누적판매 100만...\n",
              "2  이게 정말 LG폰이에요G7 씽큐 기분 좋은 스타트20일 서울 신촌역 앞 한 휴대폰 ...\n",
              "3  애플 10억불vs 삼성 2800만불배상액 종지부 눈앞삼성애플 둥근모서리 디자인특허침...\n",
              "4  삼성전자 5G 국제 표준 주도한다삼성전자가 5세대5G 이동통신 1차 표준 완성을 위..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6MY4qCCEfVm"
      },
      "source": [
        "### 문제 03. 데이터 프레임에서 text만 병합하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyzhalHI1B1o"
      },
      "source": [
        "`text` 변수에 데이터프레임의 담긴 모든 기사를 join하여 병합합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18hZwbSm3gHx"
      },
      "source": [
        "데이터 프레임의 `text`를 모두 병합합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP8-a8VmEfVn"
      },
      "source": [
        "text = ' '.join(df['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HA5IDD01B1o"
      },
      "source": [
        "총 문장의 길이는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCZwAMbwEfVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb39f48-238f-47d8-9b82-103dbc1fab1e"
      },
      "source": [
        "# 총 문장의 길이\n",
        "len(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222853"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwGCGTy41B1p"
      },
      "source": [
        "문장의 500 글자만 출력해 봅니다. 전처리가 완료된 문장이 출려됨을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1pXJ8x8EfVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c73cfcc-1c25-4d10-ed93-a3e89a09b6e6"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "갤럭시S9 20만 원대 아이폰6S 0원 모비톡 가정의 달 이벤트갤럭시노트8 갤럭시S9 갤럭시S8 갤럭시S7 갤럭시S7엣지 아이폰6S 아이폰X 아이폰8 G7 G6 V30 등 다양한 휴대폰 정보가 가득한 스마트폰 공동구매 및 거래 어플 모비톡의 가정의 달 이벤트가 화제다모비톡 단독으로 진행되는 5월 가정의 달 이벤트에 이용자들의 폭발적인 반응이 나타나고 있다 고가의 인기 스마트폰을 파격가에 판매한다는 사실에 각종 커뮤니티와 카페를 중심으로 화제를 모으고 있는 것 특히 갤럭시S9를 20만 원대 아이폰6S는 0원 할부원금을 앞세워 안드로이드와iOS인기 기종을 중심으로 큰 폭의 할인을 펼치는게 주된 요인으로 꼽힌다 모비톡 관계자에 따르면 고마운 사람들에게 감사한 마음을 담아 선물할 기회가 많은 5월 가정의 달을 맞아 공격적인 마케팅을 진행하고 있다며 독보적인 통신비 절약 어플로서 앞으로도 최선을 다하겠다고 밝혔다이 밖에도 모비톡은 갤럭시노트8 V30 구매 시 닌텐도 스위치를 증정한다 스마트폰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGO7N_2-EfVp"
      },
      "source": [
        "### 문제 04. 텍스트 기본 전처리 (preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6TT6-Rf1B1q"
      },
      "source": [
        "단어 사전을 만듭니다. 먼저, 중복되는 모든 글자를 제외하기 위하여 **set를 활용**합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMzJc2WnEfVq"
      },
      "source": [
        "vocab = sorted(set(text)) # 고유 글자만 추출"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfG2huqb5E-H",
        "outputId": "c70feb14-d2ab-465e-f428-2574782583f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " '#',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b55h8e2z1B1q"
      },
      "source": [
        "고유 글자의 숫자를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPcVmJDTEfVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbefb2c7-f274-4be6-9e5b-d6cf76d587d3"
      },
      "source": [
        "# 고유 글자의 숫자 확인\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1172"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS_8rjbg1B1r"
      },
      "source": [
        "'?'라는 글자는 `vocab` 변수에 없는 글자임을 확인할 수 있습니다. 전처리 단계에서 제거했기 때문에 당연히 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFblnqXl1B1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6473fbae-fdc5-4136-caf0-dbb00b7e09c3"
      },
      "source": [
        "'?' in vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLg7pjQi1B1r"
      },
      "source": [
        "**'?'** 글자를 추가해 주는데, 추후 사용자의 입력이 없는 글자일 때는 ?로 입력하기 위함입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmFA3igN1B1s"
      },
      "source": [
        "vocab.append('?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'?' in vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LOFhY3q5Z3C",
        "outputId": "8408ff66-3901-46c0-a132-ebdb179cad71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGVhTYP2EfVr"
      },
      "source": [
        "### 문제 05. 데이터 형태 변환하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wVsb0Ob1B1s"
      },
      "source": [
        "`char2idx`는 글자를 index로 변환하는 역할이고, `idx2char`는 index를 글자로 역변환하는 목적입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFIzFLfAEfVs"
      },
      "source": [
        "# 글자 -> index로 변환\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maJ5n0MM58IA",
        "outputId": "adc60b93-6a8a-4281-9f0d-39a54c1cc6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(' ', 0), ('#', 1), ('0', 2), ('1', 3), ('2', 4), ('3', 5), ('4', 6), ('5', 7), ('6', 8), ('7', 9), ('8', 10), ('9', 11), ('A', 12), ('B', 13), ('C', 14), ('D', 15), ('E', 16), ('F', 17), ('G', 18), ('H', 19), ('I', 20), ('J', 21), ('K', 22), ('L', 23), ('M', 24), ('N', 25), ('O', 26), ('P', 27), ('Q', 28), ('R', 29), ('S', 30), ('T', 31), ('U', 32), ('V', 33), ('W', 34), ('X', 35), ('Y', 36), ('Z', 37), ('a', 38), ('b', 39), ('c', 40), ('d', 41), ('e', 42), ('f', 43), ('g', 44), ('h', 45), ('i', 46), ('j', 47), ('k', 48), ('l', 49), ('m', 50), ('n', 51), ('o', 52), ('p', 53), ('r', 54), ('s', 55), ('t', 56), ('u', 57), ('v', 58), ('w', 59), ('x', 60), ('y', 61), ('z', 62), ('가', 63), ('각', 64), ('간', 65), ('갈', 66), ('감', 67), ('갑', 68), ('값', 69), ('갔', 70), ('강', 71), ('갖', 72), ('같', 73), ('개', 74), ('객', 75), ('갤', 76), ('갯', 77), ('갱', 78), ('거', 79), ('걱', 80), ('건', 81), ('걷', 82), ('걸', 83), ('검', 84), ('겁', 85), ('것', 86), ('겉', 87), ('겋', 88), ('게', 89), ('겐', 90), ('겔', 91), ('겠', 92), ('겨', 93), ('격', 94), ('겪', 95), ('견', 96), ('결', 97), ('겸', 98), ('겹', 99), ('겼', 100), ('경', 101), ('곁', 102), ('계', 103), ('고', 104), ('곡', 105), ('곤', 106), ('곧', 107), ('골', 108), ('곰', 109), ('곳', 110), ('공', 111), ('과', 112), ('곽', 113), ('관', 114), ('괄', 115), ('광', 116), ('괜', 117), ('괴', 118), ('굉', 119), ('교', 120), ('구', 121), ('국', 122), ('군', 123), ('굳', 124), ('굴', 125), ('굵', 126), ('굼', 127), ('굽', 128), ('궁', 129), ('권', 130), ('궤', 131), ('귀', 132), ('규', 133), ('균', 134), ('그', 135), ('극', 136), ('근', 137), ('글', 138), ('긁', 139), ('금', 140), ('급', 141), ('긍', 142), ('기', 143), ('긴', 144), ('길', 145), ('김', 146), ('깁', 147), ('깃', 148), ('깊', 149), ('까', 150), ('깎', 151), ('깔', 152), ('깜', 153), ('깝', 154), ('깡', 155), ('깥', 156), ('깨', 157), ('꺼', 158), ('껍', 159), ('껏', 160), ('껑', 161), ('께', 162), ('껴', 163), ('꼬', 164), ('꼭', 165), ('꼴', 166), ('꼼', 167), ('꼽', 168), ('꽂', 169), ('꽃', 170), ('꽉', 171), ('꽤', 172), ('꾀', 173), ('꾸', 174), ('꾼', 175), ('꿀', 176), ('꿈', 177), ('꿔', 178), ('꿨', 179), ('뀌', 180), ('뀐', 181), ('뀔', 182), ('끄', 183), ('끈', 184), ('끊', 185), ('끌', 186), ('끓', 187), ('끔', 188), ('끗', 189), ('끝', 190), ('끼', 191), ('낄', 192), ('낌', 193), ('나', 194), ('낙', 195), ('낚', 196), ('난', 197), ('날', 198), ('남', 199), ('납', 200), ('낫', 201), ('났', 202), ('낭', 203), ('낮', 204), ('낯', 205), ('낳', 206), ('내', 207), ('낸', 208), ('낼', 209), ('냄', 210), ('냅', 211), ('냈', 212), ('냐', 213), ('냠', 214), ('냥', 215), ('너', 216), ('넋', 217), ('널', 218), ('넓', 219), ('넘', 220), ('넣', 221), ('네', 222), ('넥', 223), ('넵', 224), ('넷', 225), ('녀', 226), ('년', 227), ('념', 228), ('녔', 229), ('녕', 230), ('노', 231), ('녹', 232), ('논', 233), ('놀', 234), ('놈', 235), ('농', 236), ('높', 237), ('놓', 238), ('놔', 239), ('놨', 240), ('뇌', 241), ('누', 242), ('눈', 243), ('눌', 244), ('눔', 245), ('눠', 246), ('뉘', 247), ('뉜', 248), ('뉴', 249), ('늄', 250), ('느', 251), ('는', 252), ('늘', 253), ('늙', 254), ('늠', 255), ('능', 256), ('늦', 257), ('늪', 258), ('니', 259), ('닉', 260), ('닌', 261), ('닐', 262), ('님', 263), ('닙', 264), ('닝', 265), ('다', 266), ('닥', 267), ('닦', 268), ('단', 269), ('달', 270), ('닭', 271), ('닮', 272), ('담', 273), ('답', 274), ('닷', 275), ('당', 276), ('대', 277), ('댄', 278), ('댈', 279), ('댑', 280), ('댓', 281), ('더', 282), ('덕', 283), ('던', 284), ('덜', 285), ('덤', 286), ('덧', 287), ('덩', 288), ('덮', 289), ('데', 290), ('덴', 291), ('델', 292), ('뎁', 293), ('뎠', 294), ('도', 295), ('독', 296), ('돈', 297), ('돋', 298), ('돌', 299), ('돔', 300), ('돕', 301), ('동', 302), ('돼', 303), ('됐', 304), ('되', 305), ('된', 306), ('될', 307), ('됨', 308), ('됩', 309), ('두', 310), ('둑', 311), ('둔', 312), ('둘', 313), ('둡', 314), ('둥', 315), ('뒀', 316), ('뒤', 317), ('뒷', 318), ('듀', 319), ('듈', 320), ('드', 321), ('득', 322), ('든', 323), ('듣', 324), ('들', 325), ('듬', 326), ('듭', 327), ('듯', 328), ('등', 329), ('디', 330), ('딕', 331), ('딘', 332), ('딛', 333), ('딜', 334), ('딥', 335), ('딧', 336), ('딩', 337), ('딪', 338), ('따', 339), ('딱', 340), ('딴', 341), ('딸', 342), ('땀', 343), ('땅', 344), ('때', 345), ('땐', 346), ('땠', 347), ('떠', 348), ('떤', 349), ('떨', 350), ('떻', 351), ('떼', 352), ('뗀', 353), ('뗄', 354), ('또', 355), ('똑', 356), ('똥', 357), ('뚜', 358), ('뚝', 359), ('뚫', 360), ('뚱', 361), ('뛰', 362), ('뜨', 363), ('뜩', 364), ('뜯', 365), ('뜰', 366), ('뜸', 367), ('뜻', 368), ('띄', 369), ('띔', 370), ('띕', 371), ('띠', 372), ('띤', 373), ('띨', 374), ('라', 375), ('락', 376), ('란', 377), ('랄', 378), ('람', 379), ('랍', 380), ('랐', 381), ('랑', 382), ('래', 383), ('랙', 384), ('랜', 385), ('램', 386), ('랩', 387), ('랫', 388), ('랬', 389), ('랴', 390), ('략', 391), ('량', 392), ('러', 393), ('럭', 394), ('런', 395), ('럴', 396), ('럼', 397), ('럽', 398), ('럿', 399), ('렀', 400), ('렁', 401), ('렇', 402), ('레', 403), ('렉', 404), ('렌', 405), ('렐', 406), ('렛', 407), ('려', 408), ('력', 409), ('련', 410), ('렬', 411), ('렴', 412), ('렵', 413), ('렷', 414), ('렸', 415), ('령', 416), ('례', 417), ('로', 418), ('록', 419), ('론', 420), ('롤', 421), ('롬', 422), ('롭', 423), ('롯', 424), ('롱', 425), ('뢰', 426), ('료', 427), ('룡', 428), ('루', 429), ('룩', 430), ('룬', 431), ('룰', 432), ('룸', 433), ('룹', 434), ('뤄', 435), ('뤘', 436), ('류', 437), ('륙', 438), ('률', 439), ('륨', 440), ('르', 441), ('른', 442), ('를', 443), ('름', 444), ('릅', 445), ('릎', 446), ('리', 447), ('릭', 448), ('린', 449), ('릴', 450), ('림', 451), ('립', 452), ('릿', 453), ('링', 454), ('마', 455), ('막', 456), ('만', 457), ('많', 458), ('말', 459), ('맑', 460), ('맘', 461), ('맛', 462), ('망', 463), ('맞', 464), ('맡', 465), ('매', 466), ('맥', 467), ('맨', 468), ('맵', 469), ('맷', 470), ('맹', 471), ('맺', 472), ('머', 473), ('먹', 474), ('먼', 475), ('멀', 476), ('멈', 477), ('메', 478), ('멕', 479), ('멘', 480), ('멜', 481), ('멤', 482), ('며', 483), ('면', 484), ('멸', 485), ('명', 486), ('몇', 487), ('모', 488), ('목', 489), ('몫', 490), ('몬', 491), ('몰', 492), ('몸', 493), ('못', 494), ('몽', 495), ('묘', 496), ('무', 497), ('묶', 498), ('문', 499), ('묻', 500), ('물', 501), ('뭉', 502), ('뭐', 503), ('뭔', 504), ('뮤', 505), ('뮬', 506), ('므', 507), ('미', 508), ('믹', 509), ('민', 510), ('믿', 511), ('밀', 512), ('밋', 513), ('밍', 514), ('및', 515), ('밑', 516), ('바', 517), ('박', 518), ('밖', 519), ('반', 520), ('받', 521), ('발', 522), ('밝', 523), ('밟', 524), ('밤', 525), ('밥', 526), ('방', 527), ('배', 528), ('백', 529), ('밴', 530), ('밸', 531), ('뱀', 532), ('뱅', 533), ('버', 534), ('벅', 535), ('번', 536), ('벌', 537), ('범', 538), ('법', 539), ('벗', 540), ('베', 541), ('벤', 542), ('벨', 543), ('벳', 544), ('벵', 545), ('벼', 546), ('벽', 547), ('변', 548), ('별', 549), ('볍', 550), ('볏', 551), ('병', 552), ('보', 553), ('복', 554), ('본', 555), ('볼', 556), ('봅', 557), ('봇', 558), ('봉', 559), ('봐', 560), ('봤', 561), ('부', 562), ('북', 563), ('분', 564), ('불', 565), ('붉', 566), ('붐', 567), ('붕', 568), ('붙', 569), ('뷰', 570), ('브', 571), ('블', 572), ('비', 573), ('빅', 574), ('빈', 575), ('빌', 576), ('빗', 577), ('빙', 578), ('빚', 579), ('빛', 580), ('빠', 581), ('빨', 582), ('빼', 583), ('빽', 584), ('뺀', 585), ('뺏', 586), ('뻐', 587), ('뻔', 588), ('뻘', 589), ('뻥', 590), ('뼈', 591), ('뽐', 592), ('뿌', 593), ('뿐', 594), ('뿜', 595), ('쁘', 596), ('쁜', 597), ('삐', 598), ('사', 599), ('삭', 600), ('산', 601), ('살', 602), ('삶', 603), ('삼', 604), ('샀', 605), ('상', 606), ('새', 607), ('색', 608), ('샌', 609), ('샛', 610), ('생', 611), ('샤', 612), ('샴', 613), ('샵', 614), ('샹', 615), ('서', 616), ('석', 617), ('섞', 618), ('선', 619), ('설', 620), ('섬', 621), ('섭', 622), ('섯', 623), ('섰', 624), ('성', 625), ('세', 626), ('섹', 627), ('센', 628), ('셀', 629), ('셈', 630), ('셉', 631), ('셋', 632), ('셔', 633), ('션', 634), ('셜', 635), ('셰', 636), ('소', 637), ('속', 638), ('손', 639), ('솔', 640), ('솜', 641), ('솟', 642), ('송', 643), ('쇄', 644), ('쇼', 645), ('숍', 646), ('수', 647), ('숙', 648), ('순', 649), ('술', 650), ('숨', 651), ('숫', 652), ('숭', 653), ('숱', 654), ('숴', 655), ('쉬', 656), ('쉰', 657), ('쉽', 658), ('슈', 659), ('스', 660), ('슨', 661), ('슬', 662), ('습', 663), ('슷', 664), ('승', 665), ('시', 666), ('식', 667), ('신', 668), ('싣', 669), ('실', 670), ('싫', 671), ('심', 672), ('십', 673), ('싱', 674), ('싶', 675), ('싸', 676), ('싼', 677), ('쌀', 678), ('쌍', 679), ('쌓', 680), ('써', 681), ('썩', 682), ('썬', 683), ('썰', 684), ('쏘', 685), ('쏟', 686), ('쏠', 687), ('쏴', 688), ('쓰', 689), ('쓴', 690), ('쓸', 691), ('씀', 692), ('씨', 693), ('씩', 694), ('씬', 695), ('씻', 696), ('씽', 697), ('아', 698), ('악', 699), ('안', 700), ('앉', 701), ('않', 702), ('알', 703), ('암', 704), ('압', 705), ('앗', 706), ('았', 707), ('앙', 708), ('앞', 709), ('애', 710), ('액', 711), ('앤', 712), ('앨', 713), ('앱', 714), ('앵', 715), ('야', 716), ('약', 717), ('얀', 718), ('얇', 719), ('양', 720), ('얘', 721), ('어', 722), ('억', 723), ('언', 724), ('얻', 725), ('얼', 726), ('얽', 727), ('엄', 728), ('업', 729), ('없', 730), ('엇', 731), ('었', 732), ('엉', 733), ('엎', 734), ('에', 735), ('엑', 736), ('엔', 737), ('엘', 738), ('엠', 739), ('엣', 740), ('여', 741), ('역', 742), ('연', 743), ('열', 744), ('염', 745), ('엿', 746), ('였', 747), ('영', 748), ('옅', 749), ('옆', 750), ('예', 751), ('옛', 752), ('오', 753), ('옥', 754), ('온', 755), ('올', 756), ('옮', 757), ('옵', 758), ('옷', 759), ('옹', 760), ('와', 761), ('완', 762), ('왓', 763), ('왔', 764), ('왕', 765), ('왜', 766), ('외', 767), ('요', 768), ('욕', 769), ('용', 770), ('우', 771), ('욱', 772), ('운', 773), ('울', 774), ('움', 775), ('웃', 776), ('웅', 777), ('워', 778), ('웍', 779), ('원', 780), ('월', 781), ('웠', 782), ('웨', 783), ('웹', 784), ('위', 785), ('윈', 786), ('윌', 787), ('유', 788), ('육', 789), ('윤', 790), ('율', 791), ('융', 792), ('으', 793), ('은', 794), ('을', 795), ('음', 796), ('응', 797), ('의', 798), ('이', 799), ('익', 800), ('인', 801), ('일', 802), ('읽', 803), ('잃', 804), ('임', 805), ('입', 806), ('잇', 807), ('있', 808), ('잉', 809), ('자', 810), ('작', 811), ('잔', 812), ('잖', 813), ('잘', 814), ('잠', 815), ('잡', 816), ('장', 817), ('잦', 818), ('재', 819), ('잭', 820), ('잰', 821), ('잼', 822), ('잽', 823), ('쟁', 824), ('저', 825), ('적', 826), ('전', 827), ('절', 828), ('젊', 829), ('점', 830), ('접', 831), ('젓', 832), ('정', 833), ('제', 834), ('젝', 835), ('젠', 836), ('젤', 837), ('젯', 838), ('져', 839), ('졌', 840), ('조', 841), ('족', 842), ('존', 843), ('졸', 844), ('좀', 845), ('좁', 846), ('종', 847), ('좋', 848), ('좌', 849), ('죄', 850), ('죠', 851), ('주', 852), ('죽', 853), ('준', 854), ('줄', 855), ('줌', 856), ('줍', 857), ('중', 858), ('줘', 859), ('줬', 860), ('쥐', 861), ('쥔', 862), ('쥬', 863), ('즈', 864), ('즉', 865), ('즌', 866), ('즐', 867), ('즘', 868), ('증', 869), ('지', 870), ('직', 871), ('진', 872), ('질', 873), ('짐', 874), ('집', 875), ('짓', 876), ('징', 877), ('짙', 878), ('짜', 879), ('짝', 880), ('짧', 881), ('짬', 882), ('짱', 883), ('째', 884), ('쨌', 885), ('쩍', 886), ('쩡', 887), ('쪼', 888), ('쪽', 889), ('쭉', 890), ('쯤', 891), ('찌', 892), ('찍', 893), ('찢', 894), ('차', 895), ('착', 896), ('찬', 897), ('찮', 898), ('찰', 899), ('참', 900), ('창', 901), ('찾', 902), ('채', 903), ('책', 904), ('챔', 905), ('챙', 906), ('처', 907), ('척', 908), ('천', 909), ('철', 910), ('첨', 911), ('첫', 912), ('청', 913), ('체', 914), ('첸', 915), ('첼', 916), ('쳉', 917), ('쳐', 918), ('쳤', 919), ('초', 920), ('촉', 921), ('촌', 922), ('촘', 923), ('총', 924), ('촬', 925), ('최', 926), ('추', 927), ('축', 928), ('춘', 929), ('출', 930), ('춤', 931), ('충', 932), ('춰', 933), ('췄', 934), ('취', 935), ('츠', 936), ('측', 937), ('층', 938), ('치', 939), ('칙', 940), ('친', 941), ('칠', 942), ('침', 943), ('칩', 944), ('칫', 945), ('칭', 946), ('카', 947), ('칸', 948), ('칼', 949), ('캐', 950), ('캘', 951), ('캠', 952), ('캣', 953), ('커', 954), ('컨', 955), ('컫', 956), ('컬', 957), ('컴', 958), ('컵', 959), ('컷', 960), ('컸', 961), ('케', 962), ('켄', 963), ('켈', 964), ('켓', 965), ('켜', 966), ('켠', 967), ('켰', 968), ('코', 969), ('콘', 970), ('콜', 971), ('콤', 972), ('콥', 973), ('콧', 974), ('콩', 975), ('쾌', 976), ('쿠', 977), ('쿼', 978), ('퀀', 979), ('퀄', 980), ('퀘', 981), ('퀴', 982), ('큐', 983), ('큘', 984), ('크', 985), ('큰', 986), ('클', 987), ('큼', 988), ('키', 989), ('킨', 990), ('킬', 991), ('킴', 992), ('킷', 993), ('킹', 994), ('타', 995), ('탁', 996), ('탄', 997), ('탈', 998), ('탐', 999), ('탑', 1000), ('탓', 1001), ('탕', 1002), ('태', 1003), ('택', 1004), ('탠', 1005), ('탬', 1006), ('탭', 1007), ('탱', 1008), ('터', 1009), ('턱', 1010), ('턴', 1011), ('털', 1012), ('텀', 1013), ('텃', 1014), ('테', 1015), ('텍', 1016), ('텐', 1017), ('텔', 1018), ('템', 1019), ('텝', 1020), ('톈', 1021), ('토', 1022), ('톡', 1023), ('톤', 1024), ('톱', 1025), ('통', 1026), ('퇴', 1027), ('투', 1028), ('툰', 1029), ('툴', 1030), ('툼', 1031), ('퉈', 1032), ('튀', 1033), ('튜', 1034), ('튬', 1035), ('트', 1036), ('특', 1037), ('튼', 1038), ('틀', 1039), ('틈', 1040), ('티', 1041), ('틱', 1042), ('틴', 1043), ('틸', 1044), ('팀', 1045), ('팅', 1046), ('파', 1047), ('팍', 1048), ('팎', 1049), ('판', 1050), ('팔', 1051), ('팝', 1052), ('팟', 1053), ('팡', 1054), ('패', 1055), ('팩', 1056), ('팬', 1057), ('팰', 1058), ('팹', 1059), ('팽', 1060), ('퍼', 1061), ('펀', 1062), ('펄', 1063), ('펌', 1064), ('펍', 1065), ('펑', 1066), ('페', 1067), ('펙', 1068), ('펜', 1069), ('펠', 1070), ('펴', 1071), ('편', 1072), ('펼', 1073), ('평', 1074), ('폐', 1075), ('포', 1076), ('폭', 1077), ('폰', 1078), ('폴', 1079), ('폼', 1080), ('퐁', 1081), ('표', 1082), ('푸', 1083), ('푹', 1084), ('풀', 1085), ('품', 1086), ('풍', 1087), ('퓨', 1088), ('퓰', 1089), ('프', 1090), ('픈', 1091), ('플', 1092), ('피', 1093), ('픽', 1094), ('핀', 1095), ('필', 1096), ('핑', 1097), ('하', 1098), ('학', 1099), ('한', 1100), ('할', 1101), ('함', 1102), ('합', 1103), ('핫', 1104), ('항', 1105), ('해', 1106), ('핵', 1107), ('핸', 1108), ('햄', 1109), ('햇', 1110), ('했', 1111), ('행', 1112), ('향', 1113), ('허', 1114), ('헌', 1115), ('헐', 1116), ('험', 1117), ('헝', 1118), ('헤', 1119), ('헥', 1120), ('헨', 1121), ('헬', 1122), ('헵', 1123), ('혀', 1124), ('혁', 1125), ('현', 1126), ('혈', 1127), ('혐', 1128), ('협', 1129), ('혔', 1130), ('형', 1131), ('혜', 1132), ('호', 1133), ('혹', 1134), ('혼', 1135), ('홀', 1136), ('홈', 1137), ('홍', 1138), ('화', 1139), ('확', 1140), ('환', 1141), ('활', 1142), ('황', 1143), ('회', 1144), ('획', 1145), ('효', 1146), ('후', 1147), ('훈', 1148), ('훌', 1149), ('훙', 1150), ('훨', 1151), ('훼', 1152), ('휘', 1153), ('휩', 1154), ('휴', 1155), ('흉', 1156), ('흐', 1157), ('흑', 1158), ('흔', 1159), ('흘', 1160), ('흠', 1161), ('흡', 1162), ('흥', 1163), ('흩', 1164), ('희', 1165), ('흰', 1166), ('히', 1167), ('힌', 1168), ('힐', 1169), ('힘', 1170), ('힙', 1171), ('?', 1172)])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Dlmyk8EfVs"
      },
      "source": [
        "# index -> 글자로 변환\n",
        "idx2char = np.array(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2char[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypMa_cwV5_VS",
        "outputId": "b27f4706-25d8-47c4-ce8d-9f8041beead6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' ', '#', '0', '1', '2', '3', '4', '5', '6', '7'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx['#']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpw2Cp8A6W0i",
        "outputId": "63414b52-8407-47da-a8c5-c24c6aa5a358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2char[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-fzfD0wu6SdZ",
        "outputId": "fc4fe9e5-acb0-4132-d2f6-b1b65f4b7c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'#'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTf9OO4vEfVs"
      },
      "source": [
        "## STEP 2. 단어 사전 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TOzDoEtEfVt"
      },
      "source": [
        "### 문제 06. for문을 사용해 문서를 연속된 수치형 값들로 치환합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr_Hu7_m4ewx"
      },
      "source": [
        "문장을 `char2idx`를 활용하여 텍스트를 int로 변환합니다. (sequence 변환)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8_Bp_U2EfVt"
      },
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzNMj8EKEfVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd118d5-f340-4cc9-f977-72918f21fda7"
      },
      "source": [
        "text_as_int"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 76, 394, 666, ..., 266,   0,   1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuVELDFxEfVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9eaf7d-176c-4fba-9c21-dc243da7dc69"
      },
      "source": [
        "len(text_as_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222853"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVfWkUnHEfVu"
      },
      "source": [
        "### 문제 07. 변환된 부분을 확인합니다. (처음 5개)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWXtqehA1B1u"
      },
      "source": [
        "**원문의 출력**은 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPXOEWvGEfVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e5e06d71-d7e9-434f-8961-772afb6b9270"
      },
      "source": [
        "# 원문\n",
        "text[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'갤럭시S9'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct5ijCC-1B1u"
      },
      "source": [
        "**sequence로 변환**된 출력은 다음과 같습니다. 한글자씩 변환된 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR0foxBa1B1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13a983c-a779-4981-8ed4-d21475cfe9e5"
      },
      "source": [
        "char2idx['갤'], char2idx['럭'], char2idx['시'], char2idx['S'], char2idx['9']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 394, 666, 30, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC7RBq9aEfVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e0d284-404f-4ff2-f211-6221d4f03b0c"
      },
      "source": [
        "# 변환된 sequence\n",
        "text_as_int[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 76, 394, 666,  30,  11])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmM0XnCKYpen"
      },
      "source": [
        "### 문제 08. 각각의 단어사전으로 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY5B2EKyEfVu",
        "outputId": "1a6c7243-fdc7-4bfc-d51d-03e69b61bbaa"
      },
      "source": [
        "char2idx[' '], char2idx['회'], char2idx['사'], char2idx['#'], char2idx['?']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1144, 599, 1, 1172)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG422zZJajrQ"
      },
      "source": [
        "## Step 3. 데이터셋 생성 및 EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4RB9pRmEfVv"
      },
      "source": [
        "### 문제 09. X, Y 데이터셋 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예시  \n",
        "\n",
        "<center>many to many model  \n",
        "\n",
        "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
        "\n",
        "window size 5인 경우</center>  \n",
        "\n",
        "  \n",
        "학습 데이터 | 예측 데이터\n",
        "---------|----------\n",
        "[0,1,2,3,4]|[1,2,3,4,5]\n",
        "[1,2,3,4,5]|[2,3,4,5,6]\n",
        "[2,3,4,5,6]|[3,4,5,6,7]\n",
        "[3,4,5,6,7]|[4,5,6,7,8]"
      ],
      "metadata": {
        "id": "Vs_qnNcP80V2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxLyqzaLEfVv"
      },
      "source": [
        "# 하이퍼파라미터\n",
        "# 단일 입력에 대해 원하는 문장의 최대 길이를 지정합니다.\n",
        "window_size = 100\n",
        "shuffle_buffer = 1000\n",
        "batch_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 만드는 함수를 구현해봅니다.\n",
        "def windowed_dataset(series, window_size, shuffle_buffer, batch_size): # 윈도우로 구성된 데이터셋\n",
        "    series = tf.expand_dims(series, -1) # 차원 추가\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series) # numpy array를 tensor로 변환\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True) # window size -> x, y 포함\n",
        "    ds = ds.flat_map(lambda x: x.batch(window_size + 1)) # 결과값을 flat해서 줌 ex) [[1][2][3]] -> [1, 2, 3] / 배치구성은 window_size(window_size + 1)로 통일\n",
        "    ds = ds.shuffle(shuffle_buffer) # buffer size의 후보군들 중에서 사용할 데이터 먼저 랜덤으로 뽑아감. 뽑고 남은 부분을 채우고 또 랜덤으로 뽑아감을 반복\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:])) # x, y 분할\n",
        "    return ds.batch(batch_size).prefetch(1).repeat() # 배치 구성 / prefetch(1) -> 1개의 배치를 더 만들어놔서 병목현상이 생기지 않도록 함"
      ],
      "metadata": {
        "id": "r1nYU3-w_X6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQGsUYY-EfVv"
      },
      "source": [
        "train_data = windowed_dataset(np.array(text_as_int), window_size, shuffle_buffer, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBFDZ0dmY7Qg"
      },
      "source": [
        "### 문제 10. 어휘 사전의 크기를 간단히 살펴봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_nx-mWnEfVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c78aa7-0847-459f-b625-5d822f1d8e4e"
      },
      "source": [
        "# 문자로 된 어휘 사전의 크기\n",
        "# vocab_size에 vocab의 길이를 대입합니다.\n",
        "vocab_size = len(vocab)\n",
        "vocab_size # 고유글자의 수"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1173"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D6SKQowaojm"
      },
      "source": [
        "## Step 4.Sequential 모델 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vPMeRLGZCQI"
      },
      "source": [
        "### 문제 11. keras를 활용해 Sequential 모델을 구현합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYubFDhe1B1x"
      },
      "source": [
        "hyperparameter를 다음과 같이 설정합니다. 데이터셋에 따라서 언제든 변경하면서 더 좋은 성능을 내는 hyperparameter 값을 찾을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgQYOBoeEfVw"
      },
      "source": [
        "# 하이퍼파라미터\n",
        "# 임베딩 차원\n",
        "embedding_dim = 256 \n",
        "# RNN 유닛(unit) 개수\n",
        "rnn_units = 1024 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2akdn8nVEfVw",
        "scrolled": true
      },
      "source": [
        "# 학습용 모델\n",
        "model = tf.keras.Sequential([\n",
        "    # Embedding Layer\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=window_size), # input_length : 한 문장의 최대 길이\n",
        "    # LSTM Layer (returen_sequences=True, initializer는 glorot_uniform으로 설정)\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                         return_sequences=True, # many to many 모델\n",
        "                         recurrent_initializer='glorot_uniform'),\n",
        "    # Dense의 unit은 vocab_size로 설정\n",
        "    tf.keras.layers.Dense(vocab_size, activation='softmax')    \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mpkPQjxEfVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56c2026-37c6-4ea9-ed7a-455b19020f99"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 256)          300288    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 1024)         5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100, 1173)         1202325   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,749,589\n",
            "Trainable params: 6,749,589\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pds1usgEfVx"
      },
      "source": [
        "### 문제 12. 모델을 저장할 Checkpoint를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUTI9EshEfVx"
      },
      "source": [
        "checkpoint_path = 'sample-checkpoint.h5' # model 저장\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_best_only=True,\n",
        "    monitor='loss',\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5zhp3vmZU1l"
      },
      "source": [
        "### 문제 14. 모델을 컴파일합니다. 옵티마이저는 adam을 사용해주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOViuJyyEfVx"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # sparse\n",
        "              metrics=['acc']\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0VrJdeDZiPn"
      },
      "source": [
        "### 문제 15. steps_per_epoch를 지정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSL8bTGj1B1y"
      },
      "source": [
        "**steps_per_epoch에 대하여**\n",
        "\n",
        "\n",
        "1. fit()함수를 취할 때, 버젼별로 `steps_per_epoch`(training set에 대한 step)과, `validation_steps`(validation set에 대한 step)의 값이 지정되어 있지 않으면 학습이 안되는 현상이 있습니다.\n",
        "\n",
        "2. 따라서, 위의 2가지 파라미터에 값을 넣어 주면 정상적으로 학습하기 시작합니다.\n",
        "\n",
        "3. `steps_per_epoch`은 __weight를 업데이트 하는 주기__ 입니다. 보통은 training 데이터셋의 총 갯수가 1000개 일 때, `batch_size`가 128개 이면, **training dataset 갯수**/**배치사이즈**만큼 weight를 업데이트 합니다. 쉽게 말해서, __batch가 다 돌때마다 weight를 업데이트 합니다.__\n",
        "\n",
        "4. 딱 떨어지면 그대로 사용. 그렇지 않은 경우, 예를 들어 1000개 이미지 / 128 하면 7.8125 (소수점)이 나오기 때문에 1000 // 128 해주면 해결되는데요. 몫을 구하면 7이나오기 때문에 +1을 해주면 됩니다.(올림) 즉, 마지막 batch는 128개보다 적겠네요. 그래도 weight 업데이트 해줘야하니깐 최종 `steps_per_epoch`은 8이 맞습니다.\n",
        "\n",
        "5. validation_steps는 validation_generator의 weight 업데이트 숫자입니다. 4번에서 구한 `steps_per_epoch`과 동일한 원리로 validation dataset을 기준으로 계산하면 됩니다.\n",
        "\n",
        "6. validation data는 500개고, batch_size가 이번에는 32개면 500 // 32 + 1 = 16 이 되겠네요.\n",
        "\n",
        "7. 하지만, 이런 고민 모두다 필요없이 `steps_per_epoch` = len(training_generator)\n",
        "`validation_steps` = len(validation_generator) 로 설정해주면 초 간단합니다^^"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TirOJgNMEfVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4aaad00-23f2-4257-f178-66347183c4f2"
      },
      "source": [
        "steps_per_epoch = (len(text_as_int) - window_size) // (batch_size) + 1 # 마지막은 학습에 포함되지 않기 때문에 window_size만큼 빼줌\n",
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1741"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm95kBbfZlf0"
      },
      "source": [
        "### 문제 16. 모델을 학습하고 callbacks로 앞에서 만든 체크포인트를 할당해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8nTDb2xEfVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5d6dbc-8993-452c-fc4d-114faa53ab94"
      },
      "source": [
        "model.fit(train_data, \n",
        "          epochs=30,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          callbacks=[checkpointer],\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 2.8584 - acc: 0.4703\n",
            "Epoch 1: loss improved from inf to 2.85813, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 181s 99ms/step - loss: 2.8581 - acc: 0.4704\n",
            "Epoch 2/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 1.8870 - acc: 0.6352\n",
            "Epoch 2: loss improved from 2.85813 to 1.88682, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 170s 98ms/step - loss: 1.8868 - acc: 0.6352\n",
            "Epoch 3/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 1.5408 - acc: 0.6834\n",
            "Epoch 3: loss improved from 1.88682 to 1.54059, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 170s 98ms/step - loss: 1.5406 - acc: 0.6834\n",
            "Epoch 4/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 1.1993 - acc: 0.7390\n",
            "Epoch 4: loss improved from 1.54059 to 1.19912, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 170s 98ms/step - loss: 1.1991 - acc: 0.7390\n",
            "Epoch 5/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.9221 - acc: 0.7893\n",
            "Epoch 5: loss improved from 1.19912 to 0.92203, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 171s 98ms/step - loss: 0.9220 - acc: 0.7893\n",
            "Epoch 6/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.7116 - acc: 0.8321\n",
            "Epoch 6: loss improved from 0.92203 to 0.71157, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 171s 98ms/step - loss: 0.7116 - acc: 0.8321\n",
            "Epoch 7/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.5501 - acc: 0.8686\n",
            "Epoch 7: loss improved from 0.71157 to 0.55006, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 169s 97ms/step - loss: 0.5501 - acc: 0.8686\n",
            "Epoch 8/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8955\n",
            "Epoch 8: loss improved from 0.55006 to 0.43877, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 169s 97ms/step - loss: 0.4388 - acc: 0.8955\n",
            "Epoch 9/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.3628 - acc: 0.9147\n",
            "Epoch 9: loss improved from 0.43877 to 0.36273, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 169s 97ms/step - loss: 0.3627 - acc: 0.9147\n",
            "Epoch 10/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.9283\n",
            "Epoch 10: loss improved from 0.36273 to 0.30967, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 169s 97ms/step - loss: 0.3097 - acc: 0.9283\n",
            "Epoch 11/30\n",
            "1741/1741 [==============================] - ETA: 0s - loss: 0.2768 - acc: 0.9367\n",
            "Epoch 11: loss improved from 0.30967 to 0.27676, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 169s 97ms/step - loss: 0.2768 - acc: 0.9367\n",
            "Epoch 12/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.9411\n",
            "Epoch 12: loss improved from 0.27676 to 0.25826, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 168s 97ms/step - loss: 0.2583 - acc: 0.9412\n",
            "Epoch 13/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2477 - acc: 0.9435\n",
            "Epoch 13: loss improved from 0.25826 to 0.24765, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 169s 97ms/step - loss: 0.2476 - acc: 0.9435\n",
            "Epoch 14/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9453\n",
            "Epoch 14: loss improved from 0.24765 to 0.23935, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 168s 96ms/step - loss: 0.2393 - acc: 0.9453\n",
            "Epoch 15/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2318 - acc: 0.9471\n",
            "Epoch 15: loss improved from 0.23935 to 0.23181, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2318 - acc: 0.9471\n",
            "Epoch 16/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9501\n",
            "Epoch 16: loss improved from 0.23181 to 0.21966, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2197 - acc: 0.9501\n",
            "Epoch 17/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2144 - acc: 0.9512\n",
            "Epoch 17: loss improved from 0.21966 to 0.21442, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2144 - acc: 0.9512\n",
            "Epoch 18/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9503\n",
            "Epoch 18: loss did not improve from 0.21442\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2164 - acc: 0.9503\n",
            "Epoch 19/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9520\n",
            "Epoch 19: loss improved from 0.21442 to 0.21025, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2102 - acc: 0.9520\n",
            "Epoch 20/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9515\n",
            "Epoch 20: loss did not improve from 0.21025\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2111 - acc: 0.9515\n",
            "Epoch 21/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9507\n",
            "Epoch 21: loss did not improve from 0.21025\n",
            "1741/1741 [==============================] - 168s 96ms/step - loss: 0.2138 - acc: 0.9507\n",
            "Epoch 22/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9526\n",
            "Epoch 22: loss improved from 0.21025 to 0.20613, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 168s 96ms/step - loss: 0.2061 - acc: 0.9526\n",
            "Epoch 23/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2049 - acc: 0.9528\n",
            "Epoch 23: loss improved from 0.20613 to 0.20485, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 168s 96ms/step - loss: 0.2048 - acc: 0.9528\n",
            "Epoch 24/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9522\n",
            "Epoch 24: loss did not improve from 0.20485\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2065 - acc: 0.9522\n",
            "Epoch 25/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9528\n",
            "Epoch 25: loss improved from 0.20485 to 0.20441, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.2044 - acc: 0.9528\n",
            "Epoch 26/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.1953 - acc: 0.9552\n",
            "Epoch 26: loss improved from 0.20441 to 0.19534, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.1953 - acc: 0.9552\n",
            "Epoch 27/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2028 - acc: 0.9530\n",
            "Epoch 27: loss did not improve from 0.19534\n",
            "1741/1741 [==============================] - 169s 97ms/step - loss: 0.2028 - acc: 0.9530\n",
            "Epoch 28/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9492\n",
            "Epoch 28: loss did not improve from 0.19534\n",
            "1741/1741 [==============================] - 170s 98ms/step - loss: 0.2159 - acc: 0.9492\n",
            "Epoch 29/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9496\n",
            "Epoch 29: loss did not improve from 0.19534\n",
            "1741/1741 [==============================] - 170s 97ms/step - loss: 0.2149 - acc: 0.9496\n",
            "Epoch 30/30\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9546\n",
            "Epoch 30: loss did not improve from 0.19534\n",
            "1741/1741 [==============================] - 170s 98ms/step - loss: 0.1967 - acc: 0.9546\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c90101d90>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이어서 학습 시 아래 코드를 실행합니다.\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# 추가 학습\n",
        "model.fit(train_data, \n",
        "          epochs=2,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          callbacks=[checkpointer],\n",
        "          )"
      ],
      "metadata": {
        "id": "D6IlxAJeFlqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84663e83-84be-468d-dcc5-de82caa3eb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.1903 - acc: 0.9564\n",
            "Epoch 1: loss improved from 0.19534 to 0.19025, saving model to sample-checkpoint.h5\n",
            "1741/1741 [==============================] - 168s 96ms/step - loss: 0.1903 - acc: 0.9564\n",
            "Epoch 2/2\n",
            "1740/1741 [============================>.] - ETA: 0s - loss: 0.1927 - acc: 0.9556\n",
            "Epoch 2: loss did not improve from 0.19025\n",
            "1741/1741 [==============================] - 167s 96ms/step - loss: 0.1927 - acc: 0.9556\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c241fa890>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P__1XcrbXTY"
      },
      "source": [
        "## Step 5. 모델을 활용한 뉴스기사 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9B_hZHcEfVy"
      },
      "source": [
        "# 예측 모델\n",
        "model = tf.keras.Sequential([\n",
        "    # Embedding Layer\n",
        "    # 한 글자가 들어가면 다음 글자를 예측하도록 수정\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[1, None]), \n",
        "    # LSTM Layer (returen_sequences=True, initializer는 glorot_uniform으로 설정)\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                         return_sequences=True,\n",
        "                         recurrent_initializer='glorot_uniform'),\n",
        "    # Dense의 unit은 vocab_size로 설정\n",
        "    tf.keras.layers.Dense(vocab_size) # 단어로 다시 변환할 수 있도록 softmax 삭제\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYMYNo_naEfY"
      },
      "source": [
        "### 문제 17. 저장한 Model Checkpoint를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzusyCTQEfVy"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqvfa3m8bF15"
      },
      "source": [
        "### 문제 18. 모델을 build하고 요약 내용을 출력해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ynbz1aZEfVy"
      },
      "source": [
        "model.build(tf.TensorShape([1, None])) # input shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q45AWkOEfVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e893226d-6abc-4c38-8ec1-5d623b528765"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            300288    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (1, None, 1024)           5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 1173)           1202325   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,749,589\n",
            "Trainable params: 6,749,589\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQUD6gPKbPBT"
      },
      "source": [
        "### 문제 19. 불러온 모델을 활용해 뉴스기사를 생성해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl6eJ0-IEfVz"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # 평가 단계 (학습된 모델을 사용하여 텍스트 생성)\n",
        "    \n",
        "    # 생성할 문자의 수\n",
        "    num_generate = 1000\n",
        "\n",
        "    # 시작 문자열을 숫자로 변환(벡터화)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0) # 모델의 예측값을 배치로 넣어주기 위해 expand\n",
        "\n",
        "    # 결과를 저장할 빈 문자열\n",
        "    text_generated = []\n",
        "\n",
        "    # 온도가 낮으면 더 예측 가능한 텍스트가 됩니다.\n",
        "    # 온도가 높으면 더 의외의 텍스트가 됩니다.(랜덤성을 더 부여)\n",
        "    # 최적의 세팅을 찾기 위한 실험\n",
        "    temperature = 0.1 \n",
        "\n",
        "    # 여기에서 배치 크기 == 1\n",
        "    model.reset_states() # 초기화\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # 배치 차원 제거\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # 범주형 분포를 사용하여 모델에서 리턴한 단어 예측\n",
        "        predictions = predictions / temperature # 예측값에서 낮은 값의 temperature를 나눠주면 확률의 격차를 더 벌려줌으로써 예상 가능한 단어를 예측하는데 도움을 줌\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # 예측된 단어를 다음 입력으로 모델에 전달\n",
        "        # 이전 은닉 상태와 함께\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        result_char = idx2char[predicted_id] # 문자형으로 변환\n",
        "        \n",
        "        # '#' 문자열을 만나면 종료합니다.\n",
        "        if result_char == '#':\n",
        "            break\n",
        "        \n",
        "        text_generated.append(result_char)\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}