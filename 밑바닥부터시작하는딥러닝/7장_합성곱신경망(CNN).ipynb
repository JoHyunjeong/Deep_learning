{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328d0327",
   "metadata": {},
   "source": [
    "### 합성곱신경망(convolutional neural network, CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d5e4f",
   "metadata": {},
   "source": [
    "### CNN 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef0614",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_1.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe3e7a",
   "metadata": {},
   "source": [
    "CNN에서는 '합성곱 계층 Conv'과 '풀링 계층 Pooling'이 추가됨  \n",
    "CNN의 계층은 'Conv - ReLU - (Pooling)' 흐름으로 연결(풀링 계층은 생략하기도 함)  \n",
    "  \n",
    "출력에 가까운 층에서는 'Affine - ReLU' 구성을 사용할 수 있음  \n",
    "마지막 출력 계층에서는 'Affine - Softmax' 조합을 그대로 사용함  \n",
    "(Affine : 완전연결층)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99955a",
   "metadata": {},
   "source": [
    "### 완전연결 계층의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd13af",
   "metadata": {},
   "source": [
    "완전연결 계층은 데이터의 형상이 무시됨  \n",
    "  \n",
    "ex) \n",
    "세로, 가로, 채널(색상)으로 구성된 3차원 이미지 데이터의 경우,  \n",
    "3차원인 형상에는 공간적 정보가 담겨 있으나,  \n",
    "완전연결 계층에 입력할 때는 3차원 데이터를 평평한 1차원 데이터로 평탄화해줘야 함  \n",
    "형상을 무시하고 모든 입력 데이터를 동등한 뉴런(같은 차원의 뉴런)으로 취급하여 형상에 담긴 정보를 살릴 수 없음  \n",
    "  \n",
    "한편, 합성곱 계층은 형상을 유지함  \n",
    "이미지도 3차원 데이터로 입력받으며, 마찬가지로 다음 계층에도 3차원 데이터로 전달함  \n",
    "CNN에서는 합성곱 계층의 입출력 데이터를 특징 맵(feature map)이라고 부름  \n",
    "- 합성곱 계층의 입력 데이터 : 입력 특징 맵(input feature map)\n",
    "- 합성곱 계층의 출력 데이터 : 출력 특징 맵(output feature map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a180ae",
   "metadata": {},
   "source": [
    "### 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb53e2",
   "metadata": {},
   "source": [
    "합성곱 계층에서는 합성곱 연산을 처리  \n",
    "합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0560b72",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_2.jpeg' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32abc28",
   "metadata": {},
   "source": [
    "데이터와 필터의 형상을 (높이 height, 너비 width)로 표기하며,  \n",
    "위 예에서는 입력은 (4,4), 필터는 (3,3), 출력은 (2,2)가 됨  \n",
    "  \n",
    "필터를 커널이라 칭하기도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c40982",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_3.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b6090",
   "metadata": {},
   "source": [
    "합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용함  \n",
    "(윈도우 : 회색 $3\\times3$ 부분)  \n",
    "입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구함  \n",
    "이 계산을 __단일 곱셈-누산__(fused multiply-add, FMA)이라고 함  \n",
    "\n",
    "ex)\n",
    "첫 번째 그림의 경우,  \n",
    "$1\\times2+2\\times0+3\\times1+0\\times0+1\\times1+2\\times2+3\\times1+0\\times0+1\\times2=15$  \n",
    "  \n",
    "CNN에서는 필터의 매개변수가 '가중치'에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9ebe0",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_4.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ceb86",
   "metadata": {},
   "source": [
    "편향은 필터를 적용한 모든 원소(데이터)에 더함  \n",
    "편향은 항상 하나($1\\times1$)만 존재함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acbca94",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e50cd6",
   "metadata": {},
   "source": [
    "패딩(padding) : 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값(0)으로 채움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06816611",
   "metadata": {},
   "source": [
    "<img src='./img/padding_1.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20354d30",
   "metadata": {},
   "source": [
    "패딩은 주로 출력 크기를 조정할 목적으로 사용  \n",
    "  \n",
    "예를 들어 (4,4) 입력 데이터에 (3,3) 필터를 적용하면 출력은 (2,2)가 되어, 입력보다 2만큼 줄어듬  \n",
    "합성곱 연산을 몇 번이나 되풀이하는 심층 신경망에서는 합성곱 연산을 거칠 때마다 작아지면 어느 시점에서는 출력 크기가 1이 되어 더 이상은 합성곱 연산을 적용할 수 없게 될 수 있음  \n",
    "이러한 사태를 막기 위해 패딩을 사용함  \n",
    "  \n",
    "위 예시에서 볼 수 있듯이, 패딩의 폭을 1로 설정하니 (4,4) 입력에 대한 출력이 같은 크기인 (4,4)로 유지됨  \n",
    "즉, 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0001b",
   "metadata": {},
   "source": [
    "### 스트라이드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65190239",
   "metadata": {},
   "source": [
    "스트라이드(stride) : 필터를 적용하는 위치의 간격  \n",
    "(우리말로 '보폭'이라는 뜻)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f7fb4",
   "metadata": {},
   "source": [
    "<img src='./img/stride_1.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e4218",
   "metadata": {},
   "source": [
    "- 패딩을 크게 하면 출력 크기가 커지고,  \n",
    "- 스트라이드를 크게 하면 출력 크기는 작아짐  \n",
    "  \n",
    "입력 크기를 (H,W), 필터 크기를 (FH, FW), 출력 크기를(OH, OW), 패딩을 P, 스트라이드를 S라고 하면, 출력 크기는 다음 식으로 계산 됨  \n",
    "  \n",
    "$OH=\\frac{H+2P-FH}{S}+1$  \n",
    "\n",
    "$OW=\\frac{W+2P-FW}{S}+1$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636972c1",
   "metadata": {},
   "source": [
    "### 3차원 데이터의 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac96175",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_5.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c19122",
   "metadata": {},
   "source": [
    "2차원일 때와 비교하면, 길이 방향(채널 방향)으로 특징 맵이 늘어남  \n",
    "채널 쪽으로 특징 맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력을 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612b50f",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_6.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4810f8",
   "metadata": {},
   "source": [
    "입력 데이터의 채널 수와 필터의 채널 수가 같아야 함  \n",
    "(필터의 크기는 원하는 값으로 설정할 수 있음. 단, 모든 채널의 필터가 같은 크기여야 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe7a3b",
   "metadata": {},
   "source": [
    "### 블록으로 생각하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9699f",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_7.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ba378",
   "metadata": {},
   "source": [
    "3차원의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉬움  \n",
    "  \n",
    "위 예에서 출력 데이터는 한 장의 특징 맵(채널이 1개인 특징 맵)임  \n",
    "합성곱 연산의 출력으로 다수의 채널을 내보내려면  \n",
    "필터(가중치)를 다수 사용하면 됨!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09101bac",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_8.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ba62c",
   "metadata": {},
   "source": [
    "필터를 FN개 적용하면 출력 맵도 FN개가 생성됨  \n",
    "  \n",
    "따라서 합성곱 연산에서는 필터의 수도 고려해야 함  \n",
    "필터의 가중치 데이터는 4차원 데이터(출력 채널 수, 입력 채널 수, 높이, 너비) 순으로 씀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c1fd3",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_9.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8f183",
   "metadata": {},
   "source": [
    "편향은 채널 하나에 값 하나씩으로 구성됨  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562578a",
   "metadata": {},
   "source": [
    "### 배치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5528797",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_10.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc7a62",
   "metadata": {},
   "source": [
    "각 데이터의 선두에 배치용 차원을 추가하여 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장  \n",
    "데이터는 위와 같이 4차원 형상을 가진 채 각 계층을 타고 흐르며  \n",
    "데이터 N개에 대한 합성곱 연산이 이뤄짐(N회 분의 처리를 한 번에 수행)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed0518",
   "metadata": {},
   "source": [
    "### 풀링 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2dcfe",
   "metadata": {},
   "source": [
    "ex) $2\\times2$ 최대 풀링(max pooling)을 스트라이드 2로 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159a623",
   "metadata": {},
   "source": [
    "<img src='./img/pooling_1.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f01ac",
   "metadata": {},
   "source": [
    "최대풀링 : 대상 영역에서 최댓값을 구하는 연산  \n",
    "위 예에서 $2\\times2$가 대상 영역의 크기  \n",
    "  \n",
    "풀링의 윈도우 크기와 스트라이드는 보통 같은 값으로 설정함  \n",
    "풀링은 최대 풀링 외에도 평균 풀링 등이 있으나, 주로 최대 풀링을 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179fe4e",
   "metadata": {},
   "source": [
    "__풀링 계층의 특징__  \n",
    "  \n",
    "1. 채널 수가 변하지 않는다.\n",
    "    풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 내보냄  \n",
    "    채널마다 독립적으로 계산하기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74923942",
   "metadata": {},
   "source": [
    "<img src='./img/pooling_2.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98898219",
   "metadata": {},
   "source": [
    "2. 입력의 변화에 영향을 적게 받는다(데이터에 따라서는 다를 수 있음)  \n",
    "    입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525291de",
   "metadata": {},
   "source": [
    "### 합성곱/풀링 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4951f3",
   "metadata": {},
   "source": [
    "### 4차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26448b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.rand(10, 1, 28, 28) # 무작위로 데이터 생성\n",
    "x.shape # 데이터 10개, 채널 1, 높이 28, 너비 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48cc711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x[0].shape) # 첫 번째 데이터\n",
    "print(x[1].shape) # 두 번째 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47d0a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50316336, 0.7511575 , 0.0762883 , 0.5337324 , 0.86334461,\n",
       "        0.40644037, 0.63605815, 0.21683557, 0.52094898, 0.11201257,\n",
       "        0.37232237, 0.70273387, 0.99618482, 0.3566773 , 0.84262949,\n",
       "        0.43956506, 0.00844174, 0.55959293, 0.81068651, 0.19599028,\n",
       "        0.03746121, 0.29713737, 0.13331609, 0.96201067, 0.38933646,\n",
       "        0.18933786, 0.66990639, 0.97147994],\n",
       "       [0.17746137, 0.91207148, 0.93090653, 0.24115851, 0.65776434,\n",
       "        0.99810318, 0.89525894, 0.62942244, 0.82392598, 0.22199086,\n",
       "        0.78422602, 0.34295856, 0.32830894, 0.60209598, 0.58096791,\n",
       "        0.67739412, 0.08809075, 0.38062333, 0.54030226, 0.89015827,\n",
       "        0.27260749, 0.46053969, 0.2997987 , 0.28329796, 0.73235303,\n",
       "        0.40214777, 0.34024179, 0.80557524],\n",
       "       [0.60914625, 0.15741805, 0.4337216 , 0.94568455, 0.61126927,\n",
       "        0.38974931, 0.08801086, 0.74337946, 0.58449393, 0.83665917,\n",
       "        0.80423125, 0.6857222 , 0.39452282, 0.54957053, 0.112052  ,\n",
       "        0.79519623, 0.4758548 , 0.3738687 , 0.14637589, 0.8343784 ,\n",
       "        0.45869119, 0.32824221, 0.02884954, 0.70476878, 0.16443212,\n",
       "        0.4881282 , 0.9254079 , 0.62413815],\n",
       "       [0.73548329, 0.54677756, 0.98677099, 0.26235854, 0.31318061,\n",
       "        0.24934927, 0.05988977, 0.01645826, 0.81405301, 0.95620118,\n",
       "        0.331126  , 0.97002623, 0.57672851, 0.60821339, 0.41015399,\n",
       "        0.51685698, 0.96829929, 0.16133883, 0.23173319, 0.13698428,\n",
       "        0.31736963, 0.79904902, 0.19577143, 0.63428911, 0.70764583,\n",
       "        0.93311411, 0.63873438, 0.7559107 ],\n",
       "       [0.79151942, 0.41859698, 0.60522027, 0.45238073, 0.26806785,\n",
       "        0.92369421, 0.99785523, 0.70347665, 0.27479177, 0.74349429,\n",
       "        0.27118912, 0.35886825, 0.08296049, 0.43725516, 0.08363345,\n",
       "        0.583307  , 0.46649846, 0.85744036, 0.96683134, 0.82374364,\n",
       "        0.31344029, 0.3496331 , 0.5829872 , 0.7649001 , 0.01657278,\n",
       "        0.01112068, 0.80149052, 0.17629466],\n",
       "       [0.68297589, 0.40903993, 0.82830027, 0.09384527, 0.36508927,\n",
       "        0.77173513, 0.17205643, 0.70885304, 0.47600283, 0.12476623,\n",
       "        0.91462079, 0.52165965, 0.62693098, 0.08795282, 0.72759526,\n",
       "        0.09006229, 0.02142853, 0.08950604, 0.50819547, 0.2784267 ,\n",
       "        0.89637156, 0.0846666 , 0.35960549, 0.31596797, 0.6932048 ,\n",
       "        0.596933  , 0.07760592, 0.91183881],\n",
       "       [0.895864  , 0.76115528, 0.27480805, 0.30102144, 0.07289541,\n",
       "        0.23137698, 0.74333404, 0.07097306, 0.44997882, 0.59985136,\n",
       "        0.32720007, 0.66315817, 0.07694657, 0.24087801, 0.00108125,\n",
       "        0.87359968, 0.61903078, 0.64842337, 0.72797073, 0.98201171,\n",
       "        0.93857642, 0.15357603, 0.63746533, 0.75905545, 0.65731264,\n",
       "        0.68557214, 0.39552064, 0.05478072],\n",
       "       [0.20615152, 0.74537736, 0.35209708, 0.84192211, 0.95991982,\n",
       "        0.08712965, 0.71491236, 0.04270491, 0.44664886, 0.37602675,\n",
       "        0.21871085, 0.82199576, 0.88961081, 0.72926192, 0.91107344,\n",
       "        0.86978322, 0.27775777, 0.23625957, 0.70297956, 0.82940268,\n",
       "        0.55732884, 0.20648112, 0.9656941 , 0.76480567, 0.30635985,\n",
       "        0.94878642, 0.61937578, 0.49028941],\n",
       "       [0.77563356, 0.66491676, 0.8224392 , 0.37446283, 0.32249898,\n",
       "        0.09276838, 0.90164035, 0.32535238, 0.62904828, 0.63327816,\n",
       "        0.74872897, 0.90872325, 0.84303282, 0.85779923, 0.06246086,\n",
       "        0.30042109, 0.34382326, 0.83500879, 0.50634483, 0.76877416,\n",
       "        0.78944148, 0.01789565, 0.52418938, 0.66917268, 0.20436977,\n",
       "        0.33281015, 0.02769643, 0.8962401 ],\n",
       "       [0.296261  , 0.06340286, 0.3222013 , 0.0246569 , 0.50110042,\n",
       "        0.5046724 , 0.46053997, 0.16798809, 0.17383582, 0.94639252,\n",
       "        0.21977365, 0.87865951, 0.30932217, 0.32947013, 0.32196175,\n",
       "        0.83112091, 0.15755587, 0.80964112, 0.17382225, 0.20735728,\n",
       "        0.34633351, 0.15477775, 0.6020731 , 0.64928687, 0.94819204,\n",
       "        0.50233352, 0.40322444, 0.98031455],\n",
       "       [0.80977397, 0.7136821 , 0.41339694, 0.41320042, 0.72777474,\n",
       "        0.8246758 , 0.48775713, 0.65469673, 0.64186442, 0.46711813,\n",
       "        0.63250538, 0.32408485, 0.70826968, 0.68508762, 0.98542106,\n",
       "        0.98307523, 0.70478858, 0.66664801, 0.61554143, 0.46786534,\n",
       "        0.06737731, 0.15123493, 0.81475106, 0.88303924, 0.01682544,\n",
       "        0.24389493, 0.92326405, 0.26941182],\n",
       "       [0.5358621 , 0.10356822, 0.75691288, 0.61773209, 0.18727205,\n",
       "        0.9909638 , 0.68298182, 0.26002177, 0.79586246, 0.36089451,\n",
       "        0.14983467, 0.67961417, 0.82530453, 0.93160054, 0.80018656,\n",
       "        0.95889643, 0.34409516, 0.8081485 , 0.22912472, 0.23670855,\n",
       "        0.2367965 , 0.79216379, 0.96476653, 0.69890395, 0.07012299,\n",
       "        0.32100298, 0.68075244, 0.49157403],\n",
       "       [0.10980809, 0.06519062, 0.43525586, 0.72427734, 0.50387022,\n",
       "        0.49090983, 0.62657433, 0.97061648, 0.93069392, 0.31600371,\n",
       "        0.63178538, 0.19634599, 0.02151782, 0.26334374, 0.54471149,\n",
       "        0.68762782, 0.68915159, 0.27820326, 0.0018044 , 0.30022531,\n",
       "        0.33430956, 0.33097319, 0.99625672, 0.61650187, 0.83810317,\n",
       "        0.65770143, 0.91653086, 0.82948133],\n",
       "       [0.73680427, 0.77326013, 0.93452957, 0.67352202, 0.16389576,\n",
       "        0.43092699, 0.93584977, 0.49644577, 0.27140614, 0.57711684,\n",
       "        0.66361113, 0.42568843, 0.91973285, 0.88362975, 0.54247856,\n",
       "        0.76703403, 0.66725623, 0.20746917, 0.32231389, 0.88791475,\n",
       "        0.62697315, 0.18471748, 0.79299562, 0.08156872, 0.59886022,\n",
       "        0.41297981, 0.33509776, 0.80624348],\n",
       "       [0.58678626, 0.54259782, 0.91041447, 0.46230595, 0.4802986 ,\n",
       "        0.96177892, 0.93980079, 0.38945525, 0.99501207, 0.70624182,\n",
       "        0.43516062, 0.79284218, 0.0164694 , 0.37819885, 0.39296886,\n",
       "        0.89270671, 0.96992636, 0.12959442, 0.60586263, 0.7335199 ,\n",
       "        0.00898421, 0.34777111, 0.17989982, 0.4872679 , 0.71462084,\n",
       "        0.64285995, 0.28449385, 0.50675001],\n",
       "       [0.95337896, 0.68392189, 0.53125827, 0.85567356, 0.4442954 ,\n",
       "        0.25518359, 0.59690478, 0.15656965, 0.25214942, 0.73806265,\n",
       "        0.26178583, 0.20126893, 0.65045609, 0.73367207, 0.15268524,\n",
       "        0.23297257, 0.42073369, 0.8476506 , 0.00383401, 0.70280843,\n",
       "        0.61815424, 0.38538903, 0.94713897, 0.99404003, 0.2627022 ,\n",
       "        0.92117442, 0.07832827, 0.16994361],\n",
       "       [0.7199717 , 0.7362971 , 0.74673058, 0.84217662, 0.54937324,\n",
       "        0.05658583, 0.9449577 , 0.09480815, 0.58551593, 0.38851579,\n",
       "        0.54974647, 0.97127186, 0.2843563 , 0.18796057, 0.41720105,\n",
       "        0.23706113, 0.44633771, 0.80673831, 0.76464437, 0.29152537,\n",
       "        0.98073611, 0.01315478, 0.75834548, 0.66041595, 0.82923941,\n",
       "        0.38506751, 0.30039031, 0.80375272],\n",
       "       [0.53572493, 0.53730709, 0.61967068, 0.21591353, 0.93683512,\n",
       "        0.59028585, 0.66162547, 0.30990547, 0.8016816 , 0.31682231,\n",
       "        0.39888812, 0.18182284, 0.30343176, 0.28170975, 0.07794957,\n",
       "        0.2209334 , 0.2311473 , 0.37861959, 0.96507033, 0.96857968,\n",
       "        0.31901996, 0.15963104, 0.97827104, 0.65696527, 0.24694209,\n",
       "        0.12835314, 0.21986967, 0.14559308],\n",
       "       [0.5443414 , 0.86746966, 0.79012309, 0.86251764, 0.79204015,\n",
       "        0.50113838, 0.17152486, 0.85657308, 0.15653906, 0.76233253,\n",
       "        0.95873066, 0.06245339, 0.7891821 , 0.68707701, 0.10817586,\n",
       "        0.5077708 , 0.6373781 , 0.17292725, 0.80715825, 0.43553427,\n",
       "        0.73114847, 0.71041908, 0.57958997, 0.56103191, 0.26472859,\n",
       "        0.38515558, 0.39202218, 0.80605789],\n",
       "       [0.75260105, 0.12839814, 0.50969413, 0.67236106, 0.09099035,\n",
       "        0.37299446, 0.2671419 , 0.80767598, 0.40618002, 0.8518871 ,\n",
       "        0.98950237, 0.10170404, 0.21638477, 0.13357357, 0.75743941,\n",
       "        0.47548437, 0.45717071, 0.33677057, 0.15323023, 0.88545814,\n",
       "        0.34628183, 0.98955064, 0.59880813, 0.59493978, 0.70093619,\n",
       "        0.68288949, 0.87302951, 0.69329126],\n",
       "       [0.25996145, 0.59671509, 0.73870479, 0.20817547, 0.0967994 ,\n",
       "        0.74821719, 0.23444435, 0.6858145 , 0.15127316, 0.07019107,\n",
       "        0.15772402, 0.73745884, 0.29328431, 0.0700444 , 0.80784668,\n",
       "        0.94235906, 0.59657113, 0.00633551, 0.53666422, 0.89324677,\n",
       "        0.44577506, 0.76111834, 0.52771064, 0.08226738, 0.43414137,\n",
       "        0.85219126, 0.61241257, 0.46722943],\n",
       "       [0.84369949, 0.97261788, 0.38303518, 0.20615327, 0.42178342,\n",
       "        0.34138328, 0.18755961, 0.86584853, 0.06486305, 0.5667628 ,\n",
       "        0.31161165, 0.90553699, 0.1281603 , 0.69059581, 0.34019051,\n",
       "        0.85815479, 0.27220735, 0.77670043, 0.5303825 , 0.66748747,\n",
       "        0.64743783, 0.2184545 , 0.17518356, 0.11181124, 0.07900928,\n",
       "        0.78416055, 0.7542949 , 0.78200876],\n",
       "       [0.98429635, 0.23633426, 0.74026982, 0.75050925, 0.40845731,\n",
       "        0.29199399, 0.57148858, 0.01479344, 0.97475931, 0.69579677,\n",
       "        0.47334588, 0.71208983, 0.3226583 , 0.80252031, 0.43223037,\n",
       "        0.9220744 , 0.26248724, 0.22092356, 0.85607059, 0.08756367,\n",
       "        0.92967126, 0.47295016, 0.9389974 , 0.48475398, 0.14634855,\n",
       "        0.26358613, 0.08735286, 0.57018238],\n",
       "       [0.38613979, 0.35701026, 0.10433473, 0.40143064, 0.07224646,\n",
       "        0.45850914, 0.95327555, 0.26964285, 0.62437264, 0.49738444,\n",
       "        0.1917164 , 0.61139505, 0.30081413, 0.46168253, 0.06535709,\n",
       "        0.53310278, 0.09924756, 0.63763206, 0.17432138, 0.80370796,\n",
       "        0.13442871, 0.99178996, 0.84069356, 0.3450681 , 0.13712668,\n",
       "        0.41896873, 0.30518013, 0.47165745],\n",
       "       [0.28331893, 0.03314094, 0.90376303, 0.99515162, 0.7486949 ,\n",
       "        0.6909141 , 0.47175383, 0.51263267, 0.7966146 , 0.3788534 ,\n",
       "        0.4178511 , 0.60679313, 0.50170625, 0.26927038, 0.10921768,\n",
       "        0.12543509, 0.1056513 , 0.35256911, 0.31618595, 0.42502163,\n",
       "        0.81782607, 0.96663891, 0.11835235, 0.59529799, 0.32952065,\n",
       "        0.01357194, 0.49198715, 0.45647947],\n",
       "       [0.28773698, 0.24626937, 0.40762243, 0.10101199, 0.71641279,\n",
       "        0.27796047, 0.94780863, 0.08586764, 0.40624874, 0.68239274,\n",
       "        0.85389226, 0.9809553 , 0.190465  , 0.14442707, 0.05930062,\n",
       "        0.95978778, 0.16946585, 0.72959691, 0.99588467, 0.20498102,\n",
       "        0.64845163, 0.5102076 , 0.67188259, 0.69909224, 0.89305165,\n",
       "        0.22879006, 0.40108215, 0.48045795],\n",
       "       [0.31281282, 0.22164074, 0.78781646, 0.87890053, 0.5992831 ,\n",
       "        0.2120234 , 0.69662052, 0.39444509, 0.46614363, 0.525338  ,\n",
       "        0.9748814 , 0.23755205, 0.46288763, 0.55723227, 0.92793662,\n",
       "        0.18875541, 0.74052713, 0.38820271, 0.41821084, 0.14081854,\n",
       "        0.61326148, 0.33818155, 0.25949132, 0.27653444, 0.12263424,\n",
       "        0.62838048, 0.17424523, 0.86465865],\n",
       "       [0.84304872, 0.88509818, 0.9281435 , 0.27505229, 0.60324045,\n",
       "        0.34871944, 0.72758003, 0.57169237, 0.94958979, 0.42670735,\n",
       "        0.44753547, 0.57464722, 0.84703493, 0.31777344, 0.24804402,\n",
       "        0.07448946, 0.20255419, 0.54600417, 0.07960529, 0.79158401,\n",
       "        0.56075927, 0.30556752, 0.53260394, 0.79756992, 0.30354168,\n",
       "        0.23737788, 0.50571085, 0.08468341]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0] # 첫 번째 데이터의 첫 채널의 공간 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af0a55",
   "metadata": {},
   "source": [
    "### im2col로 데이터 전개하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77552a",
   "metadata": {},
   "source": [
    "( ※ 넘파이에서는 원소에 접근할 때 for 문을 사용하지 않는 것이 바람직 함, 성능이 떨어짐   \n",
    "따라서 for 문 대신 im2col 함수 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4740d",
   "metadata": {},
   "source": [
    "im2col(image to column)은 입력 데이터를 2차원 데이터로 변환해 줌  \n",
    "변환된 2차원 데이터의 열의 갯수는 필터를 일렬로 나열한 것의 갯수와 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3e423",
   "metadata": {},
   "source": [
    "<img src='./img/im2col.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d5185",
   "metadata": {},
   "source": [
    "im2col함수는 입력 데이터에서 필터 적용 영역을 앞에서부터 순서대로 1줄로 펼침  \n",
    "im2col로 입력 데이터를 전개한 다음에는 합성곱 계층의 필터(가중치)를 1열로 전개하고,  \n",
    "두 행렬의 곱을 계산함  \n",
    "  \n",
    "- im2col 방식으로 출력한 결과는 2차원 행렬  \n",
    "    (행의 갯수 : $N\\times OH\\times OW$개/열의 갯수 : $C\\times FH\\times FW$개)  \n",
    "  \n",
    "- 필터도 2차원 데이터로 변환  \n",
    "    (행의 갯수 : $C\\times FH\\times FW$개/열의 갯수 : $FN$개)\n",
    "\n",
    "CNN은 데이터를 4차원 배열로 저장하므로 2차원인 출력 데이터를 4차원으로 변형해줘야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569690cc",
   "metadata": {},
   "source": [
    "<참고>  \n",
    "위 예시에서는 스트라이드를 크게 잡아 필터의 적용 영역이 겹치지 않도록 했지만, 실제 상황에서는 영역이 겹치는 경우가 대부분임  \n",
    "필터 적용 영역이 겹치면 im2col로 전개한 후의 원소 수가 원래 블록의 원소 수보다 많아짐  \n",
    "따라서 im2col을 사용해 구현하면 메모리를 더 많이 소비하는 단점이 있음  \n",
    "하지만 문제를 행렬계산으로 만들면 선형 대수 라이브러리를 활용해 효율을 높일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da04e7",
   "metadata": {},
   "source": [
    "##### 순전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343a971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride] # 필터에 대응하는 이미지\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1) # (N * OH * OW, C * FH * FW) 2차원 배열로 변경\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08feb851",
   "metadata": {},
   "source": [
    "##### 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8bf602",
   "metadata": {},
   "source": [
    "역전파 시 순전파 때의 입력데이터에 맞도록 col2im 함수를 사용하여 데이터의 크기를 되돌림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b97f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환\"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2) # 2차원 데이터를 다시 6차원 데이터로 변경\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad] # 패딩 부분을 제외한 원래 이미지(N, C, H, W)를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92cd647",
   "metadata": {},
   "source": [
    "### 합성곱 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "400a47e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.rand(1,3,7,7) # (데이터 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10,3,7,7) # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab6459",
   "metadata": {},
   "source": [
    "두 경우 모두 2번째 차원의 원소는 75개  \n",
    "이 값은 필터의 원소 수와 같음(채널 3개, $5\\times5$ 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92bf9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad) # (N * OH * OW, C * FH * FW)\n",
    "        col_W = self.W.reshape(FN, -1).T # 필터 전개 # (C * FH * FW, FN)\n",
    "        out = np.dot(col, col_W) + self.b # (N * OH * OW, FN)\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2) # (N, FN, OH, OW)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN) # (N, FN, OH, OW) -> (N * OH * OW, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout) # (C * FH * FW, FN)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW) # (FN, C, FH, FW) \n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T) # (N * OH * OW, C * FH * FW)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93156a9c",
   "metadata": {},
   "source": [
    "### 풀링 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7696511",
   "metadata": {},
   "source": [
    "<img src='./img/pooling_3.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7368e",
   "metadata": {},
   "source": [
    "풀링 계층 구현도 합성곱 계층과 마찬가지로 im2col을 사용해 입력 데이터를 전개  \n",
    "단, 풀링 적용 영역을 채널마다 독립적으로 전개함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe6fbf",
   "metadata": {},
   "source": [
    "<img src='./img/pooling_4.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6a14a",
   "metadata": {},
   "source": [
    "전개한 행렬에서 행별 최댓값을 구하고 적절한 형상으로 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f90b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 입력 데이터 전개\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad) # (N * OH * OW, C * PH * PW)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w) # (N * OH * OW * C, PH * PW)\n",
    "        \n",
    "        # 행별 최댓값\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 적절한 형상으로 변형\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0,3,1,2) # (N, C, OH, OW) \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1) # (N, OH, OW, C)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size)) # 크기 (N * OH * OW * C, PH * PW)인 zeros 배열\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten() # 최대값 인덱스에 역전파된 미분값을 대입하고 나머지는 0\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) # (N, OH, OW, C, PH * PW) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1) # (N * OH * OW, C * PH * PW)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad) # 순전파 대 입력되었던 원래 데이터 크기인 self.x.shape으로 변환\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90667912",
   "metadata": {},
   "source": [
    "### CNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730a11d",
   "metadata": {},
   "source": [
    "MNIST 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65074fc8",
   "metadata": {},
   "source": [
    "<img src='./img/CNN_11.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cd7cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1 # 합성곱 계층의 출력 데이터 크기\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2)) # 풀링 계층의 출력 데이터 크기 \n",
    "\n",
    "        # 가중치 매개변수 초기화\n",
    "        self.params = {}\n",
    "        # 합성곱 계층 매개변수\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        # 첫번째 Affine 계층 매개변수\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        # 두번째 Affine 계층 매개변수\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # CNN 구성하는 계층들 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    # 추론 수행\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # 손실함수\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    # 정확도\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    # 매개변수의 기울기 - 오차역전파법\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3653064f",
   "metadata": {},
   "source": [
    "- Conv1  \n",
    "    * 입력데이터 : MNIST (1, 28, 28)\n",
    "    * W1 : (FN, C, FH, FW)\n",
    "    * b1 : (FN,)\n",
    "    * 출력데이터 : (N, FN, OH, OW)\n",
    "- Relu1  \n",
    "    * 출력데이터 : (N, FN, OH, OW)\n",
    "- Pool1\n",
    "    * 출력데이터 : (N, FN, OH, OW)\n",
    "- Affine1\n",
    "    * 입력데이터 : (N, FN, OH, OW) $\\rightarrow$ (N, FN * OH * OW)\n",
    "    * W2 : (FN * OH * OW, 은닉 노드의 수)\n",
    "    * b2 : (은닉 노드의 수,)\n",
    "    * 출력데이터 : (N, 은닉 노드의 수)\n",
    "- Relu2\n",
    "    * 출력데이터 : (N, 은닉 노드의 수)\n",
    "- Affine2\n",
    "    * W3 : (은닉 노드의 수, 10)\n",
    "    * b3 : (10,)\n",
    "    * 출력데이터 : MNIST 분류 개수인 10\n",
    "- SoftmaxWithLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "627d2fff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2987127921988133\n",
      "=== epoch:1, train acc:0.163, test acc:0.145 ===\n",
      "train loss:2.295989008446241\n",
      "train loss:2.2918638293496336\n",
      "train loss:2.285853500834688\n",
      "train loss:2.278840789644383\n",
      "train loss:2.2671410934623433\n",
      "train loss:2.2576656295805724\n",
      "train loss:2.2337447858289385\n",
      "train loss:2.210108967038017\n",
      "train loss:2.18512692949307\n",
      "train loss:2.171219200238287\n",
      "train loss:2.116974150135126\n",
      "train loss:2.089517049221032\n",
      "train loss:2.057937772532368\n",
      "train loss:1.963622714037797\n",
      "train loss:1.9165183870996012\n",
      "train loss:1.815450275741598\n",
      "train loss:1.776418421670379\n",
      "train loss:1.6714299714679473\n",
      "train loss:1.5494874011744246\n",
      "train loss:1.5462000723687805\n",
      "train loss:1.319707291721125\n",
      "train loss:1.3882837110387292\n",
      "train loss:1.251330626033898\n",
      "train loss:1.1729098075892914\n",
      "train loss:1.005777194706125\n",
      "train loss:1.1734871523573829\n",
      "train loss:0.9561141181510464\n",
      "train loss:0.9318647611378104\n",
      "train loss:0.8709250349218945\n",
      "train loss:0.9662866843393689\n",
      "train loss:0.8849386994007469\n",
      "train loss:0.8772856336875755\n",
      "train loss:0.6336697064803193\n",
      "train loss:0.7718181303556593\n",
      "train loss:0.7071866811077794\n",
      "train loss:0.603272938751836\n",
      "train loss:0.6031354813491834\n",
      "train loss:0.7325229740746977\n",
      "train loss:0.6547477592117883\n",
      "train loss:0.8150984320204784\n",
      "train loss:0.4864591243895071\n",
      "train loss:0.687075211534038\n",
      "train loss:0.7156827625041351\n",
      "train loss:0.4633636744704156\n",
      "train loss:0.4367898161527514\n",
      "train loss:0.7015184896018508\n",
      "train loss:0.5710920881209798\n",
      "train loss:0.5627268012467518\n",
      "train loss:0.6667896774402864\n",
      "train loss:0.44795409553631543\n",
      "train loss:0.5934984220354216\n",
      "train loss:0.6193056850187932\n",
      "train loss:0.30344320818847437\n",
      "train loss:0.4039931693122702\n",
      "train loss:0.5532205491649311\n",
      "train loss:0.49708745115491304\n",
      "train loss:0.44744152340442506\n",
      "train loss:0.5572596764665636\n",
      "train loss:0.4550478896302221\n",
      "train loss:0.5247159452947809\n",
      "train loss:0.5453710271874983\n",
      "train loss:0.486893820294151\n",
      "train loss:0.6385720369179758\n",
      "train loss:0.4086206684319999\n",
      "train loss:0.501958233542056\n",
      "train loss:0.6567640174681447\n",
      "train loss:0.5638368529229718\n",
      "train loss:0.3806757961663541\n",
      "train loss:0.40507228694503267\n",
      "train loss:0.42993570862509584\n",
      "train loss:0.4588279006104616\n",
      "train loss:0.3454480269112743\n",
      "train loss:0.4881086829185076\n",
      "train loss:0.43930209673893417\n",
      "train loss:0.5772092263771401\n",
      "train loss:0.34909980447421474\n",
      "train loss:0.4745232732894038\n",
      "train loss:0.4028609039616321\n",
      "train loss:0.3164372185600961\n",
      "train loss:0.39358526887615514\n",
      "train loss:0.5541377089691943\n",
      "train loss:0.29289639664560685\n",
      "train loss:0.3618821920442532\n",
      "train loss:0.4769709670118627\n",
      "train loss:0.3771787965931992\n",
      "train loss:0.3818444834519997\n",
      "train loss:0.3315587963951307\n",
      "train loss:0.49689225926987896\n",
      "train loss:0.4484815441102789\n",
      "train loss:0.20452005040626736\n",
      "train loss:0.377882940302913\n",
      "train loss:0.4285993369261709\n",
      "train loss:0.38589770800129913\n",
      "train loss:0.32120214115726303\n",
      "train loss:0.2972137314944906\n",
      "train loss:0.3248977419503936\n",
      "train loss:0.21311806716677828\n",
      "train loss:0.4270559060871919\n",
      "train loss:0.36755120881878967\n",
      "train loss:0.3933891060489146\n",
      "train loss:0.17783365488069222\n",
      "train loss:0.310593534487858\n",
      "train loss:0.3809392865178048\n",
      "train loss:0.43186578301975076\n",
      "train loss:0.5527586883383097\n",
      "train loss:0.2231693226424799\n",
      "train loss:0.31811031593006267\n",
      "train loss:0.45765116462787814\n",
      "train loss:0.3564398026074134\n",
      "train loss:0.4558945343891466\n",
      "train loss:0.3894280843303306\n",
      "train loss:0.43074292947878023\n",
      "train loss:0.35241198885467356\n",
      "train loss:0.3552599373572989\n",
      "train loss:0.43365094807348425\n",
      "train loss:0.4177170405746518\n",
      "train loss:0.2940225140641739\n",
      "train loss:0.47525971671221146\n",
      "train loss:0.7200913619864636\n",
      "train loss:0.3525053043385819\n",
      "train loss:0.3200794360800032\n",
      "train loss:0.46433306886313125\n",
      "train loss:0.5674828908267177\n",
      "train loss:0.33855703156834016\n",
      "train loss:0.4282046252344675\n",
      "train loss:0.39311516837564014\n",
      "train loss:0.34510077679333334\n",
      "train loss:0.29105221409352255\n",
      "train loss:0.40006687827041565\n",
      "train loss:0.2800063429100864\n",
      "train loss:0.29318218978310556\n",
      "train loss:0.39756811579484497\n",
      "train loss:0.5248257434657871\n",
      "train loss:0.3190428781074566\n",
      "train loss:0.3719416302607864\n",
      "train loss:0.27804241819350856\n",
      "train loss:0.2613222847293439\n",
      "train loss:0.3832495578656744\n",
      "train loss:0.4497387961601526\n",
      "train loss:0.35386701767899353\n",
      "train loss:0.3983139500034227\n",
      "train loss:0.5656346849947469\n",
      "train loss:0.2558014708887122\n",
      "train loss:0.3316451656097435\n",
      "train loss:0.3519082987444397\n",
      "train loss:0.3800293077847975\n",
      "train loss:0.42721332230730885\n",
      "train loss:0.3146649004277198\n",
      "train loss:0.19191719093385326\n",
      "train loss:0.40277880970601865\n",
      "train loss:0.30832679471103636\n",
      "train loss:0.364321834624472\n",
      "train loss:0.41583266411886943\n",
      "train loss:0.33395005074540657\n",
      "train loss:0.3125113552910274\n",
      "train loss:0.32356631920307877\n",
      "train loss:0.3721189137233406\n",
      "train loss:0.2562742259412411\n",
      "train loss:0.5212926585567706\n",
      "train loss:0.4186577665494016\n",
      "train loss:0.36407551923219833\n",
      "train loss:0.3406672434027112\n",
      "train loss:0.20121182257986173\n",
      "train loss:0.2338927227565783\n",
      "train loss:0.36293480947299556\n",
      "train loss:0.29016371692192583\n",
      "train loss:0.34261275507970007\n",
      "train loss:0.30037667024603576\n",
      "train loss:0.37575084675656195\n",
      "train loss:0.26131469041520566\n",
      "train loss:0.500829252601302\n",
      "train loss:0.2428469176323078\n",
      "train loss:0.42399090647845356\n",
      "train loss:0.22195107464990774\n",
      "train loss:0.31667354217050536\n",
      "train loss:0.23581002295329\n",
      "train loss:0.2205198200203839\n",
      "train loss:0.3792572942892298\n",
      "train loss:0.37289641617922054\n",
      "train loss:0.2952709883555893\n",
      "train loss:0.2912028607237338\n",
      "train loss:0.34448192206686473\n",
      "train loss:0.15789340828475873\n",
      "train loss:0.29060564335197486\n",
      "train loss:0.4058073601912986\n",
      "train loss:0.26888484717279154\n",
      "train loss:0.5605242608316416\n",
      "train loss:0.19998152705583586\n",
      "train loss:0.34176363439250956\n",
      "train loss:0.2668550547872686\n",
      "train loss:0.23213901927818303\n",
      "train loss:0.27955261096440004\n",
      "train loss:0.3241334126476657\n",
      "train loss:0.29198639670315274\n",
      "train loss:0.18233547109077475\n",
      "train loss:0.24014008103215972\n",
      "train loss:0.34650359131072667\n",
      "train loss:0.3012934467154724\n",
      "train loss:0.271235830027442\n",
      "train loss:0.39548990803223005\n",
      "train loss:0.28643587621699856\n",
      "train loss:0.2299435753079436\n",
      "train loss:0.27989094857668995\n",
      "train loss:0.2396834612892178\n",
      "train loss:0.4767246199943936\n",
      "train loss:0.3187780469709103\n",
      "train loss:0.25857174786039927\n",
      "train loss:0.17355413213925125\n",
      "train loss:0.1841263256810083\n",
      "train loss:0.35053964423446177\n",
      "train loss:0.403635276821506\n",
      "train loss:0.2786862631815963\n",
      "train loss:0.2898712233061568\n",
      "train loss:0.3037294541706258\n",
      "train loss:0.4160296340381977\n",
      "train loss:0.23745333914564676\n",
      "train loss:0.280391489391232\n",
      "train loss:0.19478437018315475\n",
      "train loss:0.24807495634301166\n",
      "train loss:0.3117184001598904\n",
      "train loss:0.21901624379643964\n",
      "train loss:0.17325660009764993\n",
      "train loss:0.3086535518827428\n",
      "train loss:0.19832653480792028\n",
      "train loss:0.2656027566172897\n",
      "train loss:0.31535648590772447\n",
      "train loss:0.28823624304032064\n",
      "train loss:0.20572822811303562\n",
      "train loss:0.34684458197136564\n",
      "train loss:0.3252238913101678\n",
      "train loss:0.2228456001322231\n",
      "train loss:0.17159073630431887\n",
      "train loss:0.3540572634873078\n",
      "train loss:0.17697079493514298\n",
      "train loss:0.27846811400703414\n",
      "train loss:0.31640456948054657\n",
      "train loss:0.19815872179362556\n",
      "train loss:0.4561588066742837\n",
      "train loss:0.39339319914694654\n",
      "train loss:0.22657584767895295\n",
      "train loss:0.24367833411742176\n",
      "train loss:0.2071641636500357\n",
      "train loss:0.30805408726829137\n",
      "train loss:0.32016673489681297\n",
      "train loss:0.20219838771464893\n",
      "train loss:0.22705437822392305\n",
      "train loss:0.24886182938706639\n",
      "train loss:0.341948878607767\n",
      "train loss:0.39438829819153326\n",
      "train loss:0.18856636600182855\n",
      "train loss:0.21623305053425448\n",
      "train loss:0.24764022384147244\n",
      "train loss:0.25884387229367867\n",
      "train loss:0.16899458565245692\n",
      "train loss:0.28744137311346785\n",
      "train loss:0.23404154971853314\n",
      "train loss:0.26678976440026186\n",
      "train loss:0.2490412295060268\n",
      "train loss:0.26432105533384403\n",
      "train loss:0.40676480245107377\n",
      "train loss:0.20122002858214022\n",
      "train loss:0.2892149738465757\n",
      "train loss:0.1877098547000375\n",
      "train loss:0.1526819811487543\n",
      "train loss:0.3180398836692325\n",
      "train loss:0.279204097442722\n",
      "train loss:0.2917757481657403\n",
      "train loss:0.4315690713141185\n",
      "train loss:0.27535057865159074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2457266779260172\n",
      "train loss:0.23620678703455258\n",
      "train loss:0.3353663826545429\n",
      "train loss:0.2657707822176182\n",
      "train loss:0.15945675970347284\n",
      "train loss:0.3115973652495408\n",
      "train loss:0.17810204440445646\n",
      "train loss:0.22732856530895768\n",
      "train loss:0.2561693987022549\n",
      "train loss:0.39292506534332916\n",
      "train loss:0.2813160345211571\n",
      "train loss:0.2151534344623486\n",
      "train loss:0.358038203669718\n",
      "train loss:0.37419858498273995\n",
      "train loss:0.20173954809532943\n",
      "train loss:0.2849197366204502\n",
      "train loss:0.38496167301817735\n",
      "train loss:0.26342026196764884\n",
      "train loss:0.1821463746873007\n",
      "train loss:0.22962975173292272\n",
      "train loss:0.2241884628119636\n",
      "train loss:0.20347870912857208\n",
      "train loss:0.25227487101798973\n",
      "train loss:0.10628144033505958\n",
      "train loss:0.16634761608527726\n",
      "train loss:0.20861719383023236\n",
      "train loss:0.33499516739303126\n",
      "train loss:0.29184913260039086\n",
      "train loss:0.16345392843011822\n",
      "train loss:0.14997931023087235\n",
      "train loss:0.3777430699964466\n",
      "train loss:0.2560102935024609\n",
      "train loss:0.2975026166201825\n",
      "train loss:0.18433830169564888\n",
      "train loss:0.28240572259712154\n",
      "train loss:0.14902292075220308\n",
      "train loss:0.2364030571080798\n",
      "train loss:0.21234977059738147\n",
      "train loss:0.2824545426113927\n",
      "train loss:0.3127980703956955\n",
      "train loss:0.295468248058681\n",
      "train loss:0.3330144842676425\n",
      "train loss:0.31472474339768736\n",
      "train loss:0.3023159752117724\n",
      "train loss:0.2008027179195662\n",
      "train loss:0.2898868374772094\n",
      "train loss:0.2584388444634423\n",
      "train loss:0.20583096282052352\n",
      "train loss:0.2308875293843001\n",
      "train loss:0.10661155663232556\n",
      "train loss:0.1944059787890975\n",
      "train loss:0.2252068153307138\n",
      "train loss:0.1425893645933982\n",
      "train loss:0.2636643324323128\n",
      "train loss:0.2412424315204986\n",
      "train loss:0.16922518922416085\n",
      "train loss:0.16329624167874518\n",
      "train loss:0.11841025794442643\n",
      "train loss:0.23973568910099824\n",
      "train loss:0.3860534328984736\n",
      "train loss:0.1901608555738407\n",
      "train loss:0.20318370058141016\n",
      "train loss:0.23734728109240635\n",
      "train loss:0.2046116113305585\n",
      "train loss:0.24958523006023697\n",
      "train loss:0.23340482407964466\n",
      "train loss:0.2769379253494843\n",
      "train loss:0.31908798172828257\n",
      "train loss:0.17079058736330668\n",
      "train loss:0.10165553602086325\n",
      "train loss:0.12858584472097287\n",
      "train loss:0.09183092641033083\n",
      "train loss:0.26197914601877165\n",
      "train loss:0.16054188298444966\n",
      "train loss:0.1800093821710625\n",
      "train loss:0.1455690262009143\n",
      "train loss:0.11218712721903965\n",
      "train loss:0.2021189990893151\n",
      "train loss:0.2110060968005858\n",
      "train loss:0.22582285547798034\n",
      "train loss:0.25644705939469026\n",
      "train loss:0.2890877135535538\n",
      "train loss:0.1375671196637985\n",
      "train loss:0.1737944205974327\n",
      "train loss:0.2304080691557183\n",
      "train loss:0.18309273458881695\n",
      "train loss:0.19651314822698368\n",
      "train loss:0.2398116384319911\n",
      "train loss:0.3133880464267045\n",
      "train loss:0.22788195468616756\n",
      "train loss:0.23417607048439698\n",
      "train loss:0.1903803564420026\n",
      "train loss:0.2542019520076954\n",
      "train loss:0.1917533346425566\n",
      "train loss:0.3774655256186552\n",
      "train loss:0.16349962903233106\n",
      "train loss:0.1653409976703943\n",
      "train loss:0.3009435750192897\n",
      "train loss:0.17648107659894247\n",
      "train loss:0.18531174460922814\n",
      "train loss:0.0908969447970426\n",
      "train loss:0.2566242619912321\n",
      "train loss:0.3427489859900158\n",
      "train loss:0.12793100648841146\n",
      "train loss:0.15813692012513594\n",
      "train loss:0.1293254773465493\n",
      "train loss:0.22997772941992803\n",
      "train loss:0.09479621938590928\n",
      "train loss:0.16974819576512806\n",
      "train loss:0.13306150472021264\n",
      "train loss:0.36350219041253967\n",
      "train loss:0.15859455170333303\n",
      "train loss:0.1904202165235455\n",
      "train loss:0.23262599181323668\n",
      "train loss:0.16776566344247495\n",
      "train loss:0.2110918083785238\n",
      "train loss:0.26212038807636595\n",
      "train loss:0.15457366606626308\n",
      "train loss:0.07091426765446424\n",
      "train loss:0.1931129403736226\n",
      "train loss:0.24416509763412494\n",
      "train loss:0.1671600293779138\n",
      "train loss:0.27276341470933047\n",
      "train loss:0.12253297925677455\n",
      "train loss:0.11007197528355278\n",
      "train loss:0.21137442455479147\n",
      "train loss:0.25469516284230037\n",
      "train loss:0.11545180530926437\n",
      "train loss:0.25185441628659627\n",
      "train loss:0.20897339159889083\n",
      "train loss:0.18139446790914848\n",
      "train loss:0.268279210933759\n",
      "train loss:0.13085218996516249\n",
      "train loss:0.19303328529905245\n",
      "train loss:0.17660018395869131\n",
      "train loss:0.18665221391271591\n",
      "train loss:0.1842786460036732\n",
      "train loss:0.32020995966533433\n",
      "train loss:0.1420059032792685\n",
      "train loss:0.17909970022259436\n",
      "train loss:0.127707062978204\n",
      "train loss:0.147699373044462\n",
      "train loss:0.10066727739528403\n",
      "train loss:0.07031785863975902\n",
      "train loss:0.07600309402768265\n",
      "train loss:0.19149568299219918\n",
      "train loss:0.09936969027702951\n",
      "train loss:0.2158744906427546\n",
      "train loss:0.20293489896293782\n",
      "train loss:0.2624368709478496\n",
      "train loss:0.2053672164101453\n",
      "train loss:0.2138635076069311\n",
      "train loss:0.08549576202688884\n",
      "train loss:0.22072143817907905\n",
      "train loss:0.21859494004104277\n",
      "train loss:0.14947356251751262\n",
      "train loss:0.12509192981904943\n",
      "train loss:0.23266280112343907\n",
      "train loss:0.12810665478120475\n",
      "train loss:0.19996732030033926\n",
      "train loss:0.13650848257323175\n",
      "train loss:0.32639078668602695\n",
      "train loss:0.18919471566143892\n",
      "train loss:0.16289687566401945\n",
      "train loss:0.12021262761664349\n",
      "train loss:0.3040246475368225\n",
      "train loss:0.1185841490768211\n",
      "train loss:0.1782046109812963\n",
      "train loss:0.21529918899791053\n",
      "train loss:0.15108658022941746\n",
      "train loss:0.11503680786615952\n",
      "train loss:0.1185191976121506\n",
      "train loss:0.18540379054466857\n",
      "train loss:0.2274631378516817\n",
      "train loss:0.2585621201135942\n",
      "train loss:0.16268973160274208\n",
      "train loss:0.08657365795857569\n",
      "train loss:0.23245741050107277\n",
      "train loss:0.10779285513772964\n",
      "train loss:0.07120164194076031\n",
      "train loss:0.1428725192712431\n",
      "train loss:0.1406379348966281\n",
      "train loss:0.24627084392381296\n",
      "train loss:0.21583858459833966\n",
      "train loss:0.18261642723095334\n",
      "train loss:0.3579426322299837\n",
      "train loss:0.10765519228720773\n",
      "train loss:0.22452094952673093\n",
      "train loss:0.17080285548219745\n",
      "train loss:0.14972455023196224\n",
      "train loss:0.08915016276258651\n",
      "train loss:0.11739169461465325\n",
      "train loss:0.29185307847260494\n",
      "train loss:0.20863522479272628\n",
      "train loss:0.1340333024417835\n",
      "train loss:0.1846242830990195\n",
      "train loss:0.2039475657961175\n",
      "train loss:0.24405472635217643\n",
      "train loss:0.2622978747007892\n",
      "train loss:0.12168929479232293\n",
      "train loss:0.1985026000193028\n",
      "train loss:0.11158110652867986\n",
      "train loss:0.13389297488280388\n",
      "train loss:0.10676110858688924\n",
      "train loss:0.09650400752107338\n",
      "train loss:0.126070812503206\n",
      "train loss:0.19150806543131582\n",
      "train loss:0.25161365992822043\n",
      "train loss:0.1410847634754393\n",
      "train loss:0.1580617992569339\n",
      "train loss:0.14364852748865098\n",
      "train loss:0.20533208230644198\n",
      "train loss:0.24090465533664712\n",
      "train loss:0.2120524540488549\n",
      "train loss:0.15808241310896828\n",
      "train loss:0.2077917633504259\n",
      "train loss:0.09112087942080459\n",
      "train loss:0.1770041130965455\n",
      "train loss:0.25887081321414707\n",
      "train loss:0.11989725923744227\n",
      "train loss:0.04832786926216773\n",
      "train loss:0.29935386307103984\n",
      "train loss:0.1531043280411354\n",
      "train loss:0.19900995756402381\n",
      "train loss:0.14376869515698165\n",
      "train loss:0.11828504857602466\n",
      "train loss:0.17082927637256212\n",
      "train loss:0.0858416269769432\n",
      "train loss:0.16582681552848114\n",
      "train loss:0.18310860817559463\n",
      "train loss:0.0993976330267208\n",
      "train loss:0.1466408489678611\n",
      "train loss:0.20818371512015768\n",
      "train loss:0.1350859529791662\n",
      "train loss:0.34280822832793445\n",
      "train loss:0.29077406440326536\n",
      "train loss:0.07407897171474391\n",
      "train loss:0.1089047938397403\n",
      "train loss:0.07886420833936635\n",
      "train loss:0.11767345294501945\n",
      "train loss:0.0888666596403708\n",
      "train loss:0.19772032228352088\n",
      "train loss:0.1733716670343582\n",
      "train loss:0.14504483822447878\n",
      "train loss:0.12284894577736108\n",
      "train loss:0.1379908956389017\n",
      "train loss:0.2547968043903225\n",
      "train loss:0.12407218464412789\n",
      "train loss:0.12228688699098944\n",
      "train loss:0.12397418069081245\n",
      "train loss:0.13133834273372014\n",
      "train loss:0.08712384200098443\n",
      "train loss:0.09806814261602387\n",
      "train loss:0.13997982650696245\n",
      "train loss:0.1428360412533487\n",
      "train loss:0.08374684571876397\n",
      "train loss:0.09365627758794655\n",
      "train loss:0.1751605119579251\n",
      "train loss:0.17582321027726636\n",
      "train loss:0.11678659305166222\n",
      "train loss:0.0638069103661997\n",
      "train loss:0.11043859897280951\n",
      "train loss:0.20136010783849106\n",
      "train loss:0.13046143202941607\n",
      "train loss:0.130595329383643\n",
      "train loss:0.15186025332893924\n",
      "train loss:0.17093653981777152\n",
      "train loss:0.31909601887414796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.21959311371937842\n",
      "train loss:0.07822718103864663\n",
      "train loss:0.0878400953000888\n",
      "train loss:0.13555741224370785\n",
      "train loss:0.10735820297239576\n",
      "train loss:0.19366044849801697\n",
      "train loss:0.09835172360485916\n",
      "train loss:0.20512144719472386\n",
      "train loss:0.083939286419899\n",
      "train loss:0.17855453177623395\n",
      "train loss:0.20716051068113703\n",
      "train loss:0.19093225272639394\n",
      "train loss:0.06377451023409197\n",
      "train loss:0.17965743310692592\n",
      "train loss:0.2277091740103813\n",
      "train loss:0.20400667203233208\n",
      "train loss:0.12397127607475662\n",
      "train loss:0.16232082028606842\n",
      "train loss:0.12682352767432556\n",
      "train loss:0.17247685839737456\n",
      "train loss:0.07762588248744318\n",
      "train loss:0.16899373953598065\n",
      "train loss:0.13778595303944555\n",
      "train loss:0.06527737150218552\n",
      "train loss:0.1435463711482696\n",
      "train loss:0.22639918451365634\n",
      "train loss:0.10957698627665673\n",
      "train loss:0.16935917083008495\n",
      "train loss:0.09459146979165474\n",
      "train loss:0.11685918180969415\n",
      "train loss:0.13977894052104806\n",
      "train loss:0.11250807946862051\n",
      "train loss:0.16560607244716377\n",
      "train loss:0.08621423772422869\n",
      "train loss:0.2052331356421767\n",
      "train loss:0.08243528800577474\n",
      "train loss:0.09428377294092911\n",
      "train loss:0.19697150063889005\n",
      "train loss:0.15998985611819927\n",
      "train loss:0.06871955950934674\n",
      "train loss:0.164916804912117\n",
      "train loss:0.1009496205599919\n",
      "train loss:0.17326556658592043\n",
      "train loss:0.15448077205082994\n",
      "train loss:0.04362035135423402\n",
      "train loss:0.1130418344474582\n",
      "train loss:0.04161128605463896\n",
      "train loss:0.17622608690428154\n",
      "train loss:0.11385168509252354\n",
      "train loss:0.187267810648175\n",
      "train loss:0.10830167785651863\n",
      "train loss:0.15156556775272137\n",
      "train loss:0.08587389750981636\n",
      "train loss:0.11001474672649943\n",
      "train loss:0.1209099447785437\n",
      "train loss:0.19955830226243468\n",
      "train loss:0.21379783964537716\n",
      "train loss:0.13636641411706013\n",
      "train loss:0.14642674381481774\n",
      "train loss:0.18435787718267718\n",
      "train loss:0.11149882893259176\n",
      "train loss:0.13032078304147426\n",
      "train loss:0.0985880665571382\n",
      "=== epoch:2, train acc:0.957, test acc:0.958 ===\n",
      "train loss:0.05866964506728951\n",
      "train loss:0.18421254946530727\n",
      "train loss:0.11646302884313142\n",
      "train loss:0.07655788784147005\n",
      "train loss:0.14699754415261443\n",
      "train loss:0.1957011814229882\n",
      "train loss:0.22636049944882872\n",
      "train loss:0.11035321573041436\n",
      "train loss:0.07084706865409655\n",
      "train loss:0.09428537571055015\n",
      "train loss:0.11576340173589235\n",
      "train loss:0.3128218440674345\n",
      "train loss:0.056088324209091524\n",
      "train loss:0.18989742572387416\n",
      "train loss:0.0914420051525734\n",
      "train loss:0.1260944346897228\n",
      "train loss:0.09776622350553112\n",
      "train loss:0.10789372566742193\n",
      "train loss:0.16629897713013986\n",
      "train loss:0.19258884772290796\n",
      "train loss:0.2662412328830364\n",
      "train loss:0.16229189401939983\n",
      "train loss:0.15335544996849296\n",
      "train loss:0.12499186444071303\n",
      "train loss:0.2206768081407926\n",
      "train loss:0.22853569564995513\n",
      "train loss:0.18661636207800109\n",
      "train loss:0.11375835270579536\n",
      "train loss:0.12141176089095382\n",
      "train loss:0.18573650074315978\n",
      "train loss:0.15773788321214155\n",
      "train loss:0.07243771155424962\n",
      "train loss:0.10235597819997815\n",
      "train loss:0.10377182789396948\n",
      "train loss:0.0962630697718292\n",
      "train loss:0.097910550602108\n",
      "train loss:0.07251121148596754\n",
      "train loss:0.08705301255312202\n",
      "train loss:0.21912825809371259\n",
      "train loss:0.07117038117719773\n",
      "train loss:0.14412528953350143\n",
      "train loss:0.08497860185270635\n",
      "train loss:0.1386381603164349\n",
      "train loss:0.15123269939034087\n",
      "train loss:0.1781067928333411\n",
      "train loss:0.16390661459592565\n",
      "train loss:0.06998287657585317\n",
      "train loss:0.09233156968992354\n",
      "train loss:0.06152838430933013\n",
      "train loss:0.16531981743701304\n",
      "train loss:0.10859562854866095\n",
      "train loss:0.08050739382874149\n",
      "train loss:0.08884930698868403\n",
      "train loss:0.10788547257359685\n",
      "train loss:0.3084023500101817\n",
      "train loss:0.08401798480141469\n",
      "train loss:0.17133454969444814\n",
      "train loss:0.25359567362688773\n",
      "train loss:0.06408088894623754\n",
      "train loss:0.1674180584777803\n",
      "train loss:0.12919847496564568\n",
      "train loss:0.12152747223765274\n",
      "train loss:0.28786027666555886\n",
      "train loss:0.10760656082662556\n",
      "train loss:0.129810288752691\n",
      "train loss:0.08459499777201376\n",
      "train loss:0.10946108391405232\n",
      "train loss:0.22623016371034402\n",
      "train loss:0.10061265366623008\n",
      "train loss:0.1370019050836127\n",
      "train loss:0.12190397133675632\n",
      "train loss:0.0981756451589314\n",
      "train loss:0.11660590635779174\n",
      "train loss:0.2100536358257366\n",
      "train loss:0.12699920924864394\n",
      "train loss:0.07837295393974461\n",
      "train loss:0.0682487727998598\n",
      "train loss:0.130713614285143\n",
      "train loss:0.1103452189491985\n",
      "train loss:0.10603570694952051\n",
      "train loss:0.16907384205470108\n",
      "train loss:0.17741646095331715\n",
      "train loss:0.09793880914173167\n",
      "train loss:0.11140280224239552\n",
      "train loss:0.08597990892894704\n",
      "train loss:0.07553061304404685\n",
      "train loss:0.12197413889597643\n",
      "train loss:0.14431265136364427\n",
      "train loss:0.0824099566891769\n",
      "train loss:0.06970566235145474\n",
      "train loss:0.11199417000361513\n",
      "train loss:0.13762840743857027\n",
      "train loss:0.1124550859767311\n",
      "train loss:0.09009470685000359\n",
      "train loss:0.11006988834518491\n",
      "train loss:0.10719208737555168\n",
      "train loss:0.1002812031205686\n",
      "train loss:0.10865312167327097\n",
      "train loss:0.05911995719172935\n",
      "train loss:0.11305347571804089\n",
      "train loss:0.20633467712906306\n",
      "train loss:0.06350250643188944\n",
      "train loss:0.049386884873332\n",
      "train loss:0.10150745205996432\n",
      "train loss:0.19629445509073523\n",
      "train loss:0.11342657961787411\n",
      "train loss:0.13577736262389561\n",
      "train loss:0.0742542133090625\n",
      "train loss:0.049206366312209156\n",
      "train loss:0.25574613748582953\n",
      "train loss:0.05240964465276387\n",
      "train loss:0.11265815250777696\n",
      "train loss:0.1749025639894373\n",
      "train loss:0.07189810914085945\n",
      "train loss:0.08955831061609071\n",
      "train loss:0.20497367705435743\n",
      "train loss:0.124674893432111\n",
      "train loss:0.27665646082218964\n",
      "train loss:0.1422787713044973\n",
      "train loss:0.07446166609745114\n",
      "train loss:0.18183556487980362\n",
      "train loss:0.04811934263111477\n",
      "train loss:0.19234049555082783\n",
      "train loss:0.1316180242311719\n",
      "train loss:0.1434965178987633\n",
      "train loss:0.11904218098243366\n",
      "train loss:0.07878234549678063\n",
      "train loss:0.1768510883248246\n",
      "train loss:0.11584774734981095\n",
      "train loss:0.08444288766009171\n",
      "train loss:0.1835414417119269\n",
      "train loss:0.20228622275147906\n",
      "train loss:0.062174718881821855\n",
      "train loss:0.03767238845854212\n",
      "train loss:0.10349524128662849\n",
      "train loss:0.13958276346761025\n",
      "train loss:0.060741336259116804\n",
      "train loss:0.09643204475339046\n",
      "train loss:0.0656871835280172\n",
      "train loss:0.03441315252731877\n",
      "train loss:0.15733420301381776\n",
      "train loss:0.11115418625845627\n",
      "train loss:0.09882084327921645\n",
      "train loss:0.08172179110863652\n",
      "train loss:0.14372800726432147\n",
      "train loss:0.11041785462140902\n",
      "train loss:0.10505920746187984\n",
      "train loss:0.07124243420386218\n",
      "train loss:0.13263528436676691\n",
      "train loss:0.1613175737902212\n",
      "train loss:0.12857391474683794\n",
      "train loss:0.07391814202539847\n",
      "train loss:0.13029534386273198\n",
      "train loss:0.12749772000484588\n",
      "train loss:0.12168933492635459\n",
      "train loss:0.050498160962129154\n",
      "train loss:0.11650931165583903\n",
      "train loss:0.11364605167023883\n",
      "train loss:0.10638666049929216\n",
      "train loss:0.09307065175619669\n",
      "train loss:0.1167184262848293\n",
      "train loss:0.04192510789229101\n",
      "train loss:0.06782993958438245\n",
      "train loss:0.06700350037032331\n",
      "train loss:0.12570930924077442\n",
      "train loss:0.11950094682658932\n",
      "train loss:0.09773030541374193\n",
      "train loss:0.0774601547635872\n",
      "train loss:0.17159569178488937\n",
      "train loss:0.09851592767505153\n",
      "train loss:0.1336594733068261\n",
      "train loss:0.09222804531584082\n",
      "train loss:0.09945662860918064\n",
      "train loss:0.06973356670872217\n",
      "train loss:0.10756541914818384\n",
      "train loss:0.11389524064975615\n",
      "train loss:0.1622890162038141\n",
      "train loss:0.08770993356602151\n",
      "train loss:0.175355362478677\n",
      "train loss:0.039238795053925406\n",
      "train loss:0.12367811459201045\n",
      "train loss:0.06244047358890567\n",
      "train loss:0.12068219926522737\n",
      "train loss:0.054380209897851535\n",
      "train loss:0.05314084544212954\n",
      "train loss:0.10109225199110858\n",
      "train loss:0.03444849351819519\n",
      "train loss:0.09900405492152992\n",
      "train loss:0.10332180446703056\n",
      "train loss:0.12927865728305435\n",
      "train loss:0.11233866011548503\n",
      "train loss:0.03645868791626792\n",
      "train loss:0.04028985963095454\n",
      "train loss:0.13423029382738755\n",
      "train loss:0.04203555656614893\n",
      "train loss:0.04660509964841029\n",
      "train loss:0.11677086563691033\n",
      "train loss:0.08460364766467793\n",
      "train loss:0.13967799434784203\n",
      "train loss:0.07402602401464725\n",
      "train loss:0.20180612630092476\n",
      "train loss:0.12263268455478986\n",
      "train loss:0.041567137485028265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07383419496482112\n",
      "train loss:0.05754431058586284\n",
      "train loss:0.09084110744141856\n",
      "train loss:0.10733219759634269\n",
      "train loss:0.0494962136124598\n",
      "train loss:0.0780393990781879\n",
      "train loss:0.1707015160588562\n",
      "train loss:0.1610942114529714\n",
      "train loss:0.0502094359660237\n",
      "train loss:0.04776995934368588\n",
      "train loss:0.07510067032860858\n",
      "train loss:0.11616116046260991\n",
      "train loss:0.05943779437455961\n",
      "train loss:0.09023000528535371\n",
      "train loss:0.08061224132467805\n",
      "train loss:0.20133493048371892\n",
      "train loss:0.09139783404376718\n",
      "train loss:0.1319814648850647\n",
      "train loss:0.05508868869572217\n",
      "train loss:0.043191476933522745\n",
      "train loss:0.07265319191362693\n",
      "train loss:0.08668589621645534\n",
      "train loss:0.05297107459615135\n",
      "train loss:0.05707113133922133\n",
      "train loss:0.15667287376343794\n",
      "train loss:0.1431417786011329\n",
      "train loss:0.07196416729303697\n",
      "train loss:0.05050099876823198\n",
      "train loss:0.031138231998462745\n",
      "train loss:0.09183026479463835\n",
      "train loss:0.07574426564358974\n",
      "train loss:0.14516380294674222\n",
      "train loss:0.12747113526580856\n",
      "train loss:0.11428464229138557\n",
      "train loss:0.11074818094719406\n",
      "train loss:0.06480118492100245\n",
      "train loss:0.08741648700363172\n",
      "train loss:0.07889110611296365\n",
      "train loss:0.14005044258740232\n",
      "train loss:0.04623938929488312\n",
      "train loss:0.12768517552903388\n",
      "train loss:0.2721939177399758\n",
      "train loss:0.1945401348901437\n",
      "train loss:0.09922097634027356\n",
      "train loss:0.14651434681407413\n",
      "train loss:0.04147443208475915\n",
      "train loss:0.054623785972354504\n",
      "train loss:0.07770748177289805\n",
      "train loss:0.08583047417328361\n",
      "train loss:0.16069103549988586\n",
      "train loss:0.13905443758355363\n",
      "train loss:0.11374232835281585\n",
      "train loss:0.0763403506932408\n",
      "train loss:0.10839569657383522\n",
      "train loss:0.09287582905828805\n",
      "train loss:0.11388775483429889\n",
      "train loss:0.05920828377537607\n",
      "train loss:0.09017372880786238\n",
      "train loss:0.1837284513100945\n",
      "train loss:0.059793207126207275\n",
      "train loss:0.0739835808705519\n",
      "train loss:0.09363961396656578\n",
      "train loss:0.21147606378037995\n",
      "train loss:0.07845665433672214\n",
      "train loss:0.08373102475670956\n",
      "train loss:0.06362407680310153\n",
      "train loss:0.10362070712044721\n",
      "train loss:0.16988023721366452\n",
      "train loss:0.03753837671712366\n",
      "train loss:0.13004170219341477\n",
      "train loss:0.06266181343066105\n",
      "train loss:0.0652499553927981\n",
      "train loss:0.054970199956537256\n",
      "train loss:0.07522397895197938\n",
      "train loss:0.08076668831300218\n",
      "train loss:0.061844244360927315\n",
      "train loss:0.08552548263870223\n",
      "train loss:0.14892347680750212\n",
      "train loss:0.09651068273128688\n",
      "train loss:0.04390418820733438\n",
      "train loss:0.12911011999294852\n",
      "train loss:0.08135927513816002\n",
      "train loss:0.1356215301303541\n",
      "train loss:0.052800026520610464\n",
      "train loss:0.05268477363470012\n",
      "train loss:0.14557531614121036\n",
      "train loss:0.07442071440327784\n",
      "train loss:0.1481539482224524\n",
      "train loss:0.1496033964572686\n",
      "train loss:0.04718431369839464\n",
      "train loss:0.04193414385800072\n",
      "train loss:0.16676404923319077\n",
      "train loss:0.11622027606056015\n",
      "train loss:0.06289776097560984\n",
      "train loss:0.09157627326341147\n",
      "train loss:0.10980704972324311\n",
      "train loss:0.10048629862616731\n",
      "train loss:0.06380786300546949\n",
      "train loss:0.032766265361190434\n",
      "train loss:0.0631463568068883\n",
      "train loss:0.07557211989567875\n",
      "train loss:0.09959334199456295\n",
      "train loss:0.034218122855405424\n",
      "train loss:0.06557999471705066\n",
      "train loss:0.08662501397769676\n",
      "train loss:0.1319887575339512\n",
      "train loss:0.12122071864370447\n",
      "train loss:0.03775078322335302\n",
      "train loss:0.1825966933996079\n",
      "train loss:0.06770718193376646\n",
      "train loss:0.045419009983890264\n",
      "train loss:0.06340650899822299\n",
      "train loss:0.2086468722688154\n",
      "train loss:0.18645621955986574\n",
      "train loss:0.20421140408205582\n",
      "train loss:0.06543080147454465\n",
      "train loss:0.06605087976875007\n",
      "train loss:0.07924957727337094\n",
      "train loss:0.052656537266599\n",
      "train loss:0.08897865973900812\n",
      "train loss:0.06125032781750162\n",
      "train loss:0.16928236000613586\n",
      "train loss:0.033783304342515634\n",
      "train loss:0.05878501923146943\n",
      "train loss:0.024754087955677524\n",
      "train loss:0.09497310016926346\n",
      "train loss:0.11919138546195368\n",
      "train loss:0.026501552341675626\n",
      "train loss:0.05467267025758314\n",
      "train loss:0.10439048522675332\n",
      "train loss:0.04472149020818537\n",
      "train loss:0.13000707697194203\n",
      "train loss:0.12494117820073077\n",
      "train loss:0.03164164106114459\n",
      "train loss:0.1212590271328157\n",
      "train loss:0.10105339074512758\n",
      "train loss:0.038017574592453\n",
      "train loss:0.053433895942161184\n",
      "train loss:0.01918077379760801\n",
      "train loss:0.047263566592416976\n",
      "train loss:0.054535602556439536\n",
      "train loss:0.030298398456061616\n",
      "train loss:0.030539448947006935\n",
      "train loss:0.08676914301420138\n",
      "train loss:0.054197534809670926\n",
      "train loss:0.045119919109649034\n",
      "train loss:0.05190460232622574\n",
      "train loss:0.1049768949615982\n",
      "train loss:0.17590919140899808\n",
      "train loss:0.022048569840787405\n",
      "train loss:0.0234170087586798\n",
      "train loss:0.10334011791443222\n",
      "train loss:0.14811133745551922\n",
      "train loss:0.03330286245723079\n",
      "train loss:0.14912763475822544\n",
      "train loss:0.03389832477021163\n",
      "train loss:0.07398354449464065\n",
      "train loss:0.09873688725830551\n",
      "train loss:0.13635069707758554\n",
      "train loss:0.06571462224699995\n",
      "train loss:0.10658390083688607\n",
      "train loss:0.04194680403111259\n",
      "train loss:0.10664743339004783\n",
      "train loss:0.05313930105816854\n",
      "train loss:0.05143747929372636\n",
      "train loss:0.053007865934462634\n",
      "train loss:0.10192236256806053\n",
      "train loss:0.12804376535661968\n",
      "train loss:0.08208959750906995\n",
      "train loss:0.074500063119111\n",
      "train loss:0.03801958344158499\n",
      "train loss:0.0689150442770018\n",
      "train loss:0.07412653564311011\n",
      "train loss:0.027977367758094097\n",
      "train loss:0.04842671850616226\n",
      "train loss:0.07873902174546453\n",
      "train loss:0.09957996582818657\n",
      "train loss:0.0735308194312704\n",
      "train loss:0.05208498241706709\n",
      "train loss:0.040963797482562396\n",
      "train loss:0.08647568457875074\n",
      "train loss:0.10616363777071504\n",
      "train loss:0.08780773310410032\n",
      "train loss:0.0699989252925765\n",
      "train loss:0.07082301367217698\n",
      "train loss:0.0987884854180426\n",
      "train loss:0.10993729318758652\n",
      "train loss:0.11869218959716756\n",
      "train loss:0.027828703465068143\n",
      "train loss:0.07691535809853417\n",
      "train loss:0.11422721468094105\n",
      "train loss:0.08235938679987682\n",
      "train loss:0.08188507035409547\n",
      "train loss:0.22392672063785107\n",
      "train loss:0.06662028123820432\n",
      "train loss:0.09202182110287188\n",
      "train loss:0.09212673275724104\n",
      "train loss:0.13575625803760233\n",
      "train loss:0.10224000545124938\n",
      "train loss:0.04438929097322084\n",
      "train loss:0.0538014222116759\n",
      "train loss:0.032648815304229764\n",
      "train loss:0.04290387232783208\n",
      "train loss:0.05881627607449119\n",
      "train loss:0.04186215510447135\n",
      "train loss:0.07053655596750584\n",
      "train loss:0.0770622307406365\n",
      "train loss:0.04772731373370251\n",
      "train loss:0.027282147078928558\n",
      "train loss:0.0469390778100368\n",
      "train loss:0.0828044235417063\n",
      "train loss:0.14912220519901853\n",
      "train loss:0.12357871470718594\n",
      "train loss:0.10300923546379166\n",
      "train loss:0.1916215109712877\n",
      "train loss:0.03218048249960879\n",
      "train loss:0.11236158399479383\n",
      "train loss:0.06787767743342109\n",
      "train loss:0.04230764149094478\n",
      "train loss:0.05065298809714167\n",
      "train loss:0.06518955936445096\n",
      "train loss:0.0491632098631907\n",
      "train loss:0.04050355694074426\n",
      "train loss:0.09775309257787174\n",
      "train loss:0.028614714850412608\n",
      "train loss:0.12400236057199247\n",
      "train loss:0.26694921476229283\n",
      "train loss:0.09420102931710561\n",
      "train loss:0.08015477587324879\n",
      "train loss:0.06746941846135988\n",
      "train loss:0.08803336456172406\n",
      "train loss:0.11325662298977746\n",
      "train loss:0.02600954015660083\n",
      "train loss:0.1195382790468129\n",
      "train loss:0.04626550431752824\n",
      "train loss:0.048174100845220044\n",
      "train loss:0.0655006397803473\n",
      "train loss:0.07957965083647531\n",
      "train loss:0.11636609855065096\n",
      "train loss:0.057547645548835825\n",
      "train loss:0.04256349283126522\n",
      "train loss:0.050165974757032404\n",
      "train loss:0.07216114147215451\n",
      "train loss:0.03511458776488971\n",
      "train loss:0.1812201734225048\n",
      "train loss:0.06620326374664699\n",
      "train loss:0.08436268981118573\n",
      "train loss:0.07824321939260191\n",
      "train loss:0.10522640609641996\n",
      "train loss:0.06378340815714786\n",
      "train loss:0.09195395340518649\n",
      "train loss:0.06915984998968314\n",
      "train loss:0.10606771379486235\n",
      "train loss:0.11763394306098578\n",
      "train loss:0.0415969704469368\n",
      "train loss:0.12228910254764491\n",
      "train loss:0.05577707658876507\n",
      "train loss:0.06493730103453393\n",
      "train loss:0.043546141438402595\n",
      "train loss:0.040808547563098214\n",
      "train loss:0.07874030105284988\n",
      "train loss:0.07331536984992043\n",
      "train loss:0.05775457092578469\n",
      "train loss:0.09434667679978492\n",
      "train loss:0.0523816456695978\n",
      "train loss:0.04662476344782815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08960601242200422\n",
      "train loss:0.05322987825381078\n",
      "train loss:0.04492376124199943\n",
      "train loss:0.017444796288269285\n",
      "train loss:0.03155713940238387\n",
      "train loss:0.03247554850967678\n",
      "train loss:0.06098359113744472\n",
      "train loss:0.06631514937048882\n",
      "train loss:0.02652947661834766\n",
      "train loss:0.04586142330843674\n",
      "train loss:0.0461536921960626\n",
      "train loss:0.04312527640582911\n",
      "train loss:0.06368716824908718\n",
      "train loss:0.07723155833131626\n",
      "train loss:0.03157544063327164\n",
      "train loss:0.027693982637710376\n",
      "train loss:0.04718872074350904\n",
      "train loss:0.09050115113018026\n",
      "train loss:0.029524733437657828\n",
      "train loss:0.07224560589776205\n",
      "train loss:0.06286526602582891\n",
      "train loss:0.1226389174195499\n",
      "train loss:0.1118614619453627\n",
      "train loss:0.1095044873979547\n",
      "train loss:0.03740237664713618\n",
      "train loss:0.02301664709764615\n",
      "train loss:0.04056312547590976\n",
      "train loss:0.11571919647377861\n",
      "train loss:0.05955792808874873\n",
      "train loss:0.05118625519647038\n",
      "train loss:0.08071062933838238\n",
      "train loss:0.05384577612213999\n",
      "train loss:0.03994241121916717\n",
      "train loss:0.05065632334829617\n",
      "train loss:0.06372605587641829\n",
      "train loss:0.05900603079430609\n",
      "train loss:0.10446388704656498\n",
      "train loss:0.07613250743792029\n",
      "train loss:0.05493655533477814\n",
      "train loss:0.034829761750627894\n",
      "train loss:0.10989480083047379\n",
      "train loss:0.07959126328616307\n",
      "train loss:0.04058296858253847\n",
      "train loss:0.029881741108634268\n",
      "train loss:0.05805160178778154\n",
      "train loss:0.21585591950556965\n",
      "train loss:0.07728481337282014\n",
      "train loss:0.029950302373944675\n",
      "train loss:0.06766277856916413\n",
      "train loss:0.07728311017154438\n",
      "train loss:0.1065875728417716\n",
      "train loss:0.10945733070982021\n",
      "train loss:0.06976263407991284\n",
      "train loss:0.05624412937140848\n",
      "train loss:0.04077954929987206\n",
      "train loss:0.09136337372465513\n",
      "train loss:0.05768823837994344\n",
      "train loss:0.06010972691739825\n",
      "train loss:0.06942625745213912\n",
      "train loss:0.1054397782782395\n",
      "train loss:0.11074296011604487\n",
      "train loss:0.01858758129004391\n",
      "train loss:0.06661044432708176\n",
      "train loss:0.10706570180786203\n",
      "train loss:0.09010144781544939\n",
      "train loss:0.06368473109462579\n",
      "train loss:0.09589724732686818\n",
      "train loss:0.21330154534066548\n",
      "train loss:0.03554182924508645\n",
      "train loss:0.044448395138741124\n",
      "train loss:0.07394326312969703\n",
      "train loss:0.09597413255565015\n",
      "train loss:0.024929798450147724\n",
      "train loss:0.060293723061941924\n",
      "train loss:0.12018737136251768\n",
      "train loss:0.0762904324325865\n",
      "train loss:0.13969621544309127\n",
      "train loss:0.04871802038809622\n",
      "train loss:0.10110063460692494\n",
      "train loss:0.10907772889660086\n",
      "train loss:0.26354924820374764\n",
      "train loss:0.04349629751359382\n",
      "train loss:0.06575998971183097\n",
      "train loss:0.15043171951325518\n",
      "train loss:0.043258259862328716\n",
      "train loss:0.0533866208837754\n",
      "train loss:0.04972213481892415\n",
      "train loss:0.0412258976264647\n",
      "train loss:0.04033300902205378\n",
      "train loss:0.06850940186363218\n",
      "train loss:0.04052415887503768\n",
      "train loss:0.10144555034370524\n",
      "train loss:0.07248284664663825\n",
      "train loss:0.1547091467338768\n",
      "train loss:0.06596225919550094\n",
      "train loss:0.0994208574028803\n",
      "train loss:0.03862347879093131\n",
      "train loss:0.0267074350052022\n",
      "train loss:0.06339591078695636\n",
      "train loss:0.07400998826972142\n",
      "train loss:0.03968679592710592\n",
      "train loss:0.02011863489828823\n",
      "train loss:0.050380877632478054\n",
      "train loss:0.1103717809601652\n",
      "train loss:0.029771574526332237\n",
      "train loss:0.06878599169113969\n",
      "train loss:0.08179375241978355\n",
      "train loss:0.06392995613488157\n",
      "train loss:0.03050774025153554\n",
      "train loss:0.07520921788663588\n",
      "train loss:0.029543360477217933\n",
      "train loss:0.03298649055373373\n",
      "train loss:0.05330847359201415\n",
      "train loss:0.09614234735562453\n",
      "train loss:0.049552407059188334\n",
      "train loss:0.0347967348909063\n",
      "train loss:0.06751777531598685\n",
      "train loss:0.034898783003768384\n",
      "train loss:0.09574066101451811\n",
      "train loss:0.2784541762308926\n",
      "train loss:0.0914671011592602\n",
      "train loss:0.069111434465553\n",
      "train loss:0.06812787862326682\n",
      "train loss:0.05763900434655904\n",
      "train loss:0.06286938863280786\n",
      "train loss:0.0981535350155202\n",
      "train loss:0.06807912824649652\n",
      "train loss:0.10821706318919709\n",
      "train loss:0.017467227802259504\n",
      "train loss:0.06622847426865269\n",
      "train loss:0.033996192430853764\n",
      "=== epoch:3, train acc:0.969, test acc:0.973 ===\n",
      "train loss:0.11153236106684689\n",
      "train loss:0.043309782831695606\n",
      "train loss:0.10461188312141273\n",
      "train loss:0.06240542124795103\n",
      "train loss:0.0527809656403751\n",
      "train loss:0.09622175093300676\n",
      "train loss:0.09625191712979682\n",
      "train loss:0.09836097426371702\n",
      "train loss:0.10425963269357466\n",
      "train loss:0.03396979039003153\n",
      "train loss:0.031079723029028852\n",
      "train loss:0.08650930095307141\n",
      "train loss:0.05214263542653651\n",
      "train loss:0.05629192409300087\n",
      "train loss:0.15381996127171818\n",
      "train loss:0.03581315820110543\n",
      "train loss:0.055963460109192155\n",
      "train loss:0.06419282145985931\n",
      "train loss:0.15836263692172958\n",
      "train loss:0.10817609662651538\n",
      "train loss:0.041697055315622594\n",
      "train loss:0.11375201760719818\n",
      "train loss:0.11805808903743684\n",
      "train loss:0.06365595275496715\n",
      "train loss:0.0601378194456107\n",
      "train loss:0.06158894601374098\n",
      "train loss:0.027626881930649116\n",
      "train loss:0.10182937995423023\n",
      "train loss:0.12330460944100748\n",
      "train loss:0.13753581621512334\n",
      "train loss:0.045356613670409135\n",
      "train loss:0.0680480264371702\n",
      "train loss:0.04402968955180752\n",
      "train loss:0.11733761480314263\n",
      "train loss:0.06217934822711481\n",
      "train loss:0.07653829354133243\n",
      "train loss:0.03885501432829389\n",
      "train loss:0.1403620096824334\n",
      "train loss:0.05335005675933247\n",
      "train loss:0.060777622870623785\n",
      "train loss:0.06391435225788748\n",
      "train loss:0.05686912090032974\n",
      "train loss:0.06182897056294883\n",
      "train loss:0.019021829812666\n",
      "train loss:0.08429670875417777\n",
      "train loss:0.05350082657840483\n",
      "train loss:0.059246686071198755\n",
      "train loss:0.06486665500810677\n",
      "train loss:0.054934225177715616\n",
      "train loss:0.028832662599856763\n",
      "train loss:0.1774701473746855\n",
      "train loss:0.06892979007882716\n",
      "train loss:0.010432222093881971\n",
      "train loss:0.020387917196800987\n",
      "train loss:0.09799122576554728\n",
      "train loss:0.07864721931491313\n",
      "train loss:0.0300508870475326\n",
      "train loss:0.0590494150593772\n",
      "train loss:0.03580647721404612\n",
      "train loss:0.05748639708533638\n",
      "train loss:0.10511053058681766\n",
      "train loss:0.03313849422978867\n",
      "train loss:0.03730423937537304\n",
      "train loss:0.09052887715452859\n",
      "train loss:0.0451078698443891\n",
      "train loss:0.04723241915257132\n",
      "train loss:0.07402692683037451\n",
      "train loss:0.11225779757281135\n",
      "train loss:0.07295919061212279\n",
      "train loss:0.06322666046806984\n",
      "train loss:0.04940630123595627\n",
      "train loss:0.03780476468569261\n",
      "train loss:0.05801962798693637\n",
      "train loss:0.0437587774626\n",
      "train loss:0.12479757800213659\n",
      "train loss:0.03365247829750034\n",
      "train loss:0.040432801901534844\n",
      "train loss:0.0892431703989697\n",
      "train loss:0.07344805155308846\n",
      "train loss:0.13235095643549474\n",
      "train loss:0.05065122548776923\n",
      "train loss:0.041262142474160476\n",
      "train loss:0.09688640060045559\n",
      "train loss:0.08887129080609109\n",
      "train loss:0.06002944280362705\n",
      "train loss:0.04187590934166462\n",
      "train loss:0.07889201952916336\n",
      "train loss:0.10244780138801925\n",
      "train loss:0.05492274114367334\n",
      "train loss:0.05304805952958702\n",
      "train loss:0.017095382466923544\n",
      "train loss:0.021670341830242034\n",
      "train loss:0.03086687029347273\n",
      "train loss:0.07037415572243406\n",
      "train loss:0.1457890949490297\n",
      "train loss:0.13035908117348594\n",
      "train loss:0.08251248119636825\n",
      "train loss:0.08007287906507189\n",
      "train loss:0.0363595970750165\n",
      "train loss:0.08141772781930752\n",
      "train loss:0.038806476539845036\n",
      "train loss:0.02608223461029821\n",
      "train loss:0.028579804849354788\n",
      "train loss:0.05148363937547578\n",
      "train loss:0.06470877885000932\n",
      "train loss:0.08736385031683637\n",
      "train loss:0.03466009600855002\n",
      "train loss:0.07861274077452163\n",
      "train loss:0.08886660678279662\n",
      "train loss:0.03854556672456678\n",
      "train loss:0.08127609616658697\n",
      "train loss:0.06450835808355487\n",
      "train loss:0.01700500938077191\n",
      "train loss:0.05955348068169531\n",
      "train loss:0.06204367748053445\n",
      "train loss:0.041206188016334994\n",
      "train loss:0.05343371498021629\n",
      "train loss:0.0449787995010641\n",
      "train loss:0.020396146446010274\n",
      "train loss:0.1651833126495179\n",
      "train loss:0.09273529491920408\n",
      "train loss:0.06670261474509537\n",
      "train loss:0.07255779890575179\n",
      "train loss:0.09394653068041871\n",
      "train loss:0.04108049539941006\n",
      "train loss:0.040934989067382174\n",
      "train loss:0.054290362656274356\n",
      "train loss:0.03917114185392331\n",
      "train loss:0.06053400573976436\n",
      "train loss:0.01938251689462204\n",
      "train loss:0.03951526951635941\n",
      "train loss:0.09421028583751218\n",
      "train loss:0.02826945013433492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1099486786258714\n",
      "train loss:0.031121504267277434\n",
      "train loss:0.1117350192231147\n",
      "train loss:0.040254019928893714\n",
      "train loss:0.0616750488055965\n",
      "train loss:0.027464116512729567\n",
      "train loss:0.0625916142253603\n",
      "train loss:0.09451150435026355\n",
      "train loss:0.054001219934458174\n",
      "train loss:0.16198044405783554\n",
      "train loss:0.14057145098050905\n",
      "train loss:0.05173462132491738\n",
      "train loss:0.0753634234420364\n",
      "train loss:0.08414861558983261\n",
      "train loss:0.018583166837837867\n",
      "train loss:0.036632339696105555\n",
      "train loss:0.02665047273365709\n",
      "train loss:0.021249626880540533\n",
      "train loss:0.050967721893045076\n",
      "train loss:0.03978095260523808\n",
      "train loss:0.052217848669179785\n",
      "train loss:0.026912184155015242\n",
      "train loss:0.09868273995750004\n",
      "train loss:0.04622910072246945\n",
      "train loss:0.06733142573920672\n",
      "train loss:0.02559945962077294\n",
      "train loss:0.04295345401007956\n",
      "train loss:0.03989867310097031\n",
      "train loss:0.11925804170623229\n",
      "train loss:0.11302398462461329\n",
      "train loss:0.08058062702619682\n",
      "train loss:0.044709742010811876\n",
      "train loss:0.038694662830536145\n",
      "train loss:0.06419365469783606\n",
      "train loss:0.1609235264755412\n",
      "train loss:0.06072663512901389\n",
      "train loss:0.045565929205302814\n",
      "train loss:0.04612290065817201\n",
      "train loss:0.10443389500752145\n",
      "train loss:0.07379418200579764\n",
      "train loss:0.06174993980600047\n",
      "train loss:0.05203793465610511\n",
      "train loss:0.05159318448466645\n",
      "train loss:0.03378956014551368\n",
      "train loss:0.06799894709417195\n",
      "train loss:0.0534969228695044\n",
      "train loss:0.03529665271677041\n",
      "train loss:0.04996575092032579\n",
      "train loss:0.0800033373903312\n",
      "train loss:0.04313038076026133\n",
      "train loss:0.06013427098821505\n",
      "train loss:0.028518018128487803\n",
      "train loss:0.035810618524512415\n",
      "train loss:0.018298457014852384\n",
      "train loss:0.11713743350825986\n",
      "train loss:0.043200993721513384\n",
      "train loss:0.03654652847916391\n",
      "train loss:0.026483884303771073\n",
      "train loss:0.082447038368258\n",
      "train loss:0.08754694891407898\n",
      "train loss:0.05755649917812174\n",
      "train loss:0.03393811563531776\n",
      "train loss:0.1394856724301358\n",
      "train loss:0.03872936582102673\n",
      "train loss:0.12945383764420593\n",
      "train loss:0.06472537542295084\n",
      "train loss:0.10343197941707279\n",
      "train loss:0.05188972946275908\n",
      "train loss:0.09087227708213122\n",
      "train loss:0.06383426208474734\n",
      "train loss:0.11436261902370999\n",
      "train loss:0.0775264395011614\n",
      "train loss:0.13234640685037133\n",
      "train loss:0.06512171508094208\n",
      "train loss:0.058518893211886046\n",
      "train loss:0.04870502965700313\n",
      "train loss:0.07966729213420681\n",
      "train loss:0.027793959166105973\n",
      "train loss:0.05782377481775683\n",
      "train loss:0.07687234562101478\n",
      "train loss:0.022174040268295777\n",
      "train loss:0.06137794679775733\n",
      "train loss:0.07909038437856636\n",
      "train loss:0.06346874629171861\n",
      "train loss:0.05280363978592589\n",
      "train loss:0.04189709800521943\n",
      "train loss:0.06129701171287233\n",
      "train loss:0.09623128979643238\n",
      "train loss:0.030173955698168477\n",
      "train loss:0.03582771306588196\n",
      "train loss:0.0233996360938126\n",
      "train loss:0.08170625318035446\n",
      "train loss:0.04668284638212704\n",
      "train loss:0.05623399648558794\n",
      "train loss:0.053458703943559574\n",
      "train loss:0.020576191903822164\n",
      "train loss:0.012501912087130428\n",
      "train loss:0.015251622332733522\n",
      "train loss:0.062131289397113015\n",
      "train loss:0.05665726387959569\n",
      "train loss:0.09049485108566376\n",
      "train loss:0.04204512621995533\n",
      "train loss:0.0756300765092064\n",
      "train loss:0.01419957151563103\n",
      "train loss:0.15032333673103257\n",
      "train loss:0.07024760437132413\n",
      "train loss:0.16059298173612074\n",
      "train loss:0.022112564367977598\n",
      "train loss:0.04958156963518623\n",
      "train loss:0.03734737067218866\n",
      "train loss:0.0966128846839951\n",
      "train loss:0.027190914421925227\n",
      "train loss:0.043969160234494584\n",
      "train loss:0.07196131478022635\n",
      "train loss:0.04090902419721073\n",
      "train loss:0.038424909296978234\n",
      "train loss:0.04030518618893399\n",
      "train loss:0.11804876565075893\n",
      "train loss:0.01988019387053144\n",
      "train loss:0.02526166443065144\n",
      "train loss:0.12548559161859918\n",
      "train loss:0.05969928717288145\n",
      "train loss:0.017908864959689984\n",
      "train loss:0.08103222986626321\n",
      "train loss:0.07325719087655054\n",
      "train loss:0.0633137961253432\n",
      "train loss:0.15435090941905044\n",
      "train loss:0.06164957863699836\n",
      "train loss:0.0735621238662291\n",
      "train loss:0.06794249657707493\n",
      "train loss:0.04019101456084383\n",
      "train loss:0.05765135860150766\n",
      "train loss:0.13490902207356634\n",
      "train loss:0.11973776533518463\n",
      "train loss:0.038819631153751435\n",
      "train loss:0.08881418277583322\n",
      "train loss:0.023749913298546584\n",
      "train loss:0.06861529353326146\n",
      "train loss:0.028402598415457822\n",
      "train loss:0.03595745803719843\n",
      "train loss:0.024839643118131357\n",
      "train loss:0.023075388533458405\n",
      "train loss:0.22670401899760192\n",
      "train loss:0.07312688934912322\n",
      "train loss:0.07220475991899533\n",
      "train loss:0.02155279998117838\n",
      "train loss:0.040147250744657484\n",
      "train loss:0.05297386509659031\n",
      "train loss:0.053085550553526775\n",
      "train loss:0.03246139067601685\n",
      "train loss:0.07521455789778189\n",
      "train loss:0.04867262474301854\n",
      "train loss:0.06385471561657638\n",
      "train loss:0.011818703532255965\n",
      "train loss:0.08471208526493916\n",
      "train loss:0.021874849108067456\n",
      "train loss:0.045000589569013545\n",
      "train loss:0.02541496169187686\n",
      "train loss:0.04747421397985228\n",
      "train loss:0.026986353931634476\n",
      "train loss:0.08924858353836657\n",
      "train loss:0.12710564775356853\n",
      "train loss:0.06021439301408425\n",
      "train loss:0.02325284237802786\n",
      "train loss:0.05800879325728779\n",
      "train loss:0.05162476726564229\n",
      "train loss:0.024842272297062568\n",
      "train loss:0.053292046116719075\n",
      "train loss:0.014838163930307093\n",
      "train loss:0.027000291011415118\n",
      "train loss:0.018811339134306423\n",
      "train loss:0.04851613432985382\n",
      "train loss:0.057325537377758334\n",
      "train loss:0.08513951832058844\n",
      "train loss:0.1515221360309855\n",
      "train loss:0.05636705002417536\n",
      "train loss:0.023089684043620315\n",
      "train loss:0.051808141866148086\n",
      "train loss:0.03988996424626135\n",
      "train loss:0.11594207470452803\n",
      "train loss:0.09383870349616005\n",
      "train loss:0.03346466378469382\n",
      "train loss:0.07307888704579872\n",
      "train loss:0.10009727458908531\n",
      "train loss:0.11495701891840658\n",
      "train loss:0.061992498496550835\n",
      "train loss:0.0744569653416908\n",
      "train loss:0.058377717333597055\n",
      "train loss:0.018847146732195036\n",
      "train loss:0.06947971883856413\n",
      "train loss:0.052853491274566095\n",
      "train loss:0.023862588414169262\n",
      "train loss:0.04987753151413064\n",
      "train loss:0.035270109765741936\n",
      "train loss:0.05532507984781138\n",
      "train loss:0.012902801435939302\n",
      "train loss:0.042805431462106275\n",
      "train loss:0.05682504742824854\n",
      "train loss:0.05426607832157763\n",
      "train loss:0.014377307020529893\n",
      "train loss:0.036780512412071406\n",
      "train loss:0.017132428993306234\n",
      "train loss:0.10080100304983225\n",
      "train loss:0.03148692958111608\n",
      "train loss:0.010271365546478813\n",
      "train loss:0.05659163528080049\n",
      "train loss:0.027789282492373623\n",
      "train loss:0.04241538020212086\n",
      "train loss:0.11965348657384428\n",
      "train loss:0.015345299192821585\n",
      "train loss:0.02745825894799341\n",
      "train loss:0.08354900452467186\n",
      "train loss:0.038167302338132716\n",
      "train loss:0.0516897535466885\n",
      "train loss:0.02933178665572602\n",
      "train loss:0.06014882243697236\n",
      "train loss:0.033595309693549964\n",
      "train loss:0.024557205426767363\n",
      "train loss:0.030106263584810448\n",
      "train loss:0.05446506306547568\n",
      "train loss:0.06176708726867441\n",
      "train loss:0.05536175210268914\n",
      "train loss:0.07511993108623401\n",
      "train loss:0.08339221524360267\n",
      "train loss:0.05558494058484561\n",
      "train loss:0.08675363991410782\n",
      "train loss:0.02294526531757922\n",
      "train loss:0.021723158639798356\n",
      "train loss:0.13752603525702795\n",
      "train loss:0.013722363484341471\n",
      "train loss:0.054455708150960055\n",
      "train loss:0.021395874972725118\n",
      "train loss:0.02524242723619293\n",
      "train loss:0.07588180566116948\n",
      "train loss:0.14185432111789434\n",
      "train loss:0.07300080232664276\n",
      "train loss:0.06211043448967378\n",
      "train loss:0.09658238203363234\n",
      "train loss:0.05283165758170043\n",
      "train loss:0.05130810366414286\n",
      "train loss:0.03384198479714154\n",
      "train loss:0.02317306785773695\n",
      "train loss:0.04641118814817731\n",
      "train loss:0.06765790147666681\n",
      "train loss:0.10247357220384844\n",
      "train loss:0.03354356202318363\n",
      "train loss:0.04495327901745728\n",
      "train loss:0.09084189222457568\n",
      "train loss:0.1089221479850637\n",
      "train loss:0.01255919248327582\n",
      "train loss:0.10579103771762782\n",
      "train loss:0.0383121291258063\n",
      "train loss:0.05520201447132131\n",
      "train loss:0.048355786283460246\n",
      "train loss:0.04076008327821373\n",
      "train loss:0.03273934970561792\n",
      "train loss:0.028417190878219062\n",
      "train loss:0.01909127806280144\n",
      "train loss:0.061080589279456865\n",
      "train loss:0.01785805515843514\n",
      "train loss:0.046815109824439816\n",
      "train loss:0.07889713442660409\n",
      "train loss:0.0944678109180299\n",
      "train loss:0.047407022892501864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03313613251461885\n",
      "train loss:0.03246974642032435\n",
      "train loss:0.046625292202351586\n",
      "train loss:0.08778200984939467\n",
      "train loss:0.08900115184870451\n",
      "train loss:0.08813730622446063\n",
      "train loss:0.01927155424981966\n",
      "train loss:0.03709832678283354\n",
      "train loss:0.0847561437337871\n",
      "train loss:0.04080280202164926\n",
      "train loss:0.08405642607435784\n",
      "train loss:0.036893956116206064\n",
      "train loss:0.0516573294573503\n",
      "train loss:0.06150339648132433\n",
      "train loss:0.01634968088031431\n",
      "train loss:0.031002280341226603\n",
      "train loss:0.05503519404429083\n",
      "train loss:0.04409580246256582\n",
      "train loss:0.04377394839841122\n",
      "train loss:0.1091567714548925\n",
      "train loss:0.10912218753094095\n",
      "train loss:0.015754050363730322\n",
      "train loss:0.02288969406193508\n",
      "train loss:0.028844771685244068\n",
      "train loss:0.010454468951724711\n",
      "train loss:0.0332737963003017\n",
      "train loss:0.05839766270142575\n",
      "train loss:0.035743832991804864\n",
      "train loss:0.01695556261557933\n",
      "train loss:0.14345368465267055\n",
      "train loss:0.04959916493141961\n",
      "train loss:0.11908141372994004\n",
      "train loss:0.048759121030639355\n",
      "train loss:0.056985110899488364\n",
      "train loss:0.014616656356417197\n",
      "train loss:0.06000225204579987\n",
      "train loss:0.02707943231550794\n",
      "train loss:0.020956760284479962\n",
      "train loss:0.03787429463706486\n",
      "train loss:0.06539513180297861\n",
      "train loss:0.025797584227219606\n",
      "train loss:0.062392504230317364\n",
      "train loss:0.06529689826211234\n",
      "train loss:0.01881604797913831\n",
      "train loss:0.05405572713099117\n",
      "train loss:0.05564646673212983\n",
      "train loss:0.05313283520596682\n",
      "train loss:0.02941240351627517\n",
      "train loss:0.014817332259535325\n",
      "train loss:0.079680810164888\n",
      "train loss:0.06101488412731614\n",
      "train loss:0.037456149146968876\n",
      "train loss:0.04806658726705491\n",
      "train loss:0.04842472125072977\n",
      "train loss:0.0750975568073597\n",
      "train loss:0.01041685246077139\n",
      "train loss:0.05570045488597927\n",
      "train loss:0.034972746249927925\n",
      "train loss:0.07575392911444304\n",
      "train loss:0.09476163261550441\n",
      "train loss:0.02404737295464606\n",
      "train loss:0.04368287026039609\n",
      "train loss:0.018223425380236444\n",
      "train loss:0.061824161919596034\n",
      "train loss:0.04805255560049514\n",
      "train loss:0.05866172555246338\n",
      "train loss:0.029237117167047844\n",
      "train loss:0.04210555828057722\n",
      "train loss:0.024489790098702717\n",
      "train loss:0.04399963008891495\n",
      "train loss:0.033161338470999835\n",
      "train loss:0.061847933705429466\n",
      "train loss:0.05615941978819355\n",
      "train loss:0.030015059270595477\n",
      "train loss:0.10519249712785672\n",
      "train loss:0.09619618300028801\n",
      "train loss:0.1314081346699515\n",
      "train loss:0.05710259098754719\n",
      "train loss:0.016467196695266095\n",
      "train loss:0.10370467566118304\n",
      "train loss:0.0452367222083383\n",
      "train loss:0.040249098340621986\n",
      "train loss:0.02793486700089569\n",
      "train loss:0.11657115818203344\n",
      "train loss:0.05684415883955081\n",
      "train loss:0.04772651202695616\n",
      "train loss:0.013710093168368203\n",
      "train loss:0.037541186377484353\n",
      "train loss:0.06928827263782679\n",
      "train loss:0.027070497258665057\n",
      "train loss:0.04252367182639769\n",
      "train loss:0.029480118346128008\n",
      "train loss:0.1037557886458193\n",
      "train loss:0.07052180895588367\n",
      "train loss:0.06649861284841006\n",
      "train loss:0.00838848281466354\n",
      "train loss:0.02599931597026932\n",
      "train loss:0.01820674748363591\n",
      "train loss:0.05163064625067307\n",
      "train loss:0.10838739253912064\n",
      "train loss:0.030908987821941028\n",
      "train loss:0.04776761368474825\n",
      "train loss:0.03695521894152822\n",
      "train loss:0.009719547556942236\n",
      "train loss:0.07297097023402026\n",
      "train loss:0.01617311988097224\n",
      "train loss:0.07012271508287746\n",
      "train loss:0.0399783457952314\n",
      "train loss:0.021402103679342605\n",
      "train loss:0.029856931118220662\n",
      "train loss:0.012053006316001503\n",
      "train loss:0.1112161812636061\n",
      "train loss:0.031587974296114735\n",
      "train loss:0.04870784343022834\n",
      "train loss:0.013548157128155264\n",
      "train loss:0.01126781087136285\n",
      "train loss:0.04611823219404022\n",
      "train loss:0.15512968025519772\n",
      "train loss:0.02118756819172117\n",
      "train loss:0.022831968214128206\n",
      "train loss:0.012219285504911859\n",
      "train loss:0.039450079307138085\n",
      "train loss:0.015076474481497938\n",
      "train loss:0.08102430004190309\n",
      "train loss:0.012775620181087308\n",
      "train loss:0.01814336841689018\n",
      "train loss:0.0204389141224334\n",
      "train loss:0.024292867072933363\n",
      "train loss:0.019631252785182667\n",
      "train loss:0.10391151846766254\n",
      "train loss:0.010569794572974125\n",
      "train loss:0.02674464975999738\n",
      "train loss:0.0511536418317184\n",
      "train loss:0.09163172508051025\n",
      "train loss:0.035959456172941405\n",
      "train loss:0.06630418223874567\n",
      "train loss:0.030789518855283048\n",
      "train loss:0.04533487736121547\n",
      "train loss:0.045539705562439144\n",
      "train loss:0.02179777124372636\n",
      "train loss:0.024369894542688755\n",
      "train loss:0.10230164495809875\n",
      "train loss:0.01425289633089761\n",
      "train loss:0.016885292646559052\n",
      "train loss:0.026062349759689078\n",
      "train loss:0.014464213431423026\n",
      "train loss:0.04354403056489633\n",
      "train loss:0.05274404760628063\n",
      "train loss:0.02122254991975475\n",
      "train loss:0.06274174337407265\n",
      "train loss:0.01748498172942692\n",
      "train loss:0.030597032088532802\n",
      "train loss:0.008854038135055458\n",
      "train loss:0.08061646272897242\n",
      "train loss:0.05918196227207023\n",
      "train loss:0.07824008878637397\n",
      "train loss:0.1120613541548422\n",
      "train loss:0.04353219873401775\n",
      "train loss:0.03743395115882877\n",
      "train loss:0.07114826458434298\n",
      "train loss:0.054736765457769156\n",
      "train loss:0.08228479147524528\n",
      "train loss:0.07492271401774851\n",
      "train loss:0.039367614417625506\n",
      "train loss:0.04067637912552973\n",
      "train loss:0.042574010724624946\n",
      "train loss:0.018662960410214265\n",
      "train loss:0.06955597993835164\n",
      "train loss:0.013312606522164507\n",
      "train loss:0.025522710148937\n",
      "train loss:0.03470706624247522\n",
      "train loss:0.03655180121460518\n",
      "train loss:0.011170670320309994\n",
      "train loss:0.05240547281714059\n",
      "train loss:0.11867706688728959\n",
      "train loss:0.05684765461547028\n",
      "train loss:0.03570927202656225\n",
      "train loss:0.03733713042182568\n",
      "train loss:0.08565863445804794\n",
      "train loss:0.014491764745291706\n",
      "train loss:0.021602906341471866\n",
      "train loss:0.02181085129600062\n",
      "train loss:0.061144540872222174\n",
      "train loss:0.08093764823179436\n",
      "train loss:0.09416181698038184\n",
      "train loss:0.019366219627313844\n",
      "train loss:0.03789446500623584\n",
      "train loss:0.025902464162317503\n",
      "train loss:0.06422578633446133\n",
      "train loss:0.015335650704708395\n",
      "train loss:0.008495125827894827\n",
      "train loss:0.04593251463827148\n",
      "train loss:0.011854779087641303\n",
      "train loss:0.11284702789178963\n",
      "train loss:0.013776701917711503\n",
      "train loss:0.07264708217625226\n",
      "train loss:0.036928095572456236\n",
      "train loss:0.014335044604389375\n",
      "train loss:0.0739667428507225\n",
      "train loss:0.03129107211688121\n",
      "train loss:0.01524031360758677\n",
      "train loss:0.065617155144955\n",
      "train loss:0.024849095219359213\n",
      "=== epoch:4, train acc:0.981, test acc:0.98 ===\n",
      "train loss:0.008800308904934597\n",
      "train loss:0.024301495433016348\n",
      "train loss:0.05648566804097956\n",
      "train loss:0.03894556776363785\n",
      "train loss:0.15069135877258535\n",
      "train loss:0.032472150355409984\n",
      "train loss:0.004571990221863872\n",
      "train loss:0.053807680864387496\n",
      "train loss:0.0651799253907959\n",
      "train loss:0.05081373952771544\n",
      "train loss:0.03702302351467472\n",
      "train loss:0.05283473249619066\n",
      "train loss:0.07678868931858983\n",
      "train loss:0.05020786833134511\n",
      "train loss:0.03041722546529901\n",
      "train loss:0.02926902264279931\n",
      "train loss:0.036873584013067576\n",
      "train loss:0.03250557543687483\n",
      "train loss:0.02576507936660609\n",
      "train loss:0.02445741307803993\n",
      "train loss:0.07702268869846977\n",
      "train loss:0.04738437885307471\n",
      "train loss:0.07516339459274747\n",
      "train loss:0.04619179039210589\n",
      "train loss:0.03782728502709607\n",
      "train loss:0.039251057289108084\n",
      "train loss:0.08016344004803358\n",
      "train loss:0.019297266616043043\n",
      "train loss:0.015020824613548778\n",
      "train loss:0.015754114880229948\n",
      "train loss:0.0616858765718158\n",
      "train loss:0.06803667508498346\n",
      "train loss:0.08116976029698521\n",
      "train loss:0.04520933940941351\n",
      "train loss:0.024035008772388625\n",
      "train loss:0.030065133574968005\n",
      "train loss:0.03661304145164915\n",
      "train loss:0.027019990415172716\n",
      "train loss:0.07447293798637408\n",
      "train loss:0.04659181613328829\n",
      "train loss:0.11745851067548636\n",
      "train loss:0.042924030087457335\n",
      "train loss:0.05883474878426159\n",
      "train loss:0.017767742398126358\n",
      "train loss:0.0668348552181762\n",
      "train loss:0.0723029512520918\n",
      "train loss:0.05888228330308427\n",
      "train loss:0.007975362943394113\n",
      "train loss:0.07031541921700185\n",
      "train loss:0.05678031534358984\n",
      "train loss:0.08115613408530238\n",
      "train loss:0.02427607385148037\n",
      "train loss:0.051100358503775825\n",
      "train loss:0.07812683982229834\n",
      "train loss:0.04812097816205678\n",
      "train loss:0.0612747917300052\n",
      "train loss:0.01927394632057891\n",
      "train loss:0.09078407676448007\n",
      "train loss:0.056070487817044844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04936188882985542\n",
      "train loss:0.026860179160866016\n",
      "train loss:0.03892359238880086\n",
      "train loss:0.045352445078024856\n",
      "train loss:0.022115051728626253\n",
      "train loss:0.06987068974259855\n",
      "train loss:0.02010160540707896\n",
      "train loss:0.04653296449039786\n",
      "train loss:0.03903653178411683\n",
      "train loss:0.02006345716659221\n",
      "train loss:0.024284603076467456\n",
      "train loss:0.006816513044995329\n",
      "train loss:0.04285847739315007\n",
      "train loss:0.019854101367641264\n",
      "train loss:0.045638280786719526\n",
      "train loss:0.04561073272675027\n",
      "train loss:0.03365926676877193\n",
      "train loss:0.03874456983153738\n",
      "train loss:0.010030537389648111\n",
      "train loss:0.14290068672852002\n",
      "train loss:0.023818790419064116\n",
      "train loss:0.022676973994334562\n",
      "train loss:0.04016680630345899\n",
      "train loss:0.05159240206960386\n",
      "train loss:0.02360332435460404\n",
      "train loss:0.038499234359736755\n",
      "train loss:0.012336057585612794\n",
      "train loss:0.07556224686134158\n",
      "train loss:0.047346260247825525\n",
      "train loss:0.0602047670651214\n",
      "train loss:0.04924629306322906\n",
      "train loss:0.05121558816069361\n",
      "train loss:0.07724361932659153\n",
      "train loss:0.022024465029542705\n",
      "train loss:0.020904119321906146\n",
      "train loss:0.06130504025196339\n",
      "train loss:0.08348323825368432\n",
      "train loss:0.029382521967631702\n",
      "train loss:0.022935974849487274\n",
      "train loss:0.02317441865113309\n",
      "train loss:0.029851873831322116\n",
      "train loss:0.05267613226975669\n",
      "train loss:0.026535308214955474\n",
      "train loss:0.0376489225780475\n",
      "train loss:0.04444280114688861\n",
      "train loss:0.009426105142509886\n",
      "train loss:0.051320691851787725\n",
      "train loss:0.03646299466649794\n",
      "train loss:0.05730791122088163\n",
      "train loss:0.06477471196970777\n",
      "train loss:0.016603892776472555\n",
      "train loss:0.1811090278885898\n",
      "train loss:0.043977875494655844\n",
      "train loss:0.013648576357140568\n",
      "train loss:0.013567341781940174\n",
      "train loss:0.047230865573463204\n",
      "train loss:0.012207908943322115\n",
      "train loss:0.07665487189384342\n",
      "train loss:0.021730858628019677\n",
      "train loss:0.009948753178786218\n",
      "train loss:0.02065141779863934\n",
      "train loss:0.04600268861842331\n",
      "train loss:0.019873650171512013\n",
      "train loss:0.07924323877829564\n",
      "train loss:0.022999668281003912\n",
      "train loss:0.03161663781536629\n",
      "train loss:0.02134382639556506\n",
      "train loss:0.033018193466358856\n",
      "train loss:0.0270658098619173\n",
      "train loss:0.06963620040030924\n",
      "train loss:0.033351416690549\n",
      "train loss:0.02871796422961798\n",
      "train loss:0.07479894374130738\n",
      "train loss:0.0525532463770696\n",
      "train loss:0.12371536830421817\n",
      "train loss:0.041388661686141755\n",
      "train loss:0.04028711822674511\n",
      "train loss:0.02310629623933826\n",
      "train loss:0.11214720369549674\n",
      "train loss:0.017473551454536586\n",
      "train loss:0.05543553982591833\n",
      "train loss:0.0329374369462233\n",
      "train loss:0.11928674263615612\n",
      "train loss:0.034965670606027975\n",
      "train loss:0.007010883122979613\n",
      "train loss:0.0597722163523571\n",
      "train loss:0.012438192804363663\n",
      "train loss:0.011272586565169933\n",
      "train loss:0.05193972578575576\n",
      "train loss:0.01353167421941179\n",
      "train loss:0.0423094025365191\n",
      "train loss:0.014610382769630803\n",
      "train loss:0.08160843863435806\n",
      "train loss:0.054667064874281905\n",
      "train loss:0.024086816705308673\n",
      "train loss:0.040021724823225684\n",
      "train loss:0.010116011313372973\n",
      "train loss:0.05223277541975849\n",
      "train loss:0.04343300007318876\n",
      "train loss:0.016727114000294935\n",
      "train loss:0.03473901775891548\n",
      "train loss:0.022691321431003938\n",
      "train loss:0.020486205717717546\n",
      "train loss:0.022426187081461536\n",
      "train loss:0.027062327930141218\n",
      "train loss:0.05976927963925359\n",
      "train loss:0.02215024856502796\n",
      "train loss:0.04226811117219679\n",
      "train loss:0.07251731652058752\n",
      "train loss:0.032666202902464324\n",
      "train loss:0.03294426142745941\n",
      "train loss:0.01927688897615818\n",
      "train loss:0.021727645829141665\n",
      "train loss:0.04373835168250307\n",
      "train loss:0.05393626482114472\n",
      "train loss:0.04022844977371678\n",
      "train loss:0.06431936636232506\n",
      "train loss:0.022151665727704554\n",
      "train loss:0.037007028335799254\n",
      "train loss:0.028595097581679867\n",
      "train loss:0.016084902040658534\n",
      "train loss:0.027249568840829994\n",
      "train loss:0.07151945920636879\n",
      "train loss:0.07267013186952459\n",
      "train loss:0.043719977501459034\n",
      "train loss:0.05238056846999383\n",
      "train loss:0.032045193642221324\n",
      "train loss:0.1573565698937599\n",
      "train loss:0.024245757005003185\n",
      "train loss:0.08374361761291459\n",
      "train loss:0.0064950923066854705\n",
      "train loss:0.08990761711513094\n",
      "train loss:0.07299120294850932\n",
      "train loss:0.06406226594245448\n",
      "train loss:0.016808066247555903\n",
      "train loss:0.043553661236289294\n",
      "train loss:0.017665651362417687\n",
      "train loss:0.04565498229977596\n",
      "train loss:0.022766494849992117\n",
      "train loss:0.04935367441786417\n",
      "train loss:0.08982288103297932\n",
      "train loss:0.07146999080761865\n",
      "train loss:0.019651653806576307\n",
      "train loss:0.08062199367970438\n",
      "train loss:0.04747802226453948\n",
      "train loss:0.04439218408901627\n",
      "train loss:0.05383531539578192\n",
      "train loss:0.030345897821747757\n",
      "train loss:0.016871904894925106\n",
      "train loss:0.03311323845832368\n",
      "train loss:0.020158683466965904\n",
      "train loss:0.018309571816463043\n",
      "train loss:0.018015248068313824\n",
      "train loss:0.021385831412190876\n",
      "train loss:0.013149994718983489\n",
      "train loss:0.028424716688320903\n",
      "train loss:0.0307759479006282\n",
      "train loss:0.039990832875704936\n",
      "train loss:0.03114247949255014\n",
      "train loss:0.06172562986933415\n",
      "train loss:0.01279952711621266\n",
      "train loss:0.04641468120684388\n",
      "train loss:0.026318650999042906\n",
      "train loss:0.09923824500834008\n",
      "train loss:0.04799048220968052\n",
      "train loss:0.02114037436169829\n",
      "train loss:0.03476067922497684\n",
      "train loss:0.08493873033956635\n",
      "train loss:0.03624407753710476\n",
      "train loss:0.016263615293931034\n",
      "train loss:0.02538136366198123\n",
      "train loss:0.008375520307203515\n",
      "train loss:0.018173790358551375\n",
      "train loss:0.008690871470661476\n",
      "train loss:0.014521873924937858\n",
      "train loss:0.03407903656408115\n",
      "train loss:0.01264619238049129\n",
      "train loss:0.024807821315978765\n",
      "train loss:0.021770578387251036\n",
      "train loss:0.029079717481052317\n",
      "train loss:0.009505033174679042\n",
      "train loss:0.1040337545616733\n",
      "train loss:0.10264511050411407\n",
      "train loss:0.03741786306197469\n",
      "train loss:0.029946784235049685\n",
      "train loss:0.03002977047232645\n",
      "train loss:0.017714074806661387\n",
      "train loss:0.05485777279731388\n",
      "train loss:0.0411437178775186\n",
      "train loss:0.040350722674090816\n",
      "train loss:0.05952627226296026\n",
      "train loss:0.035083895575561005\n",
      "train loss:0.031194853225428552\n",
      "train loss:0.033006049954989305\n",
      "train loss:0.04011626469248017\n",
      "train loss:0.09566129682335225\n",
      "train loss:0.02841083335211975\n",
      "train loss:0.007352548366253553\n",
      "train loss:0.061547548455900755\n",
      "train loss:0.04133375905684591\n",
      "train loss:0.024014412220062367\n",
      "train loss:0.023001284216897986\n",
      "train loss:0.10014809712083682\n",
      "train loss:0.018282348049898874\n",
      "train loss:0.01988952142411117\n",
      "train loss:0.026633275683625928\n",
      "train loss:0.015064356916886082\n",
      "train loss:0.035881542470387384\n",
      "train loss:0.0617486911393975\n",
      "train loss:0.05601227693168525\n",
      "train loss:0.03545445583413338\n",
      "train loss:0.026969428664526545\n",
      "train loss:0.04534577789518548\n",
      "train loss:0.009537590992266528\n",
      "train loss:0.027532358337198474\n",
      "train loss:0.04391559972640097\n",
      "train loss:0.029438074796573822\n",
      "train loss:0.06013696508569042\n",
      "train loss:0.021617215538175926\n",
      "train loss:0.04377280810278247\n",
      "train loss:0.04829894628736452\n",
      "train loss:0.027448014992980326\n",
      "train loss:0.04736864374191053\n",
      "train loss:0.03074632469193136\n",
      "train loss:0.010347373760677101\n",
      "train loss:0.013319201722257453\n",
      "train loss:0.025026922680462232\n",
      "train loss:0.05747780968643064\n",
      "train loss:0.006579273924550362\n",
      "train loss:0.08970521227741138\n",
      "train loss:0.06680106856611251\n",
      "train loss:0.03312945814569827\n",
      "train loss:0.011742986501356766\n",
      "train loss:0.0321298498231167\n",
      "train loss:0.02277349891446662\n",
      "train loss:0.047772934861835564\n",
      "train loss:0.032128440037405476\n",
      "train loss:0.05281302845217982\n",
      "train loss:0.01274956198339356\n",
      "train loss:0.053379514874954646\n",
      "train loss:0.036453613951107564\n",
      "train loss:0.03493799798310308\n",
      "train loss:0.04159763532370061\n",
      "train loss:0.02276185939999875\n",
      "train loss:0.04457424936204277\n",
      "train loss:0.03592485990354486\n",
      "train loss:0.01744209805694362\n",
      "train loss:0.044390974145588534\n",
      "train loss:0.013914959663360546\n",
      "train loss:0.00757269602523494\n",
      "train loss:0.024292564456956836\n",
      "train loss:0.03482489523814905\n",
      "train loss:0.0923732703820574\n",
      "train loss:0.031621971583182466\n",
      "train loss:0.009967001354816792\n",
      "train loss:0.012409002880120965\n",
      "train loss:0.032293970569297115\n",
      "train loss:0.0583293903626032\n",
      "train loss:0.04480006551892518\n",
      "train loss:0.03216675302877341\n",
      "train loss:0.02063144975227661\n",
      "train loss:0.02359306606513096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.033896878208401905\n",
      "train loss:0.024815900168175888\n",
      "train loss:0.015368841129328143\n",
      "train loss:0.08787742254232411\n",
      "train loss:0.01568083201187034\n",
      "train loss:0.010728184733288708\n",
      "train loss:0.02776503353660439\n",
      "train loss:0.044744480149690284\n",
      "train loss:0.042907096539322426\n",
      "train loss:0.00769594629385838\n",
      "train loss:0.01915563458294591\n",
      "train loss:0.02069220206448212\n",
      "train loss:0.07289854646730341\n",
      "train loss:0.008400911251799316\n",
      "train loss:0.014320768040415282\n",
      "train loss:0.009575968399256608\n",
      "train loss:0.008592053065077645\n",
      "train loss:0.041176679840410776\n",
      "train loss:0.03939230182657018\n",
      "train loss:0.04046678939288716\n",
      "train loss:0.014572675239415089\n",
      "train loss:0.034000172701290694\n",
      "train loss:0.0428173278462554\n",
      "train loss:0.01974282888925406\n",
      "train loss:0.08769235048356963\n",
      "train loss:0.047674353459557554\n",
      "train loss:0.014599965543514665\n",
      "train loss:0.013579850781443015\n",
      "train loss:0.0645582115232599\n",
      "train loss:0.14473835454529443\n",
      "train loss:0.04379479437379734\n",
      "train loss:0.04036260164300803\n",
      "train loss:0.06235591144523328\n",
      "train loss:0.08119961132586218\n",
      "train loss:0.07564233443751657\n",
      "train loss:0.010095023558953592\n",
      "train loss:0.0722199283758564\n",
      "train loss:0.04119618376554007\n",
      "train loss:0.02723838790237254\n",
      "train loss:0.03189509918253375\n",
      "train loss:0.01672846000489299\n",
      "train loss:0.04415218559401562\n",
      "train loss:0.07203667518602007\n",
      "train loss:0.013947558790561379\n",
      "train loss:0.022334881698975812\n",
      "train loss:0.034464780290325625\n",
      "train loss:0.025544787750727535\n",
      "train loss:0.055173412431757655\n",
      "train loss:0.0539372422110215\n",
      "train loss:0.031376901978876125\n",
      "train loss:0.024923192215066767\n",
      "train loss:0.022527268320579653\n",
      "train loss:0.01868445991135976\n",
      "train loss:0.0615358303529831\n",
      "train loss:0.07790687210899955\n",
      "train loss:0.03454142604914885\n",
      "train loss:0.05192200223201235\n",
      "train loss:0.030888047562280953\n",
      "train loss:0.044692123322334555\n",
      "train loss:0.01547847843183641\n",
      "train loss:0.014657363626594026\n",
      "train loss:0.01106899976527299\n",
      "train loss:0.016892871974447995\n",
      "train loss:0.03525202859468391\n",
      "train loss:0.027745202945032413\n",
      "train loss:0.01782442342028115\n",
      "train loss:0.022644663848167424\n",
      "train loss:0.038166676492191146\n",
      "train loss:0.026593991923468684\n",
      "train loss:0.04342637878305404\n",
      "train loss:0.06794248123166739\n",
      "train loss:0.023927800012302915\n",
      "train loss:0.04307273573409724\n",
      "train loss:0.04522340457731819\n",
      "train loss:0.05315358703429741\n",
      "train loss:0.03240950010969401\n",
      "train loss:0.02688290461104693\n",
      "train loss:0.0260985348501755\n",
      "train loss:0.12793703997987407\n",
      "train loss:0.03186753460886889\n",
      "train loss:0.04914538605977033\n",
      "train loss:0.016515907042427256\n",
      "train loss:0.03681241174955945\n",
      "train loss:0.006037132894578698\n",
      "train loss:0.027753706467087223\n",
      "train loss:0.021044147879782874\n",
      "train loss:0.013899392513143753\n",
      "train loss:0.022775348743820097\n",
      "train loss:0.07945463210495526\n",
      "train loss:0.010630712849496517\n",
      "train loss:0.03494085372588744\n",
      "train loss:0.02822656602910396\n",
      "train loss:0.013958630885009975\n",
      "train loss:0.023439981106007212\n",
      "train loss:0.03001266250303763\n",
      "train loss:0.036040589763187955\n",
      "train loss:0.0299808098150774\n",
      "train loss:0.007009804457807863\n",
      "train loss:0.052943703576836844\n",
      "train loss:0.05294788966544428\n",
      "train loss:0.04736998373688775\n",
      "train loss:0.013129377511294161\n",
      "train loss:0.0561810020638754\n",
      "train loss:0.04427904224892359\n",
      "train loss:0.041074463479433415\n",
      "train loss:0.020809743247769567\n",
      "train loss:0.05977861670615439\n",
      "train loss:0.024347893851514018\n",
      "train loss:0.03252212670011254\n",
      "train loss:0.0188914640301578\n",
      "train loss:0.04681956566185432\n",
      "train loss:0.030841905422326076\n",
      "train loss:0.036084730443898684\n",
      "train loss:0.037221782904614927\n",
      "train loss:0.02356007863707831\n",
      "train loss:0.0057856591684198495\n",
      "train loss:0.010404479780385419\n",
      "train loss:0.08110732244954125\n",
      "train loss:0.01897120326026363\n",
      "train loss:0.013907778757430798\n",
      "train loss:0.031936884255474515\n",
      "train loss:0.059196366042675995\n",
      "train loss:0.057790023370714254\n",
      "train loss:0.03850275383706953\n",
      "train loss:0.04577602271251146\n",
      "train loss:0.006245012509917571\n",
      "train loss:0.07277009928868422\n",
      "train loss:0.014172999584882037\n",
      "train loss:0.02021193232587867\n",
      "train loss:0.008985937586116231\n",
      "train loss:0.03830498083071528\n",
      "train loss:0.014492187699166692\n",
      "train loss:0.1267268134606452\n",
      "train loss:0.028611437491133342\n",
      "train loss:0.0432494565306628\n",
      "train loss:0.03692707961842354\n",
      "train loss:0.042499432248149185\n",
      "train loss:0.0671983316667197\n",
      "train loss:0.05003434268473345\n",
      "train loss:0.027575923098138718\n",
      "train loss:0.08405306279859402\n",
      "train loss:0.029770762491019894\n",
      "train loss:0.008992139299697501\n",
      "train loss:0.04127567387077087\n",
      "train loss:0.03214721703027615\n",
      "train loss:0.06128223767355912\n",
      "train loss:0.018021597508232175\n",
      "train loss:0.02942767826326465\n",
      "train loss:0.02052280750163385\n",
      "train loss:0.017692853648226276\n",
      "train loss:0.0468588696381671\n",
      "train loss:0.05681890742221896\n",
      "train loss:0.06034925814615315\n",
      "train loss:0.040678649065851245\n",
      "train loss:0.05342931105887547\n",
      "train loss:0.011587105702675942\n",
      "train loss:0.06962721038481517\n",
      "train loss:0.05922306408677674\n",
      "train loss:0.025281318633107154\n",
      "train loss:0.03280300160115386\n",
      "train loss:0.01896151321641309\n",
      "train loss:0.025032925964493052\n",
      "train loss:0.023962768753708476\n",
      "train loss:0.01383386065947596\n",
      "train loss:0.03863352125353614\n",
      "train loss:0.08953364057917285\n",
      "train loss:0.007986968576684506\n",
      "train loss:0.045607342895600464\n",
      "train loss:0.01846215511392427\n",
      "train loss:0.033281672389818676\n",
      "train loss:0.13650509554604912\n",
      "train loss:0.01279402834859502\n",
      "train loss:0.06628663359833627\n",
      "train loss:0.014394475216896569\n",
      "train loss:0.02873447048307673\n",
      "train loss:0.05377225457764924\n",
      "train loss:0.03706387816867388\n",
      "train loss:0.013254003451100218\n",
      "train loss:0.010622133750877963\n",
      "train loss:0.007871030883713593\n",
      "train loss:0.01958113925088338\n",
      "train loss:0.11009371812407606\n",
      "train loss:0.015733028943837473\n",
      "train loss:0.021665898844890886\n",
      "train loss:0.011394099494659369\n",
      "train loss:0.05727661321619168\n",
      "train loss:0.012091549011581468\n",
      "train loss:0.01693635041491458\n",
      "train loss:0.03217988901767654\n",
      "train loss:0.0471704050365285\n",
      "train loss:0.009799397234651792\n",
      "train loss:0.039192077298122754\n",
      "train loss:0.026085271205085726\n",
      "train loss:0.018832596784325393\n",
      "train loss:0.024916150954506257\n",
      "train loss:0.03240468276859369\n",
      "train loss:0.007143774297709405\n",
      "train loss:0.03497648363425877\n",
      "train loss:0.014243969455315484\n",
      "train loss:0.014768599926722683\n",
      "train loss:0.034139844687775485\n",
      "train loss:0.07929286766425245\n",
      "train loss:0.020137594678846\n",
      "train loss:0.017605902889776495\n",
      "train loss:0.015775842395276015\n",
      "train loss:0.05704986160736825\n",
      "train loss:0.020709013921951073\n",
      "train loss:0.04608154505694369\n",
      "train loss:0.037450062597474555\n",
      "train loss:0.04570716437420702\n",
      "train loss:0.043172329970381326\n",
      "train loss:0.03313280185168976\n",
      "train loss:0.010485804429655647\n",
      "train loss:0.029840217609003933\n",
      "train loss:0.10150070157710359\n",
      "train loss:0.015172394019550674\n",
      "train loss:0.026668812939061676\n",
      "train loss:0.024719858877389686\n",
      "train loss:0.02063627351742301\n",
      "train loss:0.07254700088917082\n",
      "train loss:0.02044764208395994\n",
      "train loss:0.030799318208257907\n",
      "train loss:0.047969517278702155\n",
      "train loss:0.1133584199624644\n",
      "train loss:0.018563721235158915\n",
      "train loss:0.04902603082763582\n",
      "train loss:0.04940232035575938\n",
      "train loss:0.02188879571621889\n",
      "train loss:0.02235274861230823\n",
      "train loss:0.07282028151868632\n",
      "train loss:0.10802624473543589\n",
      "train loss:0.04166712639001479\n",
      "train loss:0.07291131122500003\n",
      "train loss:0.03847933855585823\n",
      "train loss:0.10557156831248765\n",
      "train loss:0.021709245887908367\n",
      "train loss:0.022236068810955124\n",
      "train loss:0.06195157877945587\n",
      "train loss:0.04320865070468813\n",
      "train loss:0.020166978218437267\n",
      "train loss:0.011585369239883219\n",
      "train loss:0.01561140434115652\n",
      "train loss:0.02469756636287066\n",
      "train loss:0.017259889963564902\n",
      "train loss:0.024441256882061762\n",
      "train loss:0.029094375737946182\n",
      "train loss:0.026446817776269185\n",
      "train loss:0.007095805402711413\n",
      "train loss:0.029770185581913376\n",
      "train loss:0.04471936157385648\n",
      "train loss:0.024991675260143426\n",
      "train loss:0.01022000438076857\n",
      "train loss:0.085477914079038\n",
      "train loss:0.08510930839613579\n",
      "train loss:0.025390212985905502\n",
      "train loss:0.02078270672097178\n",
      "train loss:0.03852543122037613\n",
      "train loss:0.06369930368507788\n",
      "train loss:0.0264158362807654\n",
      "train loss:0.04629398237507452\n",
      "train loss:0.05189773454541316\n",
      "train loss:0.0117908875244224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02375239602371997\n",
      "train loss:0.06057164861638839\n",
      "train loss:0.011888956959981678\n",
      "train loss:0.03228586234217398\n",
      "train loss:0.017496921381990153\n",
      "train loss:0.006573646153714281\n",
      "train loss:0.03437478853137793\n",
      "train loss:0.01704531838567376\n",
      "train loss:0.02531387680542975\n",
      "train loss:0.029254283794231794\n",
      "train loss:0.024373340109286937\n",
      "train loss:0.04281387453539606\n",
      "train loss:0.007771225320510451\n",
      "train loss:0.042781898343367784\n",
      "train loss:0.017918943255994305\n",
      "train loss:0.029312288071108493\n",
      "train loss:0.016645100527570872\n",
      "=== epoch:5, train acc:0.985, test acc:0.979 ===\n",
      "train loss:0.013055517002105214\n",
      "train loss:0.041460618405478156\n",
      "train loss:0.012086935484918808\n",
      "train loss:0.021788365844316367\n",
      "train loss:0.01819880215856438\n",
      "train loss:0.03446073733178749\n",
      "train loss:0.009279068645756039\n",
      "train loss:0.014351645335225805\n",
      "train loss:0.041261365036328816\n",
      "train loss:0.0536637826019207\n",
      "train loss:0.021464835488159535\n",
      "train loss:0.00838784451118868\n",
      "train loss:0.03999917328696489\n",
      "train loss:0.05512578027007524\n",
      "train loss:0.019157709411723744\n",
      "train loss:0.007057331733803828\n",
      "train loss:0.032502903164046776\n",
      "train loss:0.015051389000907387\n",
      "train loss:0.008925033581687097\n",
      "train loss:0.036035233296300935\n",
      "train loss:0.032176685811624896\n",
      "train loss:0.01926216079775338\n",
      "train loss:0.06783487203450668\n",
      "train loss:0.0061498360235981205\n",
      "train loss:0.01148336216685347\n",
      "train loss:0.018760348672335326\n",
      "train loss:0.027436648168547583\n",
      "train loss:0.012218868438844274\n",
      "train loss:0.06312236888979256\n",
      "train loss:0.04150720410058142\n",
      "train loss:0.00901493685397003\n",
      "train loss:0.013975384957618629\n",
      "train loss:0.014218800803680397\n",
      "train loss:0.013639536860347877\n",
      "train loss:0.01714431114669952\n",
      "train loss:0.02722838148718313\n",
      "train loss:0.027112670704992833\n",
      "train loss:0.04574489378188823\n",
      "train loss:0.02807968566534858\n",
      "train loss:0.011103296357871252\n",
      "train loss:0.014451735722385547\n",
      "train loss:0.027777058864931755\n",
      "train loss:0.010788165131033676\n",
      "train loss:0.04042986863764504\n",
      "train loss:0.024095814070113894\n",
      "train loss:0.0167162894312091\n",
      "train loss:0.09125132475222976\n",
      "train loss:0.07214308487770964\n",
      "train loss:0.025178121154168478\n",
      "train loss:0.06001938592009869\n",
      "train loss:0.04109215675972678\n",
      "train loss:0.025182719929001115\n",
      "train loss:0.06616160231439794\n",
      "train loss:0.07513396033793693\n",
      "train loss:0.014064466570830533\n",
      "train loss:0.026658687718222662\n",
      "train loss:0.03509069612814277\n",
      "train loss:0.03126178888682889\n",
      "train loss:0.008574843346190113\n",
      "train loss:0.017621489197233366\n",
      "train loss:0.01873651264626828\n",
      "train loss:0.045616013820007906\n",
      "train loss:0.03529521834992115\n",
      "train loss:0.054925983291360676\n",
      "train loss:0.020277939139646418\n",
      "train loss:0.009266538506161267\n",
      "train loss:0.02385937084672588\n",
      "train loss:0.028101941490498827\n",
      "train loss:0.017178979375087465\n",
      "train loss:0.015952122324950434\n",
      "train loss:0.05258611371070062\n",
      "train loss:0.023829377955659932\n",
      "train loss:0.022605418935541025\n",
      "train loss:0.011346935030527116\n",
      "train loss:0.015365575796587488\n",
      "train loss:0.036464822569200604\n",
      "train loss:0.09913337801083637\n",
      "train loss:0.027712996100857302\n",
      "train loss:0.011325079714664876\n",
      "train loss:0.06143243814394424\n",
      "train loss:0.04875766129059059\n",
      "train loss:0.05700639559587259\n",
      "train loss:0.03515724444902698\n",
      "train loss:0.06298839481804457\n",
      "train loss:0.06834982969601698\n",
      "train loss:0.010166081647568784\n",
      "train loss:0.016150750836705238\n",
      "train loss:0.10207364522359658\n",
      "train loss:0.04623995069953199\n",
      "train loss:0.007874030542793894\n",
      "train loss:0.03940393527835668\n",
      "train loss:0.04840745990053004\n",
      "train loss:0.03295570683604015\n",
      "train loss:0.032312928346072925\n",
      "train loss:0.014989934179885357\n",
      "train loss:0.011152029319247947\n",
      "train loss:0.023365170824923936\n",
      "train loss:0.024487953591576805\n",
      "train loss:0.0033318049675698557\n",
      "train loss:0.07642523693255118\n",
      "train loss:0.04550954067406842\n",
      "train loss:0.017507037551600744\n",
      "train loss:0.02572134730343185\n",
      "train loss:0.02720385087185264\n",
      "train loss:0.021056426190501965\n",
      "train loss:0.08523935593109329\n",
      "train loss:0.04791604492524316\n",
      "train loss:0.08493960181418565\n",
      "train loss:0.06372610849725062\n",
      "train loss:0.009775156100345432\n",
      "train loss:0.00872429144279509\n",
      "train loss:0.04783224449495343\n",
      "train loss:0.010349876502104973\n",
      "train loss:0.022898894032273506\n",
      "train loss:0.04270757928781042\n",
      "train loss:0.019414666497205565\n",
      "train loss:0.015110688940530076\n",
      "train loss:0.011292268374078207\n",
      "train loss:0.029298886493792566\n",
      "train loss:0.04024925259207678\n",
      "train loss:0.015078346710195303\n",
      "train loss:0.015397312405476976\n",
      "train loss:0.022863046183049917\n",
      "train loss:0.004912556811357146\n",
      "train loss:0.029712736510942438\n",
      "train loss:0.054706009377960205\n",
      "train loss:0.012245117174010858\n",
      "train loss:0.0531735105511686\n",
      "train loss:0.043957919982312584\n",
      "train loss:0.10921414415854702\n",
      "train loss:0.010705387295487163\n",
      "train loss:0.02150496495615875\n",
      "train loss:0.04545771996693877\n",
      "train loss:0.006612340228100514\n",
      "train loss:0.005064344319417123\n",
      "train loss:0.03089348112438409\n",
      "train loss:0.008217677483609081\n",
      "train loss:0.02833728982205349\n",
      "train loss:0.009216874358167556\n",
      "train loss:0.02465345729256905\n",
      "train loss:0.10119817276425001\n",
      "train loss:0.05954676648638449\n",
      "train loss:0.046557786961787445\n",
      "train loss:0.010170666993443775\n",
      "train loss:0.031063045746724294\n",
      "train loss:0.011304975565643218\n",
      "train loss:0.029069009961703904\n",
      "train loss:0.01811571113915843\n",
      "train loss:0.021435873461497636\n",
      "train loss:0.015382632813722416\n",
      "train loss:0.020547276086593024\n",
      "train loss:0.01084744058016085\n",
      "train loss:0.08019587668182576\n",
      "train loss:0.052736655927562666\n",
      "train loss:0.01309256724196403\n",
      "train loss:0.008115321243224\n",
      "train loss:0.0374787255806473\n",
      "train loss:0.07338064676414252\n",
      "train loss:0.03955459622164068\n",
      "train loss:0.02973665923645271\n",
      "train loss:0.05760502705194471\n",
      "train loss:0.020672024904828903\n",
      "train loss:0.012898066566893636\n",
      "train loss:0.015385703878238321\n",
      "train loss:0.010674983317541265\n",
      "train loss:0.04413571319796605\n",
      "train loss:0.025746761513848724\n",
      "train loss:0.16701857605120415\n",
      "train loss:0.017018690615879392\n",
      "train loss:0.02347883794077581\n",
      "train loss:0.010248550328039336\n",
      "train loss:0.023953549744829786\n",
      "train loss:0.03131148571174682\n",
      "train loss:0.01334910077547816\n",
      "train loss:0.009701407086902288\n",
      "train loss:0.020626489209011122\n",
      "train loss:0.07670244263985947\n",
      "train loss:0.01711617541488174\n",
      "train loss:0.025528730696985844\n",
      "train loss:0.04623874155315123\n",
      "train loss:0.03236258383711621\n",
      "train loss:0.04479281832537904\n",
      "train loss:0.03010589506272576\n",
      "train loss:0.03220004632480759\n",
      "train loss:0.11272649641894007\n",
      "train loss:0.028351143244636404\n",
      "train loss:0.0148598201748536\n",
      "train loss:0.05228749768854196\n",
      "train loss:0.019361153914620448\n",
      "train loss:0.03040194901359249\n",
      "train loss:0.024140562645068434\n",
      "train loss:0.021041510881399182\n",
      "train loss:0.009784528330333088\n",
      "train loss:0.06993197705456657\n",
      "train loss:0.08077580823870639\n",
      "train loss:0.005064129972879638\n",
      "train loss:0.01192451290537007\n",
      "train loss:0.01786832472168045\n",
      "train loss:0.02106968086475939\n",
      "train loss:0.07027020866305168\n",
      "train loss:0.05253301538388286\n",
      "train loss:0.009992414642858797\n",
      "train loss:0.051793853828289375\n",
      "train loss:0.019527500880665332\n",
      "train loss:0.01664344549403848\n",
      "train loss:0.009413572518873557\n",
      "train loss:0.12082177200122571\n",
      "train loss:0.008628103850525523\n",
      "train loss:0.010371892763673509\n",
      "train loss:0.0055415841365393965\n",
      "train loss:0.013711182032816098\n",
      "train loss:0.07446944969200575\n",
      "train loss:0.01603186238982989\n",
      "train loss:0.018722535746503583\n",
      "train loss:0.021453728529653705\n",
      "train loss:0.008852671893226811\n",
      "train loss:0.052256045364317584\n",
      "train loss:0.026412840286373772\n",
      "train loss:0.016846408423783554\n",
      "train loss:0.013782593788631645\n",
      "train loss:0.03147077174147682\n",
      "train loss:0.02367360416492588\n",
      "train loss:0.0228075025634153\n",
      "train loss:0.0070489699841813185\n",
      "train loss:0.01705839196105474\n",
      "train loss:0.03199749418169756\n",
      "train loss:0.0051355591091967875\n",
      "train loss:0.031501920945955435\n",
      "train loss:0.05820720910487487\n",
      "train loss:0.016782741547176176\n",
      "train loss:0.02122469367539204\n",
      "train loss:0.00688455320457004\n",
      "train loss:0.04963183361155087\n",
      "train loss:0.015973234518152087\n",
      "train loss:0.03217981163207175\n",
      "train loss:0.018941644154437172\n",
      "train loss:0.06290817202843461\n",
      "train loss:0.01823674729288803\n",
      "train loss:0.06202804965898842\n",
      "train loss:0.02977284418448457\n",
      "train loss:0.02682665472980972\n",
      "train loss:0.0313549021823117\n",
      "train loss:0.03424695172227839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0069642174824651815\n",
      "train loss:0.014272307593954037\n",
      "train loss:0.01393173216338152\n",
      "train loss:0.10673832161585085\n",
      "train loss:0.04690905253582464\n",
      "train loss:0.06033903405672809\n",
      "train loss:0.005225039386449799\n",
      "train loss:0.08330594036281908\n",
      "train loss:0.012421748621776333\n",
      "train loss:0.041772076147232357\n",
      "train loss:0.029264513611080775\n",
      "train loss:0.047648099475478746\n",
      "train loss:0.026514393266790778\n",
      "train loss:0.021482148999141516\n",
      "train loss:0.08894994197506\n",
      "train loss:0.029194757607111602\n",
      "train loss:0.00950686729852136\n",
      "train loss:0.01404779753973542\n",
      "train loss:0.06583978541286466\n",
      "train loss:0.02473662324903779\n",
      "train loss:0.04244170822231398\n",
      "train loss:0.010056970750978257\n",
      "train loss:0.03517879160154981\n",
      "train loss:0.10495587838956244\n",
      "train loss:0.005451789111697353\n",
      "train loss:0.007683362571170672\n",
      "train loss:0.04173984814190324\n",
      "train loss:0.059669489554583885\n",
      "train loss:0.02333735206963048\n",
      "train loss:0.030743526919840766\n",
      "train loss:0.023748534703621114\n",
      "train loss:0.011968903354419835\n",
      "train loss:0.043011368368756325\n",
      "train loss:0.015101479693595241\n",
      "train loss:0.024048105923765797\n",
      "train loss:0.011743732593358779\n",
      "train loss:0.0357286046984074\n",
      "train loss:0.025044676987732276\n",
      "train loss:0.012859269749042166\n",
      "train loss:0.09149052244106486\n",
      "train loss:0.016810156891663278\n",
      "train loss:0.04159287995014619\n",
      "train loss:0.03180569789109924\n",
      "train loss:0.05928580174302819\n",
      "train loss:0.01917466598742518\n",
      "train loss:0.04192911162665957\n",
      "train loss:0.047015387940820476\n",
      "train loss:0.03662389796752375\n",
      "train loss:0.026174541158732734\n",
      "train loss:0.024052327682519314\n",
      "train loss:0.04369173474254324\n",
      "train loss:0.026967089018785143\n",
      "train loss:0.015427385023007896\n",
      "train loss:0.02969820406538148\n",
      "train loss:0.013218439677216743\n",
      "train loss:0.03825671644243252\n",
      "train loss:0.02425209742699603\n",
      "train loss:0.009772069334283482\n",
      "train loss:0.021058312604258073\n",
      "train loss:0.036958045552116604\n",
      "train loss:0.05284849859015318\n",
      "train loss:0.02656145074804536\n",
      "train loss:0.020818030379196276\n",
      "train loss:0.048087541311862235\n",
      "train loss:0.052253624521779764\n",
      "train loss:0.051842833276162924\n",
      "train loss:0.0089662766179767\n",
      "train loss:0.006372440004108133\n",
      "train loss:0.06087520737157491\n",
      "train loss:0.0046513375410578315\n",
      "train loss:0.015524700478691174\n",
      "train loss:0.014227562972644681\n",
      "train loss:0.057706004731063736\n",
      "train loss:0.028100588201496905\n",
      "train loss:0.04007287698166581\n",
      "train loss:0.02479312964408556\n",
      "train loss:0.008962710526523933\n",
      "train loss:0.04378860355138406\n",
      "train loss:0.12020022190927097\n",
      "train loss:0.016164858703228664\n",
      "train loss:0.0912102370851723\n",
      "train loss:0.014377148289726804\n",
      "train loss:0.011700698098329765\n",
      "train loss:0.037259352203640225\n",
      "train loss:0.02107590477618819\n",
      "train loss:0.015569874232698564\n",
      "train loss:0.028469916455689165\n",
      "train loss:0.09426662710581737\n",
      "train loss:0.02829163284484639\n",
      "train loss:0.03567980394768199\n",
      "train loss:0.0206418758350332\n",
      "train loss:0.009324512372397866\n",
      "train loss:0.0044057635673737635\n",
      "train loss:0.01973825296517205\n",
      "train loss:0.025647620228867952\n",
      "train loss:0.020508237901790065\n",
      "train loss:0.0120015989964225\n",
      "train loss:0.05710426484360579\n",
      "train loss:0.027205838191699194\n",
      "train loss:0.016215029208670965\n",
      "train loss:0.013450397617919364\n",
      "train loss:0.01859729369520859\n",
      "train loss:0.00372545575751089\n",
      "train loss:0.05674695702273267\n",
      "train loss:0.00846089737023278\n",
      "train loss:0.03213016176306382\n",
      "train loss:0.02832927726671938\n",
      "train loss:0.027729818065010493\n",
      "train loss:0.00901160938495614\n",
      "train loss:0.018874448549785247\n",
      "train loss:0.0196998028525147\n",
      "train loss:0.010571157126212444\n",
      "train loss:0.015161365016024725\n",
      "train loss:0.004968319417196935\n",
      "train loss:0.07639155759756033\n",
      "train loss:0.07098055726483488\n",
      "train loss:0.01670596077545688\n",
      "train loss:0.02829573855623445\n",
      "train loss:0.04284752791587525\n",
      "train loss:0.05367078015017036\n",
      "train loss:0.03911091444044007\n",
      "train loss:0.04169407571523319\n",
      "train loss:0.03704370097114376\n",
      "train loss:0.02911535636782582\n",
      "train loss:0.016318754828666023\n",
      "train loss:0.01577115786398322\n",
      "train loss:0.009908146548699495\n",
      "train loss:0.02155483631743776\n",
      "train loss:0.040670457043844276\n",
      "train loss:0.06094787532307028\n",
      "train loss:0.007163652568841407\n",
      "train loss:0.01897276236842784\n",
      "train loss:0.047998351407242235\n",
      "train loss:0.01054388975798346\n",
      "train loss:0.025170188635240943\n",
      "train loss:0.07222411835912505\n",
      "train loss:0.021328212979437194\n",
      "train loss:0.023837749437808094\n",
      "train loss:0.017144830891169513\n",
      "train loss:0.019362241585692344\n",
      "train loss:0.017546164091476805\n",
      "train loss:0.029078123673033703\n",
      "train loss:0.028009213535932807\n",
      "train loss:0.029201563398701075\n",
      "train loss:0.01699265353465992\n",
      "train loss:0.06022427075685467\n",
      "train loss:0.020452510773508778\n",
      "train loss:0.05174571524107077\n",
      "train loss:0.044272457127351415\n",
      "train loss:0.0205526243608952\n",
      "train loss:0.05304966483498215\n",
      "train loss:0.008860419997295081\n",
      "train loss:0.014385256534824033\n",
      "train loss:0.04434634016423117\n",
      "train loss:0.024572139416547588\n",
      "train loss:0.08403328218690131\n",
      "train loss:0.037123324261202705\n",
      "train loss:0.018361618360166962\n",
      "train loss:0.0146569752193254\n",
      "train loss:0.022883315649282792\n",
      "train loss:0.023347355341690655\n",
      "train loss:0.01376528355371335\n",
      "train loss:0.006588702548526979\n",
      "train loss:0.012013328918360093\n",
      "train loss:0.008703937435107102\n",
      "train loss:0.10224416033467648\n",
      "train loss:0.006546997436218214\n",
      "train loss:0.053957509791612006\n",
      "train loss:0.007008173981009359\n",
      "train loss:0.017337497577495534\n",
      "train loss:0.022649682662507605\n",
      "train loss:0.05753435487522927\n",
      "train loss:0.035964650624280205\n",
      "train loss:0.003149051538480583\n",
      "train loss:0.015953517199278427\n",
      "train loss:0.023059570042292848\n",
      "train loss:0.044279361546044796\n",
      "train loss:0.02248107735187621\n",
      "train loss:0.06862485216215575\n",
      "train loss:0.02293942578689776\n",
      "train loss:0.021401438975436417\n",
      "train loss:0.015210573476908948\n",
      "train loss:0.13897357147538528\n",
      "train loss:0.044103251496574486\n",
      "train loss:0.013978349596989799\n",
      "train loss:0.01067915483084221\n",
      "train loss:0.03972304697536137\n",
      "train loss:0.019720486652116592\n",
      "train loss:0.0320850660786408\n",
      "train loss:0.026781244638060846\n",
      "train loss:0.017519407501572277\n",
      "train loss:0.06625219522307409\n",
      "train loss:0.008615244823354188\n",
      "train loss:0.003759659994762983\n",
      "train loss:0.015849167194364935\n",
      "train loss:0.006744541873458556\n",
      "train loss:0.03800491441221701\n",
      "train loss:0.03165630201627325\n",
      "train loss:0.012436426745561535\n",
      "train loss:0.018260349948157298\n",
      "train loss:0.04916630636609079\n",
      "train loss:0.10221369902008078\n",
      "train loss:0.012253766325546261\n",
      "train loss:0.016777961882983413\n",
      "train loss:0.004778457703719326\n",
      "train loss:0.00958104619500402\n",
      "train loss:0.03190385461980102\n",
      "train loss:0.028401274472753976\n",
      "train loss:0.010073223197098309\n",
      "train loss:0.006945121418260405\n",
      "train loss:0.0344718220744613\n",
      "train loss:0.04588839754216235\n",
      "train loss:0.06137090109936029\n",
      "train loss:0.01206347579092247\n",
      "train loss:0.04705436669502272\n",
      "train loss:0.011607233292065658\n",
      "train loss:0.009174293004577871\n",
      "train loss:0.048860078152744804\n",
      "train loss:0.02915655063950841\n",
      "train loss:0.020030770866209805\n",
      "train loss:0.014570071737096653\n",
      "train loss:0.009137485933851072\n",
      "train loss:0.0489305946483632\n",
      "train loss:0.041420262621438796\n",
      "train loss:0.006406470473455073\n",
      "train loss:0.018542653820422004\n",
      "train loss:0.029412247210855086\n",
      "train loss:0.013325344297274977\n",
      "train loss:0.04206465692169482\n",
      "train loss:0.02150609348279112\n",
      "train loss:0.049468878125177\n",
      "train loss:0.0032240924727450016\n",
      "train loss:0.014556825283995729\n",
      "train loss:0.02395332551486778\n",
      "train loss:0.009582444957410856\n",
      "train loss:0.052115492797466335\n",
      "train loss:0.019464879661551117\n",
      "train loss:0.07349377396682177\n",
      "train loss:0.00901026361853161\n",
      "train loss:0.012928127628585053\n",
      "train loss:0.011907092094427052\n",
      "train loss:0.016298372569896122\n",
      "train loss:0.006059179410378676\n",
      "train loss:0.0060232384191920944\n",
      "train loss:0.04287676468743056\n",
      "train loss:0.011123245480736904\n",
      "train loss:0.01148536181214175\n",
      "train loss:0.011900121731332213\n",
      "train loss:0.02507937665884139\n",
      "train loss:0.0724894750927177\n",
      "train loss:0.026210894798150447\n",
      "train loss:0.03402390473496476\n",
      "train loss:0.06165073744289837\n",
      "train loss:0.027648376418793284\n",
      "train loss:0.012200039744804499\n",
      "train loss:0.010977168178449632\n",
      "train loss:0.012589904558457609\n",
      "train loss:0.03480823669948785\n",
      "train loss:0.023053881184454107\n",
      "train loss:0.024635633590718565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01654135111270343\n",
      "train loss:0.00906925176080886\n",
      "train loss:0.017919824170824872\n",
      "train loss:0.01276958698384992\n",
      "train loss:0.04544192150090052\n",
      "train loss:0.006102854020239039\n",
      "train loss:0.010997094429603942\n",
      "train loss:0.03430772497614269\n",
      "train loss:0.011281916141021111\n",
      "train loss:0.04387798034499157\n",
      "train loss:0.1529372268723902\n",
      "train loss:0.0073850554841397905\n",
      "train loss:0.011482323144335433\n",
      "train loss:0.009927634788586447\n",
      "train loss:0.03596796375351038\n",
      "train loss:0.00534570953370339\n",
      "train loss:0.0806764714559623\n",
      "train loss:0.09920915429134583\n",
      "train loss:0.035567849081343646\n",
      "train loss:0.006087606630388216\n",
      "train loss:0.007123652393865059\n",
      "train loss:0.03989422300267548\n",
      "train loss:0.0201318134522965\n",
      "train loss:0.02221332863894184\n",
      "train loss:0.02685397161366281\n",
      "train loss:0.008183179103801987\n",
      "train loss:0.03957858473702979\n",
      "train loss:0.02895121522054077\n",
      "train loss:0.003559203465728618\n",
      "train loss:0.010605502553653773\n",
      "train loss:0.011096328842873548\n",
      "train loss:0.10163726176676065\n",
      "train loss:0.02071104956514563\n",
      "train loss:0.024540220216608632\n",
      "train loss:0.014489558919074665\n",
      "train loss:0.013497336636135582\n",
      "train loss:0.00870937184798299\n",
      "train loss:0.013380227170739757\n",
      "train loss:0.011447979580925622\n",
      "train loss:0.03128236945029447\n",
      "train loss:0.01354136905776438\n",
      "train loss:0.014565810156638475\n",
      "train loss:0.005623495511669272\n",
      "train loss:0.01566355014938673\n",
      "train loss:0.05591911811898929\n",
      "train loss:0.028846517357141815\n",
      "train loss:0.033116619981868614\n",
      "train loss:0.04082591152463046\n",
      "train loss:0.06640480444505031\n",
      "train loss:0.011828962965018402\n",
      "train loss:0.012063827675984944\n",
      "train loss:0.05212095043161118\n",
      "train loss:0.01692451910174198\n",
      "train loss:0.023928726512007965\n",
      "train loss:0.037593414481507895\n",
      "train loss:0.09600283631875653\n",
      "train loss:0.01181559571105655\n",
      "train loss:0.025499973190828244\n",
      "train loss:0.004291934955181057\n",
      "train loss:0.006880082879473365\n",
      "train loss:0.03903807350248453\n",
      "train loss:0.007285980461930675\n",
      "train loss:0.022282038504795793\n",
      "train loss:0.009705348429898085\n",
      "train loss:0.02539809062549581\n",
      "train loss:0.01885084750366032\n",
      "train loss:0.021204263622692943\n",
      "train loss:0.050666896917661394\n",
      "train loss:0.021159756369406587\n",
      "train loss:0.02059223631065029\n",
      "train loss:0.009501688160208917\n",
      "train loss:0.005798357840207546\n",
      "train loss:0.0038470930560824145\n",
      "train loss:0.03623605484273711\n",
      "train loss:0.008844729679154072\n",
      "train loss:0.16870075240943627\n",
      "train loss:0.009913805583393375\n",
      "train loss:0.002954342052088666\n",
      "train loss:0.0303658741093143\n",
      "train loss:0.09153666536508089\n",
      "train loss:0.00887643888434852\n",
      "train loss:0.011839962241312032\n",
      "train loss:0.01324195212995296\n",
      "train loss:0.06702154743718924\n",
      "train loss:0.002692597090794382\n",
      "train loss:0.03787097872256315\n",
      "train loss:0.014011583551959236\n",
      "train loss:0.004805578161300346\n",
      "train loss:0.005513737718681635\n",
      "train loss:0.036379745974953116\n",
      "train loss:0.011339199933572268\n",
      "train loss:0.017163516251208752\n",
      "train loss:0.01753737478619135\n",
      "train loss:0.004868553639752234\n",
      "train loss:0.021062183132027706\n",
      "train loss:0.036528907319132546\n",
      "train loss:0.010463994428029482\n",
      "=== epoch:6, train acc:0.984, test acc:0.984 ===\n",
      "train loss:0.026229432800992818\n",
      "train loss:0.0054229845790800665\n",
      "train loss:0.012730148267778104\n",
      "train loss:0.028697311474898665\n",
      "train loss:0.013119610990754524\n",
      "train loss:0.006944491368253092\n",
      "train loss:0.028243926396414498\n",
      "train loss:0.02412817136983181\n",
      "train loss:0.02306343829518815\n",
      "train loss:0.007779177976870745\n",
      "train loss:0.03399329528708783\n",
      "train loss:0.026147893096491\n",
      "train loss:0.04190654956071128\n",
      "train loss:0.0017276314715601953\n",
      "train loss:0.02236261810023288\n",
      "train loss:0.02223106258627495\n",
      "train loss:0.04396765700294175\n",
      "train loss:0.02914936113507365\n",
      "train loss:0.04588903761937542\n",
      "train loss:0.017469305632833443\n",
      "train loss:0.022499552211258676\n",
      "train loss:0.00592949304688253\n",
      "train loss:0.014792930804749423\n",
      "train loss:0.010044551009693892\n",
      "train loss:0.03278467984477162\n",
      "train loss:0.00842446968211344\n",
      "train loss:0.03151577798356749\n",
      "train loss:0.01861949889016442\n",
      "train loss:0.02627924328415046\n",
      "train loss:0.009029141947729679\n",
      "train loss:0.01049090150645843\n",
      "train loss:0.022230643997481488\n",
      "train loss:0.07669187969140537\n",
      "train loss:0.0070105389008324305\n",
      "train loss:0.020290318551044503\n",
      "train loss:0.00809488584352158\n",
      "train loss:0.010537725153057197\n",
      "train loss:0.03152680069774282\n",
      "train loss:0.04570354106772219\n",
      "train loss:0.007640482284322089\n",
      "train loss:0.00442825066988561\n",
      "train loss:0.04204644991512452\n",
      "train loss:0.00646321072753539\n",
      "train loss:0.011410225260888394\n",
      "train loss:0.0066609550395980155\n",
      "train loss:0.0339409200985793\n",
      "train loss:0.008309376100152352\n",
      "train loss:0.028710371360640478\n",
      "train loss:0.0074162116538760625\n",
      "train loss:0.012336198050037231\n",
      "train loss:0.019045960178039043\n",
      "train loss:0.020255188125824834\n",
      "train loss:0.036937255419625455\n",
      "train loss:0.02112994072868251\n",
      "train loss:0.05959865742306869\n",
      "train loss:0.020451842491700824\n",
      "train loss:0.007530268933128571\n",
      "train loss:0.05429202974892953\n",
      "train loss:0.013784311247444208\n",
      "train loss:0.03969772777609773\n",
      "train loss:0.07079704869708797\n",
      "train loss:0.009275882255078242\n",
      "train loss:0.0030897727819431337\n",
      "train loss:0.034560537729437374\n",
      "train loss:0.008447511096026072\n",
      "train loss:0.0048036323166397955\n",
      "train loss:0.017561244154580342\n",
      "train loss:0.06107960318740201\n",
      "train loss:0.005483552496475629\n",
      "train loss:0.03984871611453519\n",
      "train loss:0.012870530788935144\n",
      "train loss:0.05529842785092803\n",
      "train loss:0.051662761832832346\n",
      "train loss:0.011498137830874736\n",
      "train loss:0.022092828295231987\n",
      "train loss:0.012619203919383386\n",
      "train loss:0.02411525008870016\n",
      "train loss:0.0289701737742734\n",
      "train loss:0.014574469458416546\n",
      "train loss:0.005979319319568449\n",
      "train loss:0.014267528108598927\n",
      "train loss:0.0110313233187426\n",
      "train loss:0.01718775918246457\n",
      "train loss:0.006976728471370165\n",
      "train loss:0.023489212301488788\n",
      "train loss:0.039213881551545475\n",
      "train loss:0.039777363255128505\n",
      "train loss:0.02451686080048149\n",
      "train loss:0.01822114643202624\n",
      "train loss:0.009519589166504257\n",
      "train loss:0.01741132194223659\n",
      "train loss:0.006788929647766378\n",
      "train loss:0.010180711061935785\n",
      "train loss:0.018306433106214205\n",
      "train loss:0.006845336416819092\n",
      "train loss:0.0381622815334851\n",
      "train loss:0.02367800731573685\n",
      "train loss:0.012680081645803427\n",
      "train loss:0.06594920973677366\n",
      "train loss:0.008393380702666799\n",
      "train loss:0.004605645685871087\n",
      "train loss:0.017123631079656504\n",
      "train loss:0.02448052201594101\n",
      "train loss:0.003241402600669812\n",
      "train loss:0.004501998977521422\n",
      "train loss:0.011371324236496899\n",
      "train loss:0.02168715069957886\n",
      "train loss:0.020315280596559942\n",
      "train loss:0.008496091597172253\n",
      "train loss:0.014120796712170385\n",
      "train loss:0.013944631883404463\n",
      "train loss:0.022038640678405014\n",
      "train loss:0.015412951679882804\n",
      "train loss:0.0061927484650595235\n",
      "train loss:0.12672634538869398\n",
      "train loss:0.00529498305334616\n",
      "train loss:0.010537600204419432\n",
      "train loss:0.004345147309642174\n",
      "train loss:0.00902858720341319\n",
      "train loss:0.019855862747494468\n",
      "train loss:0.14420426780832962\n",
      "train loss:0.017076364653300476\n",
      "train loss:0.008468998816184601\n",
      "train loss:0.014089386916365956\n",
      "train loss:0.0048496264317322655\n",
      "train loss:0.0035043627396486392\n",
      "train loss:0.005589639819534765\n",
      "train loss:0.03546168359454905\n",
      "train loss:0.016215941510216794\n",
      "train loss:0.021311970958721865\n",
      "train loss:0.09777020167901249\n",
      "train loss:0.03416187200791431\n",
      "train loss:0.013745533327342619\n",
      "train loss:0.07219226773131616\n",
      "train loss:0.033819240399022045\n",
      "train loss:0.012193635116948008\n",
      "train loss:0.006120219578071696\n",
      "train loss:0.025393013589384332\n",
      "train loss:0.006998899119993141\n",
      "train loss:0.03603515797675047\n",
      "train loss:0.012686386063487525\n",
      "train loss:0.013660824682953725\n",
      "train loss:0.10671716271606754\n",
      "train loss:0.02833090300598981\n",
      "train loss:0.05668867661226671\n",
      "train loss:0.016895193555265416\n",
      "train loss:0.017920549094419896\n",
      "train loss:0.12174786757712587\n",
      "train loss:0.006881898335961688\n",
      "train loss:0.015951967619207377\n",
      "train loss:0.042184302330820114\n",
      "train loss:0.013675302541994063\n",
      "train loss:0.028911608041164893\n",
      "train loss:0.018679505793015302\n",
      "train loss:0.03177966710866123\n",
      "train loss:0.036291319299491316\n",
      "train loss:0.006352509221369246\n",
      "train loss:0.04769788867450557\n",
      "train loss:0.06278819461259734\n",
      "train loss:0.02752086769574398\n",
      "train loss:0.031132289915011553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01853260219662784\n",
      "train loss:0.008147389401110107\n",
      "train loss:0.009353737375787607\n",
      "train loss:0.008987445800672171\n",
      "train loss:0.03146783352904234\n",
      "train loss:0.010612137552889825\n",
      "train loss:0.004517656449847393\n",
      "train loss:0.012327703226058952\n",
      "train loss:0.029857652508070286\n",
      "train loss:0.025203947941057275\n",
      "train loss:0.024984248536807384\n",
      "train loss:0.04117320407992815\n",
      "train loss:0.04936158278269971\n",
      "train loss:0.03312314600781184\n",
      "train loss:0.026129573826407734\n",
      "train loss:0.022045544311960895\n",
      "train loss:0.008840396306206613\n",
      "train loss:0.02155777031094073\n",
      "train loss:0.02085736217036777\n",
      "train loss:0.01691491761315156\n",
      "train loss:0.013810184048742801\n",
      "train loss:0.008903684662516962\n",
      "train loss:0.05263245778297665\n",
      "train loss:0.016526812563392432\n",
      "train loss:0.027413287589481618\n",
      "train loss:0.030034180494366368\n",
      "train loss:0.02503236403814444\n",
      "train loss:0.01905570476874392\n",
      "train loss:0.013126889015606213\n",
      "train loss:0.08195424216666566\n",
      "train loss:0.03052502582965205\n",
      "train loss:0.010726720376673967\n",
      "train loss:0.004612017176267854\n",
      "train loss:0.02394635512179974\n",
      "train loss:0.03210640312083137\n",
      "train loss:0.0053293359396757445\n",
      "train loss:0.03319258295326673\n",
      "train loss:0.036053053176195456\n",
      "train loss:0.014397767904941516\n",
      "train loss:0.02503421930432801\n",
      "train loss:0.029466868265284284\n",
      "train loss:0.021535991430924488\n",
      "train loss:0.04989797319726908\n",
      "train loss:0.0066993049415611594\n",
      "train loss:0.05889704876191879\n",
      "train loss:0.005311513604456345\n",
      "train loss:0.009438822909837842\n",
      "train loss:0.040759313351802724\n",
      "train loss:0.03101153956178409\n",
      "train loss:0.013205093131819246\n",
      "train loss:0.02444854134858441\n",
      "train loss:0.010433402851244014\n",
      "train loss:0.0586288585500659\n",
      "train loss:0.005240093472566728\n",
      "train loss:0.008166338243769137\n",
      "train loss:0.009520916355993628\n",
      "train loss:0.0515167837601572\n",
      "train loss:0.02042747761638372\n",
      "train loss:0.010139214832527726\n",
      "train loss:0.0979826475247924\n",
      "train loss:0.012485363274205153\n",
      "train loss:0.022022091287477955\n",
      "train loss:0.02869927693819493\n",
      "train loss:0.009268489635334103\n",
      "train loss:0.11611744491195694\n",
      "train loss:0.03324244431834543\n",
      "train loss:0.004000858121863792\n",
      "train loss:0.06196370263693259\n",
      "train loss:0.033400225698775356\n",
      "train loss:0.03471521510419791\n",
      "train loss:0.037068715152485276\n",
      "train loss:0.0372742302742003\n",
      "train loss:0.00378026783276739\n",
      "train loss:0.031042823296952186\n",
      "train loss:0.05231139798452033\n",
      "train loss:0.022481755679171052\n",
      "train loss:0.010036812339206473\n",
      "train loss:0.031521724686065566\n",
      "train loss:0.011120189993087788\n",
      "train loss:0.013242592180839653\n",
      "train loss:0.023266832763724904\n",
      "train loss:0.04192653272989697\n",
      "train loss:0.034149364367067475\n",
      "train loss:0.006919139658599837\n",
      "train loss:0.025612732937241804\n",
      "train loss:0.021867711191912532\n",
      "train loss:0.04337780333358312\n",
      "train loss:0.0072945911547029505\n",
      "train loss:0.013409114020563195\n",
      "train loss:0.020232176767161523\n",
      "train loss:0.016248635514200718\n",
      "train loss:0.025040419346401284\n",
      "train loss:0.06377503354681772\n",
      "train loss:0.02036559191895959\n",
      "train loss:0.017857580927305466\n",
      "train loss:0.05071876548892187\n",
      "train loss:0.0150142060393139\n",
      "train loss:0.01787285240384659\n",
      "train loss:0.015290724598395351\n",
      "train loss:0.10739858728619436\n",
      "train loss:0.0053296533585681614\n",
      "train loss:0.033815610323789304\n",
      "train loss:0.013047574703391223\n",
      "train loss:0.011362996854800269\n",
      "train loss:0.019585043413203485\n",
      "train loss:0.0030201476078936316\n",
      "train loss:0.022673336777223115\n",
      "train loss:0.0179917577510559\n",
      "train loss:0.005477388113177561\n",
      "train loss:0.027001979373613705\n",
      "train loss:0.016822527855709847\n",
      "train loss:0.011743883254130932\n",
      "train loss:0.013848683851668056\n",
      "train loss:0.03462632238169467\n",
      "train loss:0.013135582329411337\n",
      "train loss:0.020675384291557748\n",
      "train loss:0.021401621972915792\n",
      "train loss:0.019327350067594458\n",
      "train loss:0.003410226969692529\n",
      "train loss:0.009491461642899712\n",
      "train loss:0.039171162909365946\n",
      "train loss:0.009697874773239919\n",
      "train loss:0.011495912077950143\n",
      "train loss:0.010425523432657796\n",
      "train loss:0.027053048022400054\n",
      "train loss:0.00302473522136979\n",
      "train loss:0.017226984900530398\n",
      "train loss:0.04430270117307921\n",
      "train loss:0.017178627188902715\n",
      "train loss:0.023117927505908277\n",
      "train loss:0.014518050596041897\n",
      "train loss:0.01878664204495059\n",
      "train loss:0.009467296612120764\n",
      "train loss:0.014540993589179669\n",
      "train loss:0.024916930215361118\n",
      "train loss:0.01763261479352867\n",
      "train loss:0.052027486049229854\n",
      "train loss:0.06918052107228535\n",
      "train loss:0.02817002281181029\n",
      "train loss:0.062494047644290444\n",
      "train loss:0.04008009940101073\n",
      "train loss:0.007834857820746298\n",
      "train loss:0.014311564041379217\n",
      "train loss:0.01839435837638155\n",
      "train loss:0.018418486171913103\n",
      "train loss:0.011995062796786853\n",
      "train loss:0.0021258810669826395\n",
      "train loss:0.030901250868094275\n",
      "train loss:0.00803401015455285\n",
      "train loss:0.12219185591298683\n",
      "train loss:0.02504257050020601\n",
      "train loss:0.018372122069005875\n",
      "train loss:0.014826787669059873\n",
      "train loss:0.01752333759639303\n",
      "train loss:0.013741193832221006\n",
      "train loss:0.046376570545159146\n",
      "train loss:0.00633993292146371\n",
      "train loss:0.00979390111210822\n",
      "train loss:0.005168578508538375\n",
      "train loss:0.02168231140255057\n",
      "train loss:0.013815006473858716\n",
      "train loss:0.023194971997922646\n",
      "train loss:0.00252589611121534\n",
      "train loss:0.0731641935216381\n",
      "train loss:0.03747914847483197\n",
      "train loss:0.049356327795293364\n",
      "train loss:0.1300685488826764\n",
      "train loss:0.007551389306182622\n",
      "train loss:0.08190398837019243\n",
      "train loss:0.01389950847646112\n",
      "train loss:0.023654290767658456\n",
      "train loss:0.053085929250751514\n",
      "train loss:0.003881511813561239\n",
      "train loss:0.007754785269001483\n",
      "train loss:0.0106070127928555\n",
      "train loss:0.07587750368589447\n",
      "train loss:0.022844479585979734\n",
      "train loss:0.02549685801966565\n",
      "train loss:0.04183892221893144\n",
      "train loss:0.017616163498844102\n",
      "train loss:0.011847081571555373\n",
      "train loss:0.007805957089916192\n",
      "train loss:0.013341664218105715\n",
      "train loss:0.07855440059149735\n",
      "train loss:0.010023650758739344\n",
      "train loss:0.010757213086033295\n",
      "train loss:0.023511145389917623\n",
      "train loss:0.007316842006681857\n",
      "train loss:0.05221002689243322\n",
      "train loss:0.013105423043957766\n",
      "train loss:0.028026356481105116\n",
      "train loss:0.02409985009093125\n",
      "train loss:0.029519032071358017\n",
      "train loss:0.011832948146567648\n",
      "train loss:0.013276076046989953\n",
      "train loss:0.04923683170309309\n",
      "train loss:0.007365478434151183\n",
      "train loss:0.017484365853162806\n",
      "train loss:0.02945734842476308\n",
      "train loss:0.010854115373401198\n",
      "train loss:0.006831226837386913\n",
      "train loss:0.004793497696614774\n",
      "train loss:0.01689991868034923\n",
      "train loss:0.012420437354351426\n",
      "train loss:0.09992027615842268\n",
      "train loss:0.010643417770888387\n",
      "train loss:0.03201100322586044\n",
      "train loss:0.09284953547008595\n",
      "train loss:0.009122730444902926\n",
      "train loss:0.027797544025198934\n",
      "train loss:0.009806751407642445\n",
      "train loss:0.013098498421128752\n",
      "train loss:0.004473031008275621\n",
      "train loss:0.010182234806409632\n",
      "train loss:0.012527730469316292\n",
      "train loss:0.03065283940490925\n",
      "train loss:0.043559771013518246\n",
      "train loss:0.06943314600901412\n",
      "train loss:0.03264782872087077\n",
      "train loss:0.03363589782632746\n",
      "train loss:0.020887913058429394\n",
      "train loss:0.014141960897622128\n",
      "train loss:0.007714185985349806\n",
      "train loss:0.012976721469072743\n",
      "train loss:0.006133733873704079\n",
      "train loss:0.03703054877682912\n",
      "train loss:0.036738136443228556\n",
      "train loss:0.005394948004510562\n",
      "train loss:0.03498456347281542\n",
      "train loss:0.006301017086500347\n",
      "train loss:0.007605441232012965\n",
      "train loss:0.024596878132491833\n",
      "train loss:0.011445088071862142\n",
      "train loss:0.027330516879835835\n",
      "train loss:0.020913143499304274\n",
      "train loss:0.011122243033347494\n",
      "train loss:0.010888481883492906\n",
      "train loss:0.014990292850695195\n",
      "train loss:0.00987687413308416\n",
      "train loss:0.011336288185790945\n",
      "train loss:0.036808546349218305\n",
      "train loss:0.01796895581459467\n",
      "train loss:0.008787367887416788\n",
      "train loss:0.018043895589220996\n",
      "train loss:0.030605635077368055\n",
      "train loss:0.024274750575962744\n",
      "train loss:0.061445960582398124\n",
      "train loss:0.010107696296114781\n",
      "train loss:0.009697472857724307\n",
      "train loss:0.00571211846118368\n",
      "train loss:0.017084516701753386\n",
      "train loss:0.004379479582648772\n",
      "train loss:0.009071299430795618\n",
      "train loss:0.009027810008092708\n",
      "train loss:0.010926838374186716\n",
      "train loss:0.060669947272084565\n",
      "train loss:0.026315016794796052\n",
      "train loss:0.02689757248742136\n",
      "train loss:0.007249982580397382\n",
      "train loss:0.04776420185947327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01925132279680282\n",
      "train loss:0.0263085853161888\n",
      "train loss:0.010197650054177877\n",
      "train loss:0.03407876695271479\n",
      "train loss:0.009786033962772535\n",
      "train loss:0.017845925158180603\n",
      "train loss:0.07929211639487613\n",
      "train loss:0.021607540393506007\n",
      "train loss:0.02063384413249768\n",
      "train loss:0.07013504997764557\n",
      "train loss:0.01447570032442254\n",
      "train loss:0.004196200180652672\n",
      "train loss:0.03012470600713206\n",
      "train loss:0.018244441562567815\n",
      "train loss:0.0076063092881455165\n",
      "train loss:0.01894207843488835\n",
      "train loss:0.011159942135039012\n",
      "train loss:0.025472410762072815\n",
      "train loss:0.019070173324655746\n",
      "train loss:0.017541269966671463\n",
      "train loss:0.023713110445781838\n",
      "train loss:0.07120390265756675\n",
      "train loss:0.03447139772516786\n",
      "train loss:0.007194195602122233\n",
      "train loss:0.061345891940391126\n",
      "train loss:0.03827636717740621\n",
      "train loss:0.024535761644604418\n",
      "train loss:0.01939305256691462\n",
      "train loss:0.006674493633375719\n",
      "train loss:0.011810541275993769\n",
      "train loss:0.005299467256321366\n",
      "train loss:0.01932133853447241\n",
      "train loss:0.023336513058929132\n",
      "train loss:0.010723734775174713\n",
      "train loss:0.02300493808186232\n",
      "train loss:0.007560083414423717\n",
      "train loss:0.03401078921294883\n",
      "train loss:0.069131287914985\n",
      "train loss:0.010928308576178832\n",
      "train loss:0.02905492922555765\n",
      "train loss:0.021833031665032206\n",
      "train loss:0.011443131718670587\n",
      "train loss:0.0017407618490641237\n",
      "train loss:0.027490860707731383\n",
      "train loss:0.08241335074664143\n",
      "train loss:0.021220679684463558\n",
      "train loss:0.007195332918643701\n",
      "train loss:0.00851955693578515\n",
      "train loss:0.021214046289689946\n",
      "train loss:0.031326208894169996\n",
      "train loss:0.02206258992851077\n",
      "train loss:0.012441730243406364\n",
      "train loss:0.008969399588424784\n",
      "train loss:0.01260720365587255\n",
      "train loss:0.024325564042612612\n",
      "train loss:0.016679075177365797\n",
      "train loss:0.04993102526683794\n",
      "train loss:0.011050589198494155\n",
      "train loss:0.004778881744062723\n",
      "train loss:0.009834899218630809\n",
      "train loss:0.005808517778272365\n",
      "train loss:0.041575606825238\n",
      "train loss:0.006575252244713281\n",
      "train loss:0.009644234691912253\n",
      "train loss:0.0069473505552760184\n",
      "train loss:0.06746701027275247\n",
      "train loss:0.02949748839933841\n",
      "train loss:0.009389191946190126\n",
      "train loss:0.004444870349014922\n",
      "train loss:0.004692156299710999\n",
      "train loss:0.009241378921713252\n",
      "train loss:0.004500934711436921\n",
      "train loss:0.01170536533613792\n",
      "train loss:0.004160679206952897\n",
      "train loss:0.0023676321573011774\n",
      "train loss:0.029067970950181078\n",
      "train loss:0.003990425262200924\n",
      "train loss:0.005044400933611412\n",
      "train loss:0.016128921635820314\n",
      "train loss:0.007523300044006687\n",
      "train loss:0.035274730747799486\n",
      "train loss:0.002808244508831686\n",
      "train loss:0.009927458224018065\n",
      "train loss:0.028538449689948946\n",
      "train loss:0.03347755271045452\n",
      "train loss:0.0017073752293881204\n",
      "train loss:0.006807909574449889\n",
      "train loss:0.03124691271628447\n",
      "train loss:0.003695881369819239\n",
      "train loss:0.0018380903537089939\n",
      "train loss:0.009226083952037407\n",
      "train loss:0.07876945262090501\n",
      "train loss:0.009242828460907272\n",
      "train loss:0.009548285121007562\n",
      "train loss:0.018508794086223444\n",
      "train loss:0.018991874032898138\n",
      "train loss:0.006094140636198076\n",
      "train loss:0.02024692928956977\n",
      "train loss:0.00783204940492297\n",
      "train loss:0.11587918792436604\n",
      "train loss:0.015267097948613915\n",
      "train loss:0.03260912518984494\n",
      "train loss:0.02561783280025836\n",
      "train loss:0.008751250435927916\n",
      "train loss:0.03431920312665642\n",
      "train loss:0.04781943893584192\n",
      "train loss:0.003235933958325255\n",
      "train loss:0.05051143405097691\n",
      "train loss:0.013207815418469868\n",
      "train loss:0.032108191879154424\n",
      "train loss:0.029733822288010008\n",
      "train loss:0.01657443797963409\n",
      "train loss:0.027198334106959626\n",
      "train loss:0.023149044996661074\n",
      "train loss:0.013475558295535393\n",
      "train loss:0.18510130698993302\n",
      "train loss:0.040215458211226573\n",
      "train loss:0.008553605898339357\n",
      "train loss:0.005893785860100988\n",
      "train loss:0.011257294543769327\n",
      "train loss:0.016822159912859763\n",
      "train loss:0.058783026513151204\n",
      "train loss:0.001364702672658771\n",
      "train loss:0.006182805144518927\n",
      "train loss:0.04519209891430271\n",
      "train loss:0.01082079939012145\n",
      "train loss:0.022388710114770463\n",
      "train loss:0.007386110208230326\n",
      "train loss:0.02044815109112883\n",
      "train loss:0.004742834366604875\n",
      "train loss:0.04375244666905107\n",
      "train loss:0.02440899680562192\n",
      "train loss:0.004377969138678256\n",
      "train loss:0.024244115150739723\n",
      "train loss:0.008747813625049925\n",
      "train loss:0.02616919765757737\n",
      "train loss:0.00807723967886568\n",
      "train loss:0.04707848384321839\n",
      "train loss:0.0075425867851157315\n",
      "train loss:0.018271535624131797\n",
      "train loss:0.026839571465588796\n",
      "train loss:0.032238325631940505\n",
      "train loss:0.017464310276274365\n",
      "train loss:0.013862479764727815\n",
      "train loss:0.009767272180929718\n",
      "train loss:0.017650020181306264\n",
      "train loss:0.012007703162461636\n",
      "train loss:0.013779402473459572\n",
      "train loss:0.10087218328283507\n",
      "train loss:0.01944279515019144\n",
      "train loss:0.022745841251165872\n",
      "train loss:0.005425338866968872\n",
      "train loss:0.009000525830374301\n",
      "train loss:0.0034387071492330227\n",
      "train loss:0.03162396269359024\n",
      "train loss:0.02589280895304906\n",
      "train loss:0.025009268856381238\n",
      "train loss:0.01939478534002827\n",
      "train loss:0.012896029334308494\n",
      "train loss:0.020681351784609777\n",
      "train loss:0.026993077989458766\n",
      "train loss:0.046186323479310794\n",
      "train loss:0.01665100731891923\n",
      "train loss:0.005640395840559856\n",
      "train loss:0.015112613908692694\n",
      "train loss:0.017548717001169955\n",
      "train loss:0.005298168580252188\n",
      "train loss:0.02522304156630649\n",
      "train loss:0.029654895143873653\n",
      "train loss:0.008441546204512379\n",
      "train loss:0.008394469384290788\n",
      "train loss:0.0059157360672958716\n",
      "train loss:0.009536820439544803\n",
      "train loss:0.044344411752782135\n",
      "train loss:0.03342713835731039\n",
      "train loss:0.004130522392192871\n",
      "train loss:0.03883062853429403\n",
      "train loss:0.020623673768893527\n",
      "train loss:0.007116490919712698\n",
      "=== epoch:7, train acc:0.987, test acc:0.984 ===\n",
      "train loss:0.014512946632082477\n",
      "train loss:0.036558808160837494\n",
      "train loss:0.02018452585826691\n",
      "train loss:0.004056058553910847\n",
      "train loss:0.007789550884330389\n",
      "train loss:0.009168014315354741\n",
      "train loss:0.012805697740269179\n",
      "train loss:0.006027773898919306\n",
      "train loss:0.024341229626112407\n",
      "train loss:0.0051886091669994736\n",
      "train loss:0.010701247669905638\n",
      "train loss:0.01579036825611502\n",
      "train loss:0.03659344739086078\n",
      "train loss:0.00769633181842624\n",
      "train loss:0.005478785538321914\n",
      "train loss:0.013064108835550417\n",
      "train loss:0.023438354189063107\n",
      "train loss:0.054626455905562664\n",
      "train loss:0.010924680480367665\n",
      "train loss:0.07985301733167041\n",
      "train loss:0.022548940785680937\n",
      "train loss:0.03700054652938496\n",
      "train loss:0.007268040254566291\n",
      "train loss:0.05035649231412194\n",
      "train loss:0.006311082981557298\n",
      "train loss:0.0220152957235855\n",
      "train loss:0.009823481474744973\n",
      "train loss:0.0079984208982698\n",
      "train loss:0.05222360389605006\n",
      "train loss:0.007716176909236381\n",
      "train loss:0.06741211908129977\n",
      "train loss:0.01756624419202566\n",
      "train loss:0.028293566874978405\n",
      "train loss:0.045351333350662965\n",
      "train loss:0.00669079678087539\n",
      "train loss:0.007106161536229319\n",
      "train loss:0.007157483665266942\n",
      "train loss:0.012039136934373338\n",
      "train loss:0.010193839563912748\n",
      "train loss:0.008067409976590842\n",
      "train loss:0.04416168911597249\n",
      "train loss:0.034600988173855554\n",
      "train loss:0.028286485252512265\n",
      "train loss:0.01811941240161012\n",
      "train loss:0.005937741644153394\n",
      "train loss:0.017777391405475886\n",
      "train loss:0.0035670180265116196\n",
      "train loss:0.044935307852654656\n",
      "train loss:0.0312575307597999\n",
      "train loss:0.0064880760925617505\n",
      "train loss:0.007534023301102718\n",
      "train loss:0.014327083402242147\n",
      "train loss:0.00524029928711838\n",
      "train loss:0.05262406338264805\n",
      "train loss:0.024208415842023313\n",
      "train loss:0.00931974480825283\n",
      "train loss:0.0301919673742601\n",
      "train loss:0.008852773349121445\n",
      "train loss:0.01514917862863571\n",
      "train loss:0.02436740305759694\n",
      "train loss:0.03166497877003592\n",
      "train loss:0.0041553184660806704\n",
      "train loss:0.01031400575893198\n",
      "train loss:0.007148299112622674\n",
      "train loss:0.03326715118579094\n",
      "train loss:0.05150084681541811\n",
      "train loss:0.012327810934704704\n",
      "train loss:0.013357722733197004\n",
      "train loss:0.01870795500032671\n",
      "train loss:0.006351177965316776\n",
      "train loss:0.016508631005415907\n",
      "train loss:0.011090748111456892\n",
      "train loss:0.008946258501404068\n",
      "train loss:0.009156462352930621\n",
      "train loss:0.01430588234323641\n",
      "train loss:0.02917115829303563\n",
      "train loss:0.0109453264371348\n",
      "train loss:0.06486825968899498\n",
      "train loss:0.020130750647029617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005720983628799286\n",
      "train loss:0.06467747313296171\n",
      "train loss:0.004619885120993802\n",
      "train loss:0.003737190747550061\n",
      "train loss:0.08637640470112816\n",
      "train loss:0.05983464452279632\n",
      "train loss:0.05078828334046082\n",
      "train loss:0.009679526916979805\n",
      "train loss:0.008611416341454726\n",
      "train loss:0.031470565722581355\n",
      "train loss:0.015285590464289438\n",
      "train loss:0.00493527713726016\n",
      "train loss:0.010843176141934951\n",
      "train loss:0.01694800719289099\n",
      "train loss:0.006912281953963571\n",
      "train loss:0.03481280569436977\n",
      "train loss:0.009841343967534092\n",
      "train loss:0.003704603248546767\n",
      "train loss:0.014435847553538595\n",
      "train loss:0.008116981401797351\n",
      "train loss:0.060801890392328445\n",
      "train loss:0.046926105895381875\n",
      "train loss:0.010582874302181773\n",
      "train loss:0.02135917763582429\n",
      "train loss:0.015364665263428898\n",
      "train loss:0.006601370966561798\n",
      "train loss:0.014277488916052707\n",
      "train loss:0.006186701800181623\n",
      "train loss:0.011507207844225003\n",
      "train loss:0.054460089665055944\n",
      "train loss:0.013030358474221826\n",
      "train loss:0.027580614877151133\n",
      "train loss:0.07338368456762497\n",
      "train loss:0.009323410786659735\n",
      "train loss:0.016300149134201313\n",
      "train loss:0.005865675417537551\n",
      "train loss:0.04190939241665416\n",
      "train loss:0.011427404477252183\n",
      "train loss:0.032063682752020414\n",
      "train loss:0.00546957903107375\n",
      "train loss:0.009267087623087646\n",
      "train loss:0.04055583941830007\n",
      "train loss:0.009117434918473161\n",
      "train loss:0.017340954178883813\n",
      "train loss:0.02674734789162178\n",
      "train loss:0.004796043364728988\n",
      "train loss:0.01756166210636739\n",
      "train loss:0.0024599725350978284\n",
      "train loss:0.015788672886467882\n",
      "train loss:0.04261342166781902\n",
      "train loss:0.0284021538741678\n",
      "train loss:0.02399317736985123\n",
      "train loss:0.014841569289307991\n",
      "train loss:0.018881506688862782\n",
      "train loss:0.02689249566283364\n",
      "train loss:0.006755689880445993\n",
      "train loss:0.022586107413668434\n",
      "train loss:0.09512000564333524\n",
      "train loss:0.036652328087147794\n",
      "train loss:0.02712292714689227\n",
      "train loss:0.002174029258620324\n",
      "train loss:0.010407562151744239\n",
      "train loss:0.034659763622872757\n",
      "train loss:0.014378949579619587\n",
      "train loss:0.03369321025826677\n",
      "train loss:0.015606494039369418\n",
      "train loss:0.06113281578566418\n",
      "train loss:0.04740718632799554\n",
      "train loss:0.037753157405728745\n",
      "train loss:0.006278018290540295\n",
      "train loss:0.013299687465285091\n",
      "train loss:0.0038762350322502238\n",
      "train loss:0.024659079695588944\n",
      "train loss:0.022571808098238205\n",
      "train loss:0.010148175092842352\n",
      "train loss:0.016029562163774724\n",
      "train loss:0.008419350737787837\n",
      "train loss:0.008919274624525231\n",
      "train loss:0.11239333896390848\n",
      "train loss:0.03865886120093508\n",
      "train loss:0.009762706634541977\n",
      "train loss:0.012680040575395419\n",
      "train loss:0.008828805724151791\n",
      "train loss:0.010884924434947978\n",
      "train loss:0.0090405117029967\n",
      "train loss:0.021388082252302737\n",
      "train loss:0.008293032832163892\n",
      "train loss:0.01847246549147119\n",
      "train loss:0.017359276913844014\n",
      "train loss:0.010086690116712876\n",
      "train loss:0.06148125026253129\n",
      "train loss:0.0055127822051419355\n",
      "train loss:0.013271232039645153\n",
      "train loss:0.008229230033348012\n",
      "train loss:0.07795320579758078\n",
      "train loss:0.010723879628034907\n",
      "train loss:0.02020860705437737\n",
      "train loss:0.004012307615555367\n",
      "train loss:0.006472380197311174\n",
      "train loss:0.008172994372614288\n",
      "train loss:0.010473473875768764\n",
      "train loss:0.029936238356622374\n",
      "train loss:0.00346880062151072\n",
      "train loss:0.00435043150314242\n",
      "train loss:0.00611825342123076\n",
      "train loss:0.020156443926420683\n",
      "train loss:0.017062346869072428\n",
      "train loss:0.10580179773384019\n",
      "train loss:0.006825447086730318\n",
      "train loss:0.022262990733278802\n",
      "train loss:0.020085565891688112\n",
      "train loss:0.010435005998457569\n",
      "train loss:0.003879022901561892\n",
      "train loss:0.06782992131472929\n",
      "train loss:0.004430854240448323\n",
      "train loss:0.026465861037212105\n",
      "train loss:0.012869861634800604\n",
      "train loss:0.011185275746950796\n",
      "train loss:0.0033347510086050637\n",
      "train loss:0.020295997985057025\n",
      "train loss:0.020354466377465345\n",
      "train loss:0.024969305673627814\n",
      "train loss:0.011952367498617056\n",
      "train loss:0.0027400319250489745\n",
      "train loss:0.0032147589558886177\n",
      "train loss:0.015591402096305386\n",
      "train loss:0.01404766719905709\n",
      "train loss:0.016815321725673203\n",
      "train loss:0.014560126753811622\n",
      "train loss:0.00824270043823955\n",
      "train loss:0.007600048287402077\n",
      "train loss:0.0038560701855540765\n",
      "train loss:0.022815662849657175\n",
      "train loss:0.01866570178770434\n",
      "train loss:0.0038094535604401747\n",
      "train loss:0.01647196609428657\n",
      "train loss:0.001296822048714514\n",
      "train loss:0.008425498612050424\n",
      "train loss:0.052004347521789694\n",
      "train loss:0.016889505074742725\n",
      "train loss:0.021578589732467\n",
      "train loss:0.001596149842535313\n",
      "train loss:0.007202905353000463\n",
      "train loss:0.009845842942392593\n",
      "train loss:0.0007357647630677533\n",
      "train loss:0.05639110880246617\n",
      "train loss:0.08857942183913856\n",
      "train loss:0.002164878610203412\n",
      "train loss:0.013642698703679713\n",
      "train loss:0.004061725330084813\n",
      "train loss:0.006534062766035418\n",
      "train loss:0.01620547574623998\n",
      "train loss:0.008108099706358245\n",
      "train loss:0.01706504146338544\n",
      "train loss:0.004765884075097693\n",
      "train loss:0.0102794451921833\n",
      "train loss:0.005862846719850108\n",
      "train loss:0.014283710247946389\n",
      "train loss:0.023547145272396562\n",
      "train loss:0.009660748377611515\n",
      "train loss:0.004918434231310493\n",
      "train loss:0.014654002133913093\n",
      "train loss:0.01696548574681313\n",
      "train loss:0.01562393827977465\n",
      "train loss:0.16428052499141596\n",
      "train loss:0.011225085831390265\n",
      "train loss:0.02213580742160481\n",
      "train loss:0.0066570417530709605\n",
      "train loss:0.011689974926285034\n",
      "train loss:0.030581736842848827\n",
      "train loss:0.019937973980676548\n",
      "train loss:0.010849590513661394\n",
      "train loss:0.04443105155493419\n",
      "train loss:0.03167137422531936\n",
      "train loss:0.009500956588589257\n",
      "train loss:0.006573145762397872\n",
      "train loss:0.009035936871945129\n",
      "train loss:0.001739913041151807\n",
      "train loss:0.010238858329152991\n",
      "train loss:0.0023156900204329995\n",
      "train loss:0.017773639446954703\n",
      "train loss:0.03468682590115757\n",
      "train loss:0.018995416950699572\n",
      "train loss:0.013901614398985114\n",
      "train loss:0.01386482784901653\n",
      "train loss:0.058142245841925205\n",
      "train loss:0.011425026351145718\n",
      "train loss:0.016074150788951955\n",
      "train loss:0.051153256523386766\n",
      "train loss:0.007878829571968227\n",
      "train loss:0.029100719209061907\n",
      "train loss:0.06387458461619316\n",
      "train loss:0.0032348291645332445\n",
      "train loss:0.01571805462358053\n",
      "train loss:0.02399426289523238\n",
      "train loss:0.04196728042753351\n",
      "train loss:0.02284952257017737\n",
      "train loss:0.01291218099419712\n",
      "train loss:0.009449579699398218\n",
      "train loss:0.005382283476219599\n",
      "train loss:0.009338610000804265\n",
      "train loss:0.014442900379579406\n",
      "train loss:0.1421057590148142\n",
      "train loss:0.01460862776974767\n",
      "train loss:0.013715139803113209\n",
      "train loss:0.005287391540777711\n",
      "train loss:0.017328340726878385\n",
      "train loss:0.017799938717853517\n",
      "train loss:0.01684891899530645\n",
      "train loss:0.07443917125083502\n",
      "train loss:0.03358511539826716\n",
      "train loss:0.02493555163374877\n",
      "train loss:0.013261716930395306\n",
      "train loss:0.0024521655610162786\n",
      "train loss:0.03771212610652923\n",
      "train loss:0.006031344845407424\n",
      "train loss:0.013591661732190966\n",
      "train loss:0.010892871942954107\n",
      "train loss:0.006945526302344116\n",
      "train loss:0.0048943969307436936\n",
      "train loss:0.006276549673064392\n",
      "train loss:0.004683353306071794\n",
      "train loss:0.014075015849569201\n",
      "train loss:0.021984896126478377\n",
      "train loss:0.018091260238378953\n",
      "train loss:0.011873172436829624\n",
      "train loss:0.006119797897669943\n",
      "train loss:0.0067398746998322\n",
      "train loss:0.029169383375339013\n",
      "train loss:0.0032891713599045537\n",
      "train loss:0.011298033731637031\n",
      "train loss:0.01578912166792284\n",
      "train loss:0.04687179659036384\n",
      "train loss:0.01662040661623016\n",
      "train loss:0.006992056299795759\n",
      "train loss:0.006717541668545224\n",
      "train loss:0.0037438944480633106\n",
      "train loss:0.006371933726718614\n",
      "train loss:0.010586757983615807\n",
      "train loss:0.05423692314390752\n",
      "train loss:0.002814444155242289\n",
      "train loss:0.055889427975859336\n",
      "train loss:0.054128222303332675\n",
      "train loss:0.008856856158043302\n",
      "train loss:0.01439048597156279\n",
      "train loss:0.03077023904003072\n",
      "train loss:0.011153931388955162\n",
      "train loss:0.00887799952411889\n",
      "train loss:0.01693370435681206\n",
      "train loss:0.019799849177347447\n",
      "train loss:0.019226555117418352\n",
      "train loss:0.011039985362229056\n",
      "train loss:0.03171195992175553\n",
      "train loss:0.004860212252105691\n",
      "train loss:0.00491954885206889\n",
      "train loss:0.01381053812075082\n",
      "train loss:0.013655333907185119\n",
      "train loss:0.010820580449744493\n",
      "train loss:0.002230858604765017\n",
      "train loss:0.07459902710563414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015848093152194234\n",
      "train loss:0.011338646676761124\n",
      "train loss:0.005290350450927397\n",
      "train loss:0.019750471456149134\n",
      "train loss:0.00760013677684943\n",
      "train loss:0.013095089164583068\n",
      "train loss:0.004923226136165197\n",
      "train loss:0.013729624359862087\n",
      "train loss:0.006621974194062127\n",
      "train loss:0.004046313181268101\n",
      "train loss:0.014121289142335583\n",
      "train loss:0.0072530332612316326\n",
      "train loss:0.003344073166993821\n",
      "train loss:0.013808212780749276\n",
      "train loss:0.00825547649819967\n",
      "train loss:0.01300091988167175\n",
      "train loss:0.015250832303460676\n",
      "train loss:0.014581294444259646\n",
      "train loss:0.010110151247366434\n",
      "train loss:0.05073408819911845\n",
      "train loss:0.007397732929476621\n",
      "train loss:0.013436087618940457\n",
      "train loss:0.03375131774952934\n",
      "train loss:0.005763301240266314\n",
      "train loss:0.004711650017260327\n",
      "train loss:0.01673483135567285\n",
      "train loss:0.020408618580558865\n",
      "train loss:0.007526104343658277\n",
      "train loss:0.010911806889622804\n",
      "train loss:0.02054395430193667\n",
      "train loss:0.00591919993066421\n",
      "train loss:0.0010850484819795512\n",
      "train loss:0.016230517704926246\n",
      "train loss:0.004481706665997438\n",
      "train loss:0.06577977160948642\n",
      "train loss:0.005691525267010709\n",
      "train loss:0.03398630234069678\n",
      "train loss:0.0266902173951314\n",
      "train loss:0.02910753282090231\n",
      "train loss:0.00519916298483315\n",
      "train loss:0.04300335604346344\n",
      "train loss:0.0036951725284567346\n",
      "train loss:0.020622678682392422\n",
      "train loss:0.09029655905532766\n",
      "train loss:0.0062902468359398965\n",
      "train loss:0.020632159177605046\n",
      "train loss:0.004170135165069124\n",
      "train loss:0.017034236727069742\n",
      "train loss:0.007748590046899029\n",
      "train loss:0.01590150335807394\n",
      "train loss:0.05428510906682135\n",
      "train loss:0.006485800720963041\n",
      "train loss:0.006260891900986476\n",
      "train loss:0.027078111558819614\n",
      "train loss:0.003466833366041443\n",
      "train loss:0.0038399970144031414\n",
      "train loss:0.0028156400324267656\n",
      "train loss:0.02801967150988451\n",
      "train loss:0.006730668268032529\n",
      "train loss:0.09612419242040515\n",
      "train loss:0.01156391343718948\n",
      "train loss:0.021945380394838634\n",
      "train loss:0.012846160656406758\n",
      "train loss:0.008477141648962759\n",
      "train loss:0.00678939911610224\n",
      "train loss:0.005894724852877382\n",
      "train loss:0.010469020751260145\n",
      "train loss:0.003601931357323776\n",
      "train loss:0.010111677081605127\n",
      "train loss:0.019565720285251692\n",
      "train loss:0.05667367684747182\n",
      "train loss:0.00581430792527022\n",
      "train loss:0.014300535529334944\n",
      "train loss:0.010591702941761538\n",
      "train loss:0.006542329650834149\n",
      "train loss:0.05697590169973351\n",
      "train loss:0.04120735018222887\n",
      "train loss:0.004264043777896915\n",
      "train loss:0.007806290564289827\n",
      "train loss:0.02780141890973171\n",
      "train loss:0.015905556155136395\n",
      "train loss:0.056661262942721224\n",
      "train loss:0.012631854533307956\n",
      "train loss:0.007535199041549192\n",
      "train loss:0.01121598675707504\n",
      "train loss:0.009793508234764037\n",
      "train loss:0.00902829477872991\n",
      "train loss:0.07500373742555363\n",
      "train loss:0.03058338447363214\n",
      "train loss:0.0061500581061411565\n",
      "train loss:0.024882065488549543\n",
      "train loss:0.008772144848215953\n",
      "train loss:0.016353863546534883\n",
      "train loss:0.015056758596680004\n",
      "train loss:0.005062681230048439\n",
      "train loss:0.00969947255000147\n",
      "train loss:0.010170562302626867\n",
      "train loss:0.028338514876390716\n",
      "train loss:0.02700630643487748\n",
      "train loss:0.010487168509366524\n",
      "train loss:0.04758218956533045\n",
      "train loss:0.028396766898812827\n",
      "train loss:0.0062333881943542925\n",
      "train loss:0.018106030089889907\n",
      "train loss:0.0830700602586429\n",
      "train loss:0.016667227376508446\n",
      "train loss:0.03141314712928879\n",
      "train loss:0.022100951952272\n",
      "train loss:0.0027415535290054287\n",
      "train loss:0.020960423280743802\n",
      "train loss:0.007095778519715969\n",
      "train loss:0.013461245884531924\n",
      "train loss:0.03222172947590305\n",
      "train loss:0.0038264747799339597\n",
      "train loss:0.015170137295458628\n",
      "train loss:0.012128435714750998\n",
      "train loss:0.014655900110946975\n",
      "train loss:0.03849209879792754\n",
      "train loss:0.005959438662258143\n",
      "train loss:0.031860433925949144\n",
      "train loss:0.00896120353692313\n",
      "train loss:0.014620661806228216\n",
      "train loss:0.01085586939392247\n",
      "train loss:0.005602501430997049\n",
      "train loss:0.0032479948150387888\n",
      "train loss:0.016258187402856335\n",
      "train loss:0.012579657747508483\n",
      "train loss:0.026300164263705645\n",
      "train loss:0.019623602517490544\n",
      "train loss:0.006852418818444018\n",
      "train loss:0.005352497559189662\n",
      "train loss:0.008097575963949928\n",
      "train loss:0.0009250861784307287\n",
      "train loss:0.0052990437900431505\n",
      "train loss:0.006040625228639321\n",
      "train loss:0.004632661126134523\n",
      "train loss:0.0065840330401399335\n",
      "train loss:0.00543844707212463\n",
      "train loss:0.02997458062639408\n",
      "train loss:0.016162553271293876\n",
      "train loss:0.03443016394276291\n",
      "train loss:0.04527317446395136\n",
      "train loss:0.02520824586821635\n",
      "train loss:0.005799812066527768\n",
      "train loss:0.029704901768526634\n",
      "train loss:0.011220717423874683\n",
      "train loss:0.005177894926880084\n",
      "train loss:0.006255083183595597\n",
      "train loss:0.048230388759101774\n",
      "train loss:0.023850016999429235\n",
      "train loss:0.010292185351117795\n",
      "train loss:0.05268395484670726\n",
      "train loss:0.01686148649749178\n",
      "train loss:0.0036767596917494138\n",
      "train loss:0.01288839132828294\n",
      "train loss:0.010752430686962362\n",
      "train loss:0.006326634693759816\n",
      "train loss:0.021420125581031315\n",
      "train loss:0.04867995199376906\n",
      "train loss:0.040328098672852794\n",
      "train loss:0.015111266871547924\n",
      "train loss:0.06463059825984309\n",
      "train loss:0.00825655309005979\n",
      "train loss:0.007295171242870063\n",
      "train loss:0.0029966907250636664\n",
      "train loss:0.008008654631881907\n",
      "train loss:0.02784171973671877\n",
      "train loss:0.015576553694580544\n",
      "train loss:0.030368375935685202\n",
      "train loss:0.01103882156678592\n",
      "train loss:0.012973058572922405\n",
      "train loss:0.008976745226912936\n",
      "train loss:0.0052469094183204175\n",
      "train loss:0.018254088441002552\n",
      "train loss:0.005761542498174264\n",
      "train loss:0.013552260793938889\n",
      "train loss:0.009706221041698963\n",
      "train loss:0.010234016394082023\n",
      "train loss:0.018358047094907314\n",
      "train loss:0.005484888317708342\n",
      "train loss:0.028898483751360404\n",
      "train loss:0.007542246246179447\n",
      "train loss:0.03563401374343254\n",
      "train loss:0.08753391300669933\n",
      "train loss:0.01974858371765294\n",
      "train loss:0.011261467099481302\n",
      "train loss:0.015276874929953221\n",
      "train loss:0.010362596266636596\n",
      "train loss:0.017265607717106703\n",
      "train loss:0.0036497844917365973\n",
      "train loss:0.0226151120905641\n",
      "train loss:0.006761983716312651\n",
      "train loss:0.002226308258106364\n",
      "train loss:0.012588239809080288\n",
      "train loss:0.008997579480479417\n",
      "train loss:0.011939073482518223\n",
      "train loss:0.008465863595126782\n",
      "train loss:0.005033779904199549\n",
      "train loss:0.01744639538871621\n",
      "train loss:0.0057184640245892294\n",
      "train loss:0.006113560088397142\n",
      "train loss:0.015403487468923189\n",
      "train loss:0.00405063704624038\n",
      "train loss:0.0031805717642399505\n",
      "train loss:0.0034971864575761248\n",
      "train loss:0.005884796366437225\n",
      "train loss:0.013400861227380196\n",
      "train loss:0.028444684276546645\n",
      "train loss:0.013054049700161226\n",
      "train loss:0.016134540039866155\n",
      "train loss:0.00463517217002399\n",
      "train loss:0.018819466564145675\n",
      "train loss:0.020334573595081316\n",
      "train loss:0.018153838853877835\n",
      "train loss:0.011060712579388853\n",
      "train loss:0.003205458602445907\n",
      "train loss:0.04823126256191837\n",
      "train loss:0.011429040876766107\n",
      "train loss:0.01048235453483547\n",
      "train loss:0.009527914204528172\n",
      "train loss:0.03484255843478962\n",
      "train loss:0.03924337498206615\n",
      "train loss:0.0005050157069727811\n",
      "train loss:0.01059044675667611\n",
      "train loss:0.01960791828798945\n",
      "train loss:0.001442984580124342\n",
      "train loss:0.0037395580714116843\n",
      "train loss:0.010563784771254154\n",
      "train loss:0.010039609356809647\n",
      "train loss:0.008091797955385956\n",
      "train loss:0.013433455914965732\n",
      "train loss:0.012005944083319325\n",
      "train loss:0.0022063545799681605\n",
      "train loss:0.010078049457001222\n",
      "train loss:0.005470072734301897\n",
      "train loss:0.0032049635298828506\n",
      "train loss:0.0016560623288978892\n",
      "train loss:0.023318610570096432\n",
      "train loss:0.0034643435263114635\n",
      "train loss:0.03695850999968846\n",
      "train loss:0.03254438293256368\n",
      "train loss:0.0034144654325923285\n",
      "train loss:0.01268471704336204\n",
      "train loss:0.008760043250091715\n",
      "train loss:0.0030385211228521848\n",
      "train loss:0.0254701315099613\n",
      "train loss:0.016482664129887824\n",
      "train loss:0.017609503383116117\n",
      "train loss:0.003996029985854722\n",
      "train loss:0.03747733842402586\n",
      "train loss:0.016271918877832494\n",
      "train loss:0.019662350631240416\n",
      "train loss:0.013269258886658739\n",
      "train loss:0.001518721085209814\n",
      "train loss:0.005959600594721682\n",
      "train loss:0.002092779710399695\n",
      "train loss:0.0028334672394909333\n",
      "train loss:0.004388666383010642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02034903915872915\n",
      "train loss:0.0273282077651619\n",
      "train loss:0.010359865923902485\n",
      "=== epoch:8, train acc:0.989, test acc:0.983 ===\n",
      "train loss:0.005050638980393729\n",
      "train loss:0.005906948436896224\n",
      "train loss:0.02657722504033326\n",
      "train loss:0.002230008930209548\n",
      "train loss:0.0053270644546190024\n",
      "train loss:0.03798089133244204\n",
      "train loss:0.03174067640309788\n",
      "train loss:0.004220561481181334\n",
      "train loss:0.05628188477255722\n",
      "train loss:0.030042802810266597\n",
      "train loss:0.03343046293926911\n",
      "train loss:0.0038461837205293475\n",
      "train loss:0.01217654481911458\n",
      "train loss:0.037144265286874686\n",
      "train loss:0.023150531265827695\n",
      "train loss:0.004957220024299212\n",
      "train loss:0.006196236687032959\n",
      "train loss:0.005238505998642045\n",
      "train loss:0.01317258049309195\n",
      "train loss:0.017429226085376025\n",
      "train loss:0.039121984999600616\n",
      "train loss:0.04290419540335432\n",
      "train loss:0.04049063721075586\n",
      "train loss:0.013927432584258517\n",
      "train loss:0.005486870440940896\n",
      "train loss:0.02630786904401504\n",
      "train loss:0.030231961237808427\n",
      "train loss:0.03842837779378192\n",
      "train loss:0.00700269764591307\n",
      "train loss:0.007918699338361266\n",
      "train loss:0.0034749746716232223\n",
      "train loss:0.02165548522813562\n",
      "train loss:0.007326597165605817\n",
      "train loss:0.006413676298529937\n",
      "train loss:0.01348617561549612\n",
      "train loss:0.00433071617313895\n",
      "train loss:0.012409642325841255\n",
      "train loss:0.0073362975278398026\n",
      "train loss:0.03972168368363774\n",
      "train loss:0.039251653050750915\n",
      "train loss:0.005776342688221961\n",
      "train loss:0.03596990417209414\n",
      "train loss:0.026435560053353183\n",
      "train loss:0.011223557809244803\n",
      "train loss:0.0028852560903024206\n",
      "train loss:0.016122483397454125\n",
      "train loss:0.0018561129473201666\n",
      "train loss:0.0057535339249892145\n",
      "train loss:0.009361069862628784\n",
      "train loss:0.004028548034673446\n",
      "train loss:0.007502530854748183\n",
      "train loss:0.009392372349836165\n",
      "train loss:0.01176313721144228\n",
      "train loss:0.009929802200434719\n",
      "train loss:0.028679640272976693\n",
      "train loss:0.002820931271769637\n",
      "train loss:0.02501093518428716\n",
      "train loss:0.014440785777777498\n",
      "train loss:0.02729377892624437\n",
      "train loss:0.010588741214095114\n",
      "train loss:0.07258945503111265\n",
      "train loss:0.013305845250081242\n",
      "train loss:0.010045055759357768\n",
      "train loss:0.005596351434947137\n",
      "train loss:0.10512828103401818\n",
      "train loss:0.0078107047858217635\n",
      "train loss:0.01108345406714441\n",
      "train loss:0.011334767665104446\n",
      "train loss:0.006177503774899835\n",
      "train loss:0.005635690027292706\n",
      "train loss:0.03310718056812182\n",
      "train loss:0.022197137013068483\n",
      "train loss:0.013372057588583581\n",
      "train loss:0.03943962784449026\n",
      "train loss:0.006202040361103527\n",
      "train loss:0.022457749147821292\n",
      "train loss:0.014416514736079244\n",
      "train loss:0.011749830957640794\n",
      "train loss:0.0077715125053298495\n",
      "train loss:0.009581729849100279\n",
      "train loss:0.003463370372016521\n",
      "train loss:0.0072261488198232735\n",
      "train loss:0.008084156214522058\n",
      "train loss:0.035495881602535626\n",
      "train loss:0.011580367193399842\n",
      "train loss:0.0032643767367370787\n",
      "train loss:0.006838437577196044\n",
      "train loss:0.01305684723225109\n",
      "train loss:0.009525972249906532\n",
      "train loss:0.02169742640967144\n",
      "train loss:0.016896922541982724\n",
      "train loss:0.02789134670545611\n",
      "train loss:0.0044814940126178485\n",
      "train loss:0.0300551545407709\n",
      "train loss:0.03438770476714134\n",
      "train loss:0.008169937851717877\n",
      "train loss:0.022856348555306417\n",
      "train loss:0.004090046052559606\n",
      "train loss:0.007251702325068907\n",
      "train loss:0.013184354469738351\n",
      "train loss:0.008593584304909105\n",
      "train loss:0.016805804617358852\n",
      "train loss:0.003596197543540185\n",
      "train loss:0.0025932911505385636\n",
      "train loss:0.03284948926876639\n",
      "train loss:0.00222052313906341\n",
      "train loss:0.014919135279385947\n",
      "train loss:0.00423444946933835\n",
      "train loss:0.00834477026972131\n",
      "train loss:0.004947336493885583\n",
      "train loss:0.00697545093377883\n",
      "train loss:0.006917875268607505\n",
      "train loss:0.013076953212653722\n",
      "train loss:0.0020928763796278756\n",
      "train loss:0.023395661414644633\n",
      "train loss:0.007324896832850315\n",
      "train loss:0.005461446483347453\n",
      "train loss:0.0024424250355981596\n",
      "train loss:0.021327734159213182\n",
      "train loss:0.014301536589677087\n",
      "train loss:0.017635856880058844\n",
      "train loss:0.005614914094234421\n",
      "train loss:0.016107344111475595\n",
      "train loss:0.0057046960589735764\n",
      "train loss:0.008849340386308947\n",
      "train loss:0.05580384877808433\n",
      "train loss:0.0017760584296295436\n",
      "train loss:0.0023770376765189453\n",
      "train loss:0.0022142433515619157\n",
      "train loss:0.0034403620372263507\n",
      "train loss:0.01675188941194811\n",
      "train loss:0.00574274551522689\n",
      "train loss:0.008310556451021965\n",
      "train loss:0.0038538457438958185\n",
      "train loss:0.005418109687712731\n",
      "train loss:0.07599542480724558\n",
      "train loss:0.008504167000650613\n",
      "train loss:0.015689261678192602\n",
      "train loss:0.017890162306724085\n",
      "train loss:0.008207856323844916\n",
      "train loss:0.012079359654985472\n",
      "train loss:0.003820026653285327\n",
      "train loss:0.06704767859467936\n",
      "train loss:0.020761443778868797\n",
      "train loss:0.027954190553527436\n",
      "train loss:0.013229154349781811\n",
      "train loss:0.03810168463295274\n",
      "train loss:0.0021033132917832216\n",
      "train loss:0.002310655484156046\n",
      "train loss:0.0082502081362253\n",
      "train loss:0.004687174661497227\n",
      "train loss:0.004184626592928815\n",
      "train loss:0.022938933748740346\n",
      "train loss:0.010463940040651454\n",
      "train loss:0.005481793988335637\n",
      "train loss:0.029443058532893945\n",
      "train loss:0.01520524601935367\n",
      "train loss:0.006094062182649458\n",
      "train loss:0.004972284260728942\n",
      "train loss:0.00045852975283329267\n",
      "train loss:0.03834961921164122\n",
      "train loss:0.0037667063180616468\n",
      "train loss:0.011349806679611411\n",
      "train loss:0.005541226217545667\n",
      "train loss:0.027686017854058057\n",
      "train loss:0.010615381357349579\n",
      "train loss:0.008265590812773213\n",
      "train loss:0.0201596365648027\n",
      "train loss:0.0062762167490800795\n",
      "train loss:0.00566990762140882\n",
      "train loss:0.006409880738210177\n",
      "train loss:0.01562898141180538\n",
      "train loss:0.013980255593556212\n",
      "train loss:0.002397243173104828\n",
      "train loss:0.011436964815292296\n",
      "train loss:0.01496393574497517\n",
      "train loss:0.0235127964079613\n",
      "train loss:0.0190424874937774\n",
      "train loss:0.0031692023750662774\n",
      "train loss:0.022422136077520766\n",
      "train loss:0.015661812048089533\n",
      "train loss:0.008545177542856658\n",
      "train loss:0.01334725664481732\n",
      "train loss:0.009890746792215776\n",
      "train loss:0.004547380478639899\n",
      "train loss:0.05616209245294911\n",
      "train loss:0.001027893411307218\n",
      "train loss:0.012948441671251002\n",
      "train loss:0.010385347079904962\n",
      "train loss:0.0038339648279656596\n",
      "train loss:0.026329937195892262\n",
      "train loss:0.007817569849834942\n",
      "train loss:0.0030037755909478065\n",
      "train loss:0.023374034886787787\n",
      "train loss:0.03086160906659449\n",
      "train loss:0.009287298258892645\n",
      "train loss:0.028592009298787878\n",
      "train loss:0.011555367354727302\n",
      "train loss:0.0022892606343143645\n",
      "train loss:0.0102262431882497\n",
      "train loss:0.008472578800940413\n",
      "train loss:0.0044114160837396285\n",
      "train loss:0.013138715152389966\n",
      "train loss:0.001518897730391086\n",
      "train loss:0.020939059880944577\n",
      "train loss:0.031606343021653355\n",
      "train loss:0.037636972169183804\n",
      "train loss:0.003146789644984113\n",
      "train loss:0.007887356530968379\n",
      "train loss:0.012879456353342889\n",
      "train loss:0.008875975389451278\n",
      "train loss:0.003962524813554454\n",
      "train loss:0.017701653282813958\n",
      "train loss:0.017098561541689455\n",
      "train loss:0.013532770118662867\n",
      "train loss:0.008762527821398297\n",
      "train loss:0.0037557431407642355\n",
      "train loss:0.018476001745216603\n",
      "train loss:0.00509442717704339\n",
      "train loss:0.0045289531257385815\n",
      "train loss:0.009359242469904133\n",
      "train loss:0.014129415901773985\n",
      "train loss:0.005895922969516735\n",
      "train loss:0.022465480172628168\n",
      "train loss:0.012778102867485472\n",
      "train loss:0.0065633853135217265\n",
      "train loss:0.00519704749265005\n",
      "train loss:0.027832856666574736\n",
      "train loss:0.003361719749175153\n",
      "train loss:0.004707246240546748\n",
      "train loss:0.007508826279229474\n",
      "train loss:0.0009750603951924971\n",
      "train loss:0.03409375637455554\n",
      "train loss:0.011663947088640856\n",
      "train loss:0.027107236923825488\n",
      "train loss:0.00660913917550253\n",
      "train loss:0.010611619084074684\n",
      "train loss:0.007782648610305227\n",
      "train loss:0.008948737212172653\n",
      "train loss:0.026462531306749408\n",
      "train loss:0.0030324158209966705\n",
      "train loss:0.020459941524393326\n",
      "train loss:0.010222077328942192\n",
      "train loss:0.0030998138478931766\n",
      "train loss:0.0035212620520810073\n",
      "train loss:0.0066336315765653684\n",
      "train loss:0.018349243861928308\n",
      "train loss:0.011675842519833493\n",
      "train loss:0.011410403844713144\n",
      "train loss:0.009701619431964058\n",
      "train loss:0.01015139348377635\n",
      "train loss:0.007841807485104574\n",
      "train loss:0.023970142128458695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0029348766878102457\n",
      "train loss:0.01578041369986864\n",
      "train loss:0.005372105519972744\n",
      "train loss:0.02901202870659632\n",
      "train loss:0.028396825381697157\n",
      "train loss:0.055683023302185164\n",
      "train loss:0.0050595187796207315\n",
      "train loss:0.01664608862658633\n",
      "train loss:0.03588673167358069\n",
      "train loss:0.05220299649572416\n",
      "train loss:0.0046459415851224425\n",
      "train loss:0.012225616596032543\n",
      "train loss:0.010830025210797343\n",
      "train loss:0.01903259626016084\n",
      "train loss:0.03232852766991968\n",
      "train loss:0.006343963714781694\n",
      "train loss:0.06333148834842259\n",
      "train loss:0.005976720757566971\n",
      "train loss:0.019671650026598427\n",
      "train loss:0.010715581779755772\n",
      "train loss:0.013844731106807054\n",
      "train loss:0.04492726700949931\n",
      "train loss:0.021037251073729425\n",
      "train loss:0.03274521738597989\n",
      "train loss:0.005839107797718956\n",
      "train loss:0.003503199809138769\n",
      "train loss:0.004668928482222047\n",
      "train loss:0.014416553441004643\n",
      "train loss:0.005586732707704203\n",
      "train loss:0.008268389817791938\n",
      "train loss:0.005059148519174871\n",
      "train loss:0.019277752863584185\n",
      "train loss:0.01400800073144942\n",
      "train loss:0.021456486281515398\n",
      "train loss:0.004412057762537862\n",
      "train loss:0.006519363586568975\n",
      "train loss:0.03635602740643027\n",
      "train loss:0.011632561129369936\n",
      "train loss:0.009964803236774566\n",
      "train loss:0.0063588710586801375\n",
      "train loss:0.0020943456644157534\n",
      "train loss:0.0050357066617464415\n",
      "train loss:0.009815175252230532\n",
      "train loss:0.007241094056141912\n",
      "train loss:0.020977060760918088\n",
      "train loss:0.008833713211389036\n",
      "train loss:0.02039052017640517\n",
      "train loss:0.005337539955640673\n",
      "train loss:0.012261374511371919\n",
      "train loss:0.003997134937644705\n",
      "train loss:0.033082688360681\n",
      "train loss:0.004063539941518076\n",
      "train loss:0.023784791042234757\n",
      "train loss:0.032014543596098295\n",
      "train loss:0.013510824763944764\n",
      "train loss:0.011144906764135099\n",
      "train loss:0.008271848989778409\n",
      "train loss:0.023469711506843818\n",
      "train loss:0.004057959300248633\n",
      "train loss:0.014288879577603397\n",
      "train loss:0.0013340049447469798\n",
      "train loss:0.019951011359483514\n",
      "train loss:0.00969372832406797\n",
      "train loss:0.0049237329813511645\n",
      "train loss:0.015298481555108078\n",
      "train loss:0.0065938446333479415\n",
      "train loss:0.006856686663948655\n",
      "train loss:0.008264958135123825\n",
      "train loss:0.014703027752144495\n",
      "train loss:0.01692798264308478\n",
      "train loss:0.01558257361342264\n",
      "train loss:0.012113155151737578\n",
      "train loss:0.008503318501820605\n",
      "train loss:0.002931154234224313\n",
      "train loss:0.003969722085646771\n",
      "train loss:0.0214325197306556\n",
      "train loss:0.008384337065585681\n",
      "train loss:0.021875444599084116\n",
      "train loss:0.01804420726748806\n",
      "train loss:0.011552526847327873\n",
      "train loss:0.042129482974471014\n",
      "train loss:0.05041697287614827\n",
      "train loss:0.006723005831211874\n",
      "train loss:0.005116073976653305\n",
      "train loss:0.006210841989877683\n",
      "train loss:0.014580773619919732\n",
      "train loss:0.012114218866532179\n",
      "train loss:0.00506280974620553\n",
      "train loss:0.002224343191114778\n",
      "train loss:0.009874674728451088\n",
      "train loss:0.014810743583214249\n",
      "train loss:0.044202450279788925\n",
      "train loss:0.009252063595219833\n",
      "train loss:0.009158703014286446\n",
      "train loss:0.005657958778171445\n",
      "train loss:0.031955353033008664\n",
      "train loss:0.00810579854218479\n",
      "train loss:0.00515842767737992\n",
      "train loss:0.0063461025824045935\n",
      "train loss:0.010618236415054383\n",
      "train loss:0.0212973475314429\n",
      "train loss:0.022469692397369182\n",
      "train loss:0.0055801038021275114\n",
      "train loss:0.022508329104644304\n",
      "train loss:0.0037872510249964157\n",
      "train loss:0.005736784630842092\n",
      "train loss:0.0012815203441140174\n",
      "train loss:0.0082402412245691\n",
      "train loss:0.017892267467259897\n",
      "train loss:0.007144505869946235\n",
      "train loss:0.011513383059918413\n",
      "train loss:0.01201371309159707\n",
      "train loss:0.008512008471927384\n",
      "train loss:0.003986143621790154\n",
      "train loss:0.012591175169052726\n",
      "train loss:0.03844425200423567\n",
      "train loss:0.006454592755729806\n",
      "train loss:0.0016807800793143027\n",
      "train loss:0.015449802769316701\n",
      "train loss:0.009026618628678554\n",
      "train loss:0.02207655406335068\n",
      "train loss:0.003294759469516602\n",
      "train loss:0.007841157880934832\n",
      "train loss:0.005026543209618345\n",
      "train loss:0.01483147166638648\n",
      "train loss:0.0046532418996164775\n",
      "train loss:0.033866998529968835\n",
      "train loss:0.00525131721423221\n",
      "train loss:0.0034671171826751246\n",
      "train loss:0.006880066234444655\n",
      "train loss:0.016456277763522778\n",
      "train loss:0.006512074493662129\n",
      "train loss:0.03680771769445233\n",
      "train loss:0.013132899714535386\n",
      "train loss:0.008285127795260578\n",
      "train loss:0.03636269791842958\n",
      "train loss:0.008892890029480589\n",
      "train loss:0.013861033211662604\n",
      "train loss:0.011922619524232765\n",
      "train loss:0.015831822637160226\n",
      "train loss:0.0073717257615671695\n",
      "train loss:0.01683672825556446\n",
      "train loss:0.03531814309781432\n",
      "train loss:0.008558357612812888\n",
      "train loss:0.0019711629690598227\n",
      "train loss:0.005337281922833367\n",
      "train loss:0.003914422731955865\n",
      "train loss:0.013819638307230825\n",
      "train loss:0.09035537664539543\n",
      "train loss:0.006353707984530328\n",
      "train loss:0.04464842379825499\n",
      "train loss:0.006120270195196013\n",
      "train loss:0.01987512985161125\n",
      "train loss:0.008119889443723804\n",
      "train loss:0.011335181130613981\n",
      "train loss:0.003778420631654943\n",
      "train loss:0.005607230554679336\n",
      "train loss:0.006636540884349431\n",
      "train loss:0.01388377453414254\n",
      "train loss:0.007575316573485913\n",
      "train loss:0.009261050331391458\n",
      "train loss:0.04517154180833523\n",
      "train loss:0.013419613906456367\n",
      "train loss:0.0038381078063536183\n",
      "train loss:0.012033223974714345\n",
      "train loss:0.006265815604462806\n",
      "train loss:0.011432377136567083\n",
      "train loss:0.008438081783554228\n",
      "train loss:0.004083295821954932\n",
      "train loss:0.012390078827323157\n",
      "train loss:0.044863226683102705\n",
      "train loss:0.004796721034281295\n",
      "train loss:0.015764644793334347\n",
      "train loss:0.0012868691422823668\n",
      "train loss:0.0058677908375567404\n",
      "train loss:0.013140645005216429\n",
      "train loss:0.008163999866771417\n",
      "train loss:0.009153161702212474\n",
      "train loss:0.00919177318828492\n",
      "train loss:0.015416507446817463\n",
      "train loss:0.0044851341253188595\n",
      "train loss:0.0033886124977896876\n",
      "train loss:0.008060658854550245\n",
      "train loss:0.0678483435034428\n",
      "train loss:0.010365351127662287\n",
      "train loss:0.0029753735065900485\n",
      "train loss:0.004422982638496405\n",
      "train loss:0.011679742888727133\n",
      "train loss:0.018499801718814\n",
      "train loss:0.021653912769837254\n",
      "train loss:0.02446274094693953\n",
      "train loss:0.005884699280420369\n",
      "train loss:0.0015291564827524878\n",
      "train loss:0.006970648284150785\n",
      "train loss:0.014106220285980783\n",
      "train loss:0.01489083926113484\n",
      "train loss:0.010156158660982509\n",
      "train loss:0.006698902656039496\n",
      "train loss:0.004525740909993185\n",
      "train loss:0.004224339851898894\n",
      "train loss:0.0050625247364305855\n",
      "train loss:0.007253315416659392\n",
      "train loss:0.0022193689630246455\n",
      "train loss:0.004243641648304254\n",
      "train loss:0.005379825115264208\n",
      "train loss:0.0022433221651040384\n",
      "train loss:0.022604195698771857\n",
      "train loss:0.006436774189922521\n",
      "train loss:0.006540928126734086\n",
      "train loss:0.008959133492952433\n",
      "train loss:0.01501119772267866\n",
      "train loss:0.005002300617695639\n",
      "train loss:0.01403510641292258\n",
      "train loss:0.004237916317222281\n",
      "train loss:0.01856161947493201\n",
      "train loss:0.015132863577927416\n",
      "train loss:0.008886040018767116\n",
      "train loss:0.024719187907641285\n",
      "train loss:0.010622430016554198\n",
      "train loss:0.006483338917843826\n",
      "train loss:0.012420434072617757\n",
      "train loss:0.0029652719690989116\n",
      "train loss:0.005299761717709231\n",
      "train loss:0.0024027147816164025\n",
      "train loss:0.02792794247780353\n",
      "train loss:0.04562928180619071\n",
      "train loss:0.006830772210175787\n",
      "train loss:0.008271925763286237\n",
      "train loss:0.050113298423710165\n",
      "train loss:0.019328968890298785\n",
      "train loss:0.012853079259576546\n",
      "train loss:0.006142365848423513\n",
      "train loss:0.012773471830307024\n",
      "train loss:0.011015891845086086\n",
      "train loss:0.013042912409415025\n",
      "train loss:0.01204250843668841\n",
      "train loss:0.0012750936449076808\n",
      "train loss:0.023188400355539165\n",
      "train loss:0.006961686872667069\n",
      "train loss:0.025265002487552618\n",
      "train loss:0.003862183161114605\n",
      "train loss:0.00855972799300461\n",
      "train loss:0.000654318809329126\n",
      "train loss:0.004855100415662231\n",
      "train loss:0.012185929329163627\n",
      "train loss:0.006362117354019916\n",
      "train loss:0.002500399490431562\n",
      "train loss:0.013968879622668311\n",
      "train loss:0.005925212025709673\n",
      "train loss:0.01805165519106537\n",
      "train loss:0.0010274247475416261\n",
      "train loss:0.007654444913417541\n",
      "train loss:0.007522359968748838\n",
      "train loss:0.005923291171382703\n",
      "train loss:0.003498677450760731\n",
      "train loss:0.015727711353209228\n",
      "train loss:0.0034455125423113104\n",
      "train loss:0.00704546647819555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010904999485374127\n",
      "train loss:0.005146694193293461\n",
      "train loss:0.011115112417524444\n",
      "train loss:0.0018533592473205871\n",
      "train loss:0.020393450360331467\n",
      "train loss:0.001246846400673823\n",
      "train loss:0.0015174221955844393\n",
      "train loss:0.02391388849270502\n",
      "train loss:0.013203457187167896\n",
      "train loss:0.015118004936151903\n",
      "train loss:0.01666622708291763\n",
      "train loss:0.009426293644792695\n",
      "train loss:0.0022963819264687256\n",
      "train loss:0.003535108496144497\n",
      "train loss:0.011047960605006022\n",
      "train loss:0.03830558037716073\n",
      "train loss:0.008082563984025667\n",
      "train loss:0.0028334385312658245\n",
      "train loss:0.01935844601373968\n",
      "train loss:0.0033831990705014926\n",
      "train loss:0.00929482262841792\n",
      "train loss:0.013213369282463472\n",
      "train loss:0.006979226130844891\n",
      "train loss:0.010277138417304564\n",
      "train loss:0.003665709451933971\n",
      "train loss:0.014195359303281765\n",
      "train loss:0.001731957408089809\n",
      "train loss:0.003947470898003696\n",
      "train loss:0.012710634917161066\n",
      "train loss:0.002561486707880125\n",
      "train loss:0.009826333737800532\n",
      "train loss:0.009633044585804622\n",
      "train loss:0.0031216169987916837\n",
      "train loss:0.01528198006761526\n",
      "train loss:0.0051894275953609115\n",
      "train loss:0.0009752634645527877\n",
      "train loss:0.004165336731508885\n",
      "train loss:0.007188596858291921\n",
      "train loss:0.005231358531925679\n",
      "train loss:0.000761343023396764\n",
      "train loss:0.00657050289981903\n",
      "train loss:0.006969535095531939\n",
      "train loss:0.02887673069329092\n",
      "train loss:0.002938950903110822\n",
      "train loss:0.004959727955439383\n",
      "train loss:0.002273123260594805\n",
      "train loss:0.010738564280784697\n",
      "train loss:0.0018056456539856183\n",
      "train loss:0.005999069872237166\n",
      "train loss:0.008125789738212662\n",
      "train loss:0.014991962716217779\n",
      "train loss:0.003698571085811383\n",
      "train loss:0.00836142690498762\n",
      "train loss:0.012178269969602125\n",
      "train loss:0.021806809626947272\n",
      "train loss:0.0021262114978398954\n",
      "train loss:0.007744030016298021\n",
      "train loss:0.016480142233042103\n",
      "train loss:0.00048698535056951835\n",
      "train loss:0.008927594542003868\n",
      "train loss:0.01916171562555082\n",
      "train loss:0.0010380308833093425\n",
      "train loss:0.005663466824652682\n",
      "train loss:0.012078812754586131\n",
      "train loss:0.009850922021212629\n",
      "train loss:0.0039608418203067024\n",
      "train loss:0.0022410690120697255\n",
      "train loss:0.005414741361862972\n",
      "train loss:0.006232923174992883\n",
      "train loss:0.030446750043258225\n",
      "train loss:0.0306652904488895\n",
      "train loss:0.0026174831527287514\n",
      "train loss:0.0024341117188988303\n",
      "train loss:0.002639498480339329\n",
      "train loss:0.0016274242238028117\n",
      "train loss:0.013398297944747652\n",
      "train loss:0.007699320333848183\n",
      "train loss:0.014493875937926526\n",
      "train loss:0.006971987073329196\n",
      "train loss:0.012325305797848816\n",
      "train loss:0.017982019309517795\n",
      "train loss:0.005557729724252418\n",
      "train loss:0.012548993558939682\n",
      "train loss:0.004705055692639254\n",
      "train loss:0.00416159620412992\n",
      "train loss:0.011581507361556524\n",
      "train loss:0.0041046681384068785\n",
      "train loss:0.003576450776396997\n",
      "train loss:0.009222313798699769\n",
      "=== epoch:9, train acc:0.989, test acc:0.984 ===\n",
      "train loss:0.10257385064628821\n",
      "train loss:0.004674479389269728\n",
      "train loss:0.015611453275180948\n",
      "train loss:0.028769046186903822\n",
      "train loss:0.008892144361820575\n",
      "train loss:0.012339557391026093\n",
      "train loss:0.003973799789491851\n",
      "train loss:0.002817599129626416\n",
      "train loss:0.01922588977559435\n",
      "train loss:0.00808398329520521\n",
      "train loss:0.006527110691817848\n",
      "train loss:0.02960986523978829\n",
      "train loss:0.010967489674243831\n",
      "train loss:0.001954671313425871\n",
      "train loss:0.01555119938794556\n",
      "train loss:0.007465340057186276\n",
      "train loss:0.006817345992793663\n",
      "train loss:0.0018222392363898719\n",
      "train loss:0.0032680131188202815\n",
      "train loss:0.028772928976293913\n",
      "train loss:0.0366325801318559\n",
      "train loss:0.0007445068909975637\n",
      "train loss:0.006105542596210265\n",
      "train loss:0.0008907278744879142\n",
      "train loss:0.004643124009357153\n",
      "train loss:0.017679277498380455\n",
      "train loss:0.019018742851100577\n",
      "train loss:0.01049963593311106\n",
      "train loss:0.03158196341019124\n",
      "train loss:0.006071005160450965\n",
      "train loss:0.013536798349997752\n",
      "train loss:0.0674375079226145\n",
      "train loss:0.0021987925279929135\n",
      "train loss:0.007025562716971704\n",
      "train loss:0.006319634581350957\n",
      "train loss:0.011502791021362853\n",
      "train loss:0.007899649755810097\n",
      "train loss:0.04142787524523595\n",
      "train loss:0.022513512510200027\n",
      "train loss:0.005265545001743194\n",
      "train loss:0.007367710386974126\n",
      "train loss:0.0035000566912601443\n",
      "train loss:0.024269345617136534\n",
      "train loss:0.026461133316165918\n",
      "train loss:0.0027756529007357898\n",
      "train loss:0.002946038206302015\n",
      "train loss:0.007978543908465774\n",
      "train loss:0.004794724922911105\n",
      "train loss:0.0016186340977896044\n",
      "train loss:0.004990291612214075\n",
      "train loss:0.01526159118979346\n",
      "train loss:0.0066248666385438195\n",
      "train loss:0.0020203739050640786\n",
      "train loss:0.04614099858415077\n",
      "train loss:0.006874906661736514\n",
      "train loss:0.001505291726031333\n",
      "train loss:0.0033571169975669096\n",
      "train loss:0.01625812538037104\n",
      "train loss:0.027349238481099377\n",
      "train loss:0.004163163538507522\n",
      "train loss:0.013104083208538717\n",
      "train loss:0.002983163495554463\n",
      "train loss:0.007363304393915672\n",
      "train loss:0.007818070684837797\n",
      "train loss:0.014958248908001848\n",
      "train loss:0.0029468853656995993\n",
      "train loss:0.0037612557549999786\n",
      "train loss:0.0053208926635121435\n",
      "train loss:0.05670676432209116\n",
      "train loss:0.010741930893551889\n",
      "train loss:0.011476146705906607\n",
      "train loss:0.008752261244874035\n",
      "train loss:0.008055955109667784\n",
      "train loss:0.002548827850856841\n",
      "train loss:0.003653960682138482\n",
      "train loss:0.0031613178914108053\n",
      "train loss:0.005682592336015432\n",
      "train loss:0.005408443707605633\n",
      "train loss:0.00685158536707471\n",
      "train loss:0.003466319948015356\n",
      "train loss:0.009826896476502912\n",
      "train loss:0.016153184186187733\n",
      "train loss:0.024807677531678948\n",
      "train loss:0.004426398499906348\n",
      "train loss:0.014925954224087148\n",
      "train loss:0.007822833248716566\n",
      "train loss:0.004613856813361571\n",
      "train loss:0.004289550583593322\n",
      "train loss:0.007054016752461431\n",
      "train loss:0.004285438283581837\n",
      "train loss:0.006907694327762738\n",
      "train loss:0.005473571726836848\n",
      "train loss:0.005377986450214628\n",
      "train loss:0.005870344918783013\n",
      "train loss:0.008024512603453675\n",
      "train loss:0.012846965878244942\n",
      "train loss:0.02559454013767213\n",
      "train loss:0.008058824056065873\n",
      "train loss:0.0052386872783733805\n",
      "train loss:0.0017730299386259046\n",
      "train loss:0.019164947224309413\n",
      "train loss:0.015668140920397696\n",
      "train loss:0.00386837067582643\n",
      "train loss:0.007571422376579738\n",
      "train loss:0.005459510798519041\n",
      "train loss:0.03112774225798211\n",
      "train loss:0.007432046869015388\n",
      "train loss:0.0022765433013954557\n",
      "train loss:0.0048379097214322824\n",
      "train loss:0.00514190256545474\n",
      "train loss:0.0033518984141362646\n",
      "train loss:0.0034012642075920254\n",
      "train loss:0.0043333561908162205\n",
      "train loss:0.018518874748740186\n",
      "train loss:0.05887837958284302\n",
      "train loss:0.00036538566893835905\n",
      "train loss:0.008092590852190362\n",
      "train loss:0.012091666654438261\n",
      "train loss:0.002668337918796237\n",
      "train loss:0.08390081832156572\n",
      "train loss:0.00456516962705866\n",
      "train loss:0.06016319727250001\n",
      "train loss:0.0023119570130858747\n",
      "train loss:0.002492392823501841\n",
      "train loss:0.008336889272307562\n",
      "train loss:0.0022403724998731893\n",
      "train loss:0.0018613582926602598\n",
      "train loss:0.002777418085208884\n",
      "train loss:0.011977410900804376\n",
      "train loss:0.0027646752174835926\n",
      "train loss:0.020250029148046314\n",
      "train loss:0.0038151494551660475\n",
      "train loss:0.0035682216416349933\n",
      "train loss:0.004334298789447088\n",
      "train loss:0.007718681183125291\n",
      "train loss:0.036998015447854214\n",
      "train loss:0.007627596701447102\n",
      "train loss:0.007159661327899922\n",
      "train loss:0.008868585649270415\n",
      "train loss:0.0040849595461684455\n",
      "train loss:0.04740443901568507\n",
      "train loss:0.003940020121757063\n",
      "train loss:0.0326375044642694\n",
      "train loss:0.0018069018868973707\n",
      "train loss:0.0012928445484953555\n",
      "train loss:0.0020556579262165503\n",
      "train loss:0.005069460404947526\n",
      "train loss:0.01399364500426455\n",
      "train loss:0.0009109514230401533\n",
      "train loss:0.007200731777748937\n",
      "train loss:0.011226434216194882\n",
      "train loss:0.008876008749514289\n",
      "train loss:0.010881403102289532\n",
      "train loss:0.004589203111678903\n",
      "train loss:0.006835624663629414\n",
      "train loss:0.0020907489016041966\n",
      "train loss:0.006909132124729258\n",
      "train loss:0.0262779036798626\n",
      "train loss:0.006850076975641557\n",
      "train loss:0.00580292328465822\n",
      "train loss:0.007270660233496032\n",
      "train loss:0.0044348725197988275\n",
      "train loss:0.010071939165979628\n",
      "train loss:0.029321621357769518\n",
      "train loss:0.009732837134789401\n",
      "train loss:0.006319131900977205\n",
      "train loss:0.017878954445891868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007170781365772339\n",
      "train loss:0.0010231155339284884\n",
      "train loss:0.006411166294420921\n",
      "train loss:0.005273447818543216\n",
      "train loss:0.015248029232836795\n",
      "train loss:0.011754542111107007\n",
      "train loss:0.0012121305587412532\n",
      "train loss:0.00460385557062864\n",
      "train loss:0.0029122658725356885\n",
      "train loss:0.013990980196766797\n",
      "train loss:0.004689739889194685\n",
      "train loss:0.005422227646164474\n",
      "train loss:0.015743540771556142\n",
      "train loss:0.000883279651420259\n",
      "train loss:0.008374923103496128\n",
      "train loss:0.005286811731416127\n",
      "train loss:0.004640072366904196\n",
      "train loss:0.009597619427507227\n",
      "train loss:0.011615027067973247\n",
      "train loss:0.010775155837072527\n",
      "train loss:0.0054919016657399115\n",
      "train loss:0.016628266706825018\n",
      "train loss:0.0021180743511239985\n",
      "train loss:0.014574066715090235\n",
      "train loss:0.013403381629835993\n",
      "train loss:0.007487826358817613\n",
      "train loss:0.021695759739850985\n",
      "train loss:0.004852285609327874\n",
      "train loss:0.003134207621841412\n",
      "train loss:0.004033480669984692\n",
      "train loss:0.005114976636785179\n",
      "train loss:0.02522650401021741\n",
      "train loss:0.005515467007340466\n",
      "train loss:0.07212731631397801\n",
      "train loss:0.011268962216541119\n",
      "train loss:0.009274640938582612\n",
      "train loss:0.011076276729132339\n",
      "train loss:0.014666179954347802\n",
      "train loss:0.0017226627169168237\n",
      "train loss:0.004458917012464743\n",
      "train loss:0.006289168651313351\n",
      "train loss:0.0008488685434866483\n",
      "train loss:0.014409506804793727\n",
      "train loss:0.009377446308987732\n",
      "train loss:0.003003966353422696\n",
      "train loss:0.0016449918027246055\n",
      "train loss:0.005448565528458637\n",
      "train loss:0.005220809949465098\n",
      "train loss:0.017131365860419755\n",
      "train loss:0.005637667627207899\n",
      "train loss:0.01841488352561592\n",
      "train loss:0.00990907763096966\n",
      "train loss:0.003050124963965334\n",
      "train loss:0.0017155947568445865\n",
      "train loss:0.021572591341249895\n",
      "train loss:0.01303047162762138\n",
      "train loss:0.0016540932142396826\n",
      "train loss:0.001818611157081608\n",
      "train loss:0.0036245162871766483\n",
      "train loss:0.011815564003794353\n",
      "train loss:0.020826340728943266\n",
      "train loss:0.0029115560529461093\n",
      "train loss:0.008422356052337147\n",
      "train loss:0.005694459113530976\n",
      "train loss:0.018001522570085\n",
      "train loss:0.01893545603325375\n",
      "train loss:0.007786878116366742\n",
      "train loss:0.006005678101523537\n",
      "train loss:0.011321473661942447\n",
      "train loss:0.0018915998737583052\n",
      "train loss:0.015061818112230053\n",
      "train loss:0.0038937518259876645\n",
      "train loss:0.0028439697141469716\n",
      "train loss:0.043552565782870506\n",
      "train loss:0.021672190098628717\n",
      "train loss:0.009347732044302877\n",
      "train loss:0.009614605448380782\n",
      "train loss:0.0019603179778244183\n",
      "train loss:0.0003021710323032292\n",
      "train loss:0.010432903606100295\n",
      "train loss:0.013781810207955667\n",
      "train loss:0.004902201188861288\n",
      "train loss:0.021515862560724713\n",
      "train loss:0.0034993480382054486\n",
      "train loss:0.012935369126651126\n",
      "train loss:0.005882408219595967\n",
      "train loss:0.012104382592668264\n",
      "train loss:0.019253854727110675\n",
      "train loss:0.05092737395998655\n",
      "train loss:0.006417584361446697\n",
      "train loss:0.010468151666010412\n",
      "train loss:0.016194052714156238\n",
      "train loss:0.011965040167283917\n",
      "train loss:0.014271552684800222\n",
      "train loss:0.0036044660809986763\n",
      "train loss:0.017428007974044077\n",
      "train loss:0.005800655659562348\n",
      "train loss:0.018697521002831386\n",
      "train loss:0.01227066132789963\n",
      "train loss:0.048721713377200125\n",
      "train loss:0.031053860505454084\n",
      "train loss:0.025405652485304867\n",
      "train loss:0.004970758373816748\n",
      "train loss:0.018191740438064645\n",
      "train loss:0.006215339071178275\n",
      "train loss:0.0024613743468026184\n",
      "train loss:0.011048391655357233\n",
      "train loss:0.0016051435919481874\n",
      "train loss:0.00880068691175388\n",
      "train loss:0.0035561771914567157\n",
      "train loss:0.004263805611810333\n",
      "train loss:0.007807187713853192\n",
      "train loss:0.00743821236932639\n",
      "train loss:0.015341282593990082\n",
      "train loss:0.006506954097914694\n",
      "train loss:0.005223555506518708\n",
      "train loss:0.031000680340991713\n",
      "train loss:0.007480399437595136\n",
      "train loss:0.00688013116770059\n",
      "train loss:0.012843662087018261\n",
      "train loss:0.043330884943728235\n",
      "train loss:0.055261430377059585\n",
      "train loss:0.0013151540259454203\n",
      "train loss:0.012606322750812115\n",
      "train loss:0.09710502275525265\n",
      "train loss:0.0012549263507637748\n",
      "train loss:0.006197138567336965\n",
      "train loss:0.03409475786122193\n",
      "train loss:0.005614493422439169\n",
      "train loss:0.0062129315655107395\n",
      "train loss:0.001494737304497477\n",
      "train loss:0.03327536731863516\n",
      "train loss:0.010902665143590647\n",
      "train loss:0.029209118552516913\n",
      "train loss:0.006796237685020673\n",
      "train loss:0.010424294966400733\n",
      "train loss:0.005121701998714808\n",
      "train loss:0.002099171323683533\n",
      "train loss:0.02534245398790888\n",
      "train loss:0.015372947497752126\n",
      "train loss:0.010589049360680803\n",
      "train loss:0.008423483060907296\n",
      "train loss:0.014185526082272573\n",
      "train loss:0.005506123874919544\n",
      "train loss:0.029552363699637773\n",
      "train loss:0.003932117720961481\n",
      "train loss:0.00432651328701848\n",
      "train loss:0.0011638384778447058\n",
      "train loss:0.0005685040055594067\n",
      "train loss:0.0033304504478867624\n",
      "train loss:0.0032529098925804223\n",
      "train loss:0.005870635898498319\n",
      "train loss:0.03264451476260035\n",
      "train loss:0.0032353982728597756\n",
      "train loss:0.01000751732932584\n",
      "train loss:0.00728649513549669\n",
      "train loss:0.0041668547879417425\n",
      "train loss:0.00150937941088726\n",
      "train loss:0.023389747545284435\n",
      "train loss:0.020090212100091764\n",
      "train loss:0.00496857837594013\n",
      "train loss:0.009834249819402927\n",
      "train loss:0.003757688152509138\n",
      "train loss:0.009677479088561994\n",
      "train loss:0.019840539872813687\n",
      "train loss:0.01076048222067593\n",
      "train loss:0.012675171676945289\n",
      "train loss:0.012266155866461232\n",
      "train loss:0.0007442470116595609\n",
      "train loss:0.0014310339277859563\n",
      "train loss:0.021975015057603464\n",
      "train loss:0.004045745892167289\n",
      "train loss:0.0022674213341311302\n",
      "train loss:0.009536779404288617\n",
      "train loss:0.010600458789290177\n",
      "train loss:0.04592256984068164\n",
      "train loss:0.0028813163198592013\n",
      "train loss:0.005115691071028324\n",
      "train loss:0.008098643467104809\n",
      "train loss:0.003913817001765775\n",
      "train loss:0.015808492302548927\n",
      "train loss:0.0010869125471019696\n",
      "train loss:0.019040283499690107\n",
      "train loss:0.00193266713185083\n",
      "train loss:0.008767790609272814\n",
      "train loss:0.0024384315803730517\n",
      "train loss:0.029999806900003097\n",
      "train loss:0.00468722608279532\n",
      "train loss:0.0016723757124659294\n",
      "train loss:0.0013551973076414404\n",
      "train loss:0.0008256386271590328\n",
      "train loss:0.002524948769929526\n",
      "train loss:0.02855069089842498\n",
      "train loss:0.006037777777714418\n",
      "train loss:0.009625393727254423\n",
      "train loss:0.013604254231803291\n",
      "train loss:0.0059607985519113706\n",
      "train loss:0.002360997854871753\n",
      "train loss:0.003507205774596119\n",
      "train loss:0.004330812334323845\n",
      "train loss:0.011349289567958167\n",
      "train loss:0.0005872817605188619\n",
      "train loss:0.015330816207835605\n",
      "train loss:0.01004706992248481\n",
      "train loss:0.006898952008328154\n",
      "train loss:0.02730239066314474\n",
      "train loss:0.01083724775732048\n",
      "train loss:0.0027803713899396004\n",
      "train loss:0.005504130758906206\n",
      "train loss:0.012958300669436946\n",
      "train loss:0.007396912311373638\n",
      "train loss:0.0003866896421715305\n",
      "train loss:0.006349610506277808\n",
      "train loss:0.011793504121613644\n",
      "train loss:0.0038053606841084954\n",
      "train loss:0.0067006303678699385\n",
      "train loss:0.02951975571296019\n",
      "train loss:0.004019708472449651\n",
      "train loss:0.0010508575011492754\n",
      "train loss:0.003406199345081623\n",
      "train loss:0.005372542029384954\n",
      "train loss:0.0011077099413720664\n",
      "train loss:0.009163875935534712\n",
      "train loss:0.007163701973619744\n",
      "train loss:0.013722722953121512\n",
      "train loss:0.0022073231949985735\n",
      "train loss:0.0017293452388348319\n",
      "train loss:0.012453035644120916\n",
      "train loss:0.009170637417479414\n",
      "train loss:0.0016397714531386962\n",
      "train loss:0.001863877613495925\n",
      "train loss:0.0011271023266446484\n",
      "train loss:0.012079511161737333\n",
      "train loss:0.002622842877307174\n",
      "train loss:0.007234912490817651\n",
      "train loss:0.007544705230884185\n",
      "train loss:0.00715267402788671\n",
      "train loss:0.013804342110467492\n",
      "train loss:0.0033774929929384786\n",
      "train loss:0.004038043919869044\n",
      "train loss:0.0027427614899475906\n",
      "train loss:0.0034960266537453445\n",
      "train loss:0.005830300959155257\n",
      "train loss:0.08152636451606299\n",
      "train loss:0.006237426256354927\n",
      "train loss:0.0017422721871641364\n",
      "train loss:0.0018264304506563364\n",
      "train loss:0.0041253026983218664\n",
      "train loss:0.004723725861132356\n",
      "train loss:0.0167423965540889\n",
      "train loss:0.004342889951712842\n",
      "train loss:0.004711304613569063\n",
      "train loss:0.007128338191021211\n",
      "train loss:0.03775308258103529\n",
      "train loss:0.02446571579295185\n",
      "train loss:0.005228532054519741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01038791729639729\n",
      "train loss:0.003191321953599434\n",
      "train loss:0.006845720509496773\n",
      "train loss:0.003827127275975113\n",
      "train loss:0.004975981663601213\n",
      "train loss:0.008463211534233009\n",
      "train loss:0.008710421724569014\n",
      "train loss:0.006420918336493126\n",
      "train loss:0.009253263742601627\n",
      "train loss:0.02298416652360751\n",
      "train loss:0.005570565377191538\n",
      "train loss:0.04406292809722019\n",
      "train loss:0.032908497335131\n",
      "train loss:0.00607760719742443\n",
      "train loss:0.017211172115805178\n",
      "train loss:0.005832042140883307\n",
      "train loss:0.0020463414299410117\n",
      "train loss:0.0016535682565405022\n",
      "train loss:0.0036862176270047527\n",
      "train loss:0.004875297824400436\n",
      "train loss:0.02465153836421696\n",
      "train loss:0.0022092831821200315\n",
      "train loss:0.02095438307506343\n",
      "train loss:0.002952436363641084\n",
      "train loss:0.003071586613365493\n",
      "train loss:0.03716959344799284\n",
      "train loss:0.05138884478739114\n",
      "train loss:0.014891009727395235\n",
      "train loss:0.0007744111479084065\n",
      "train loss:0.01930242625499844\n",
      "train loss:0.006057117331363287\n",
      "train loss:0.005967146551483521\n",
      "train loss:0.0045967178818702705\n",
      "train loss:0.006503660740078397\n",
      "train loss:0.03312043112062737\n",
      "train loss:0.012155743037312015\n",
      "train loss:0.005135082986329186\n",
      "train loss:0.005335900559082174\n",
      "train loss:0.006030750970937496\n",
      "train loss:0.042534977313236605\n",
      "train loss:0.00562705756573613\n",
      "train loss:0.00940854639993273\n",
      "train loss:0.028842673323446862\n",
      "train loss:0.025700454082766125\n",
      "train loss:0.012294043876526954\n",
      "train loss:0.02081142126707395\n",
      "train loss:0.001843729274057068\n",
      "train loss:0.003809520797342982\n",
      "train loss:0.0018250775530517613\n",
      "train loss:0.013744272323473838\n",
      "train loss:0.01454042727331404\n",
      "train loss:0.015587744896779387\n",
      "train loss:0.0016947767271315944\n",
      "train loss:0.006859855762281211\n",
      "train loss:0.017083377701874684\n",
      "train loss:0.009105295234723922\n",
      "train loss:0.01785287485831899\n",
      "train loss:0.04953287624025413\n",
      "train loss:0.01039397591898418\n",
      "train loss:0.006047049764581393\n",
      "train loss:0.013706558696379958\n",
      "train loss:0.0031867874698727726\n",
      "train loss:0.012268716191670885\n",
      "train loss:0.0343758015143419\n",
      "train loss:0.006239996110220224\n",
      "train loss:0.037064538323970955\n",
      "train loss:0.03354053490489395\n",
      "train loss:0.0271103006564523\n",
      "train loss:0.041257279357079735\n",
      "train loss:0.00199902365974941\n",
      "train loss:0.02249472867050174\n",
      "train loss:0.01186281759792521\n",
      "train loss:0.011443055112382054\n",
      "train loss:0.0466373021536346\n",
      "train loss:0.0016321099041339481\n",
      "train loss:0.023709132279019253\n",
      "train loss:0.002432582416712853\n",
      "train loss:0.012078089974220356\n",
      "train loss:0.01986712168399578\n",
      "train loss:0.006112904434693465\n",
      "train loss:0.034209800123468165\n",
      "train loss:0.009782014557741104\n",
      "train loss:0.0009926069015059736\n",
      "train loss:0.011928740132325012\n",
      "train loss:0.013914408161006492\n",
      "train loss:0.006903225128088986\n",
      "train loss:0.0413547720180562\n",
      "train loss:0.0024367155106133033\n",
      "train loss:0.008775734730327526\n",
      "train loss:0.004722655910324541\n",
      "train loss:0.003989038853387746\n",
      "train loss:0.008255146908957624\n",
      "train loss:0.04147896963091298\n",
      "train loss:0.004050114932204686\n",
      "train loss:0.04762657741145877\n",
      "train loss:0.0038362634318255084\n",
      "train loss:0.016305567442607832\n",
      "train loss:0.01955593265694308\n",
      "train loss:0.020202224072334095\n",
      "train loss:0.025520744160201943\n",
      "train loss:0.014438765468967156\n",
      "train loss:0.006120702039697644\n",
      "train loss:0.0011098619752715473\n",
      "train loss:0.006772508557596285\n",
      "train loss:0.012806001625593666\n",
      "train loss:0.007521432494294599\n",
      "train loss:0.006491427596547697\n",
      "train loss:0.010253891453829432\n",
      "train loss:0.012403682537161516\n",
      "train loss:0.001643612005821187\n",
      "train loss:0.003275165358711707\n",
      "train loss:0.009229698303904377\n",
      "train loss:0.007464099604094638\n",
      "train loss:0.002685385084037635\n",
      "train loss:0.01800525712980442\n",
      "train loss:0.020239401051115564\n",
      "train loss:0.021303942252294924\n",
      "train loss:0.01367889176985177\n",
      "train loss:0.013596725689436364\n",
      "train loss:0.0017475209253329982\n",
      "train loss:0.003261572976200642\n",
      "train loss:0.005467304239676373\n",
      "train loss:0.006797964535064551\n",
      "train loss:0.010295266860491084\n",
      "train loss:0.00096527913383962\n",
      "train loss:0.019420672764931386\n",
      "train loss:0.014251789563642965\n",
      "train loss:0.015218889215321729\n",
      "train loss:0.006921887251040359\n",
      "train loss:0.010340045260958249\n",
      "train loss:0.010641090437978194\n",
      "train loss:0.015260067352687383\n",
      "train loss:0.005939776339377716\n",
      "train loss:0.0022632443540009377\n",
      "train loss:0.0015291805183960993\n",
      "train loss:0.013351034622513755\n",
      "train loss:0.011007014247863108\n",
      "train loss:0.010632673233277143\n",
      "train loss:0.02412029573103504\n",
      "train loss:0.005204627551551219\n",
      "train loss:0.021023305704144395\n",
      "train loss:0.008994560299565682\n",
      "train loss:0.00566599250392566\n",
      "train loss:0.013731094332462914\n",
      "train loss:0.010451450094315752\n",
      "train loss:0.007675931075778829\n",
      "train loss:0.01769444205381829\n",
      "train loss:0.0025904702830919046\n",
      "train loss:0.005891230633192408\n",
      "train loss:0.005397514162556695\n",
      "train loss:0.07501150958021487\n",
      "train loss:0.0008709663405297115\n",
      "train loss:0.015416995228652005\n",
      "train loss:0.0019873050945148616\n",
      "train loss:0.011607520831793536\n",
      "train loss:0.005631413610615036\n",
      "train loss:0.005480091430927021\n",
      "train loss:0.0028965500216365987\n",
      "train loss:0.007176247219702337\n",
      "train loss:0.00913292763743714\n",
      "train loss:0.008990914490958832\n",
      "train loss:0.0035549086012458954\n",
      "train loss:0.008118098015549295\n",
      "train loss:0.010116423498434668\n",
      "train loss:0.005423509199081011\n",
      "train loss:0.007251249021625169\n",
      "train loss:0.006095616752270489\n",
      "train loss:0.003983717119527596\n",
      "train loss:0.0024345486464531917\n",
      "train loss:0.012715902256806511\n",
      "train loss:0.012511156337923972\n",
      "train loss:0.003268644880574091\n",
      "train loss:0.01758064029326224\n",
      "train loss:0.0032229333220409094\n",
      "train loss:0.009704433829299777\n",
      "train loss:0.005151968068081793\n",
      "train loss:0.025435430786217315\n",
      "=== epoch:10, train acc:0.996, test acc:0.989 ===\n",
      "train loss:0.006663039760559739\n",
      "train loss:0.0038523330546536123\n",
      "train loss:0.004718360395471511\n",
      "train loss:0.007738401986643127\n",
      "train loss:0.004992685018790184\n",
      "train loss:0.0023216895511046502\n",
      "train loss:0.011762202754832035\n",
      "train loss:0.0031482757844635313\n",
      "train loss:0.001897897616467924\n",
      "train loss:0.0018315645042854506\n",
      "train loss:0.0025202090779296716\n",
      "train loss:0.004838919686202311\n",
      "train loss:0.03283499119785116\n",
      "train loss:0.0022762642305396642\n",
      "train loss:0.008504699268890126\n",
      "train loss:0.031242941209369574\n",
      "train loss:0.003447044820666047\n",
      "train loss:0.0005238295248702987\n",
      "train loss:0.0051384886225045055\n",
      "train loss:0.009152147174327642\n",
      "train loss:0.002152275399393041\n",
      "train loss:0.026990418275383624\n",
      "train loss:0.007548031124476714\n",
      "train loss:0.00667508067359521\n",
      "train loss:0.0028296087950223647\n",
      "train loss:0.004649418136451852\n",
      "train loss:0.012008424448666033\n",
      "train loss:0.004779455992809392\n",
      "train loss:0.003751730491764359\n",
      "train loss:0.0036549461745732526\n",
      "train loss:0.003292390923346281\n",
      "train loss:0.008208625163069392\n",
      "train loss:0.0020552283845916373\n",
      "train loss:0.00560851374611629\n",
      "train loss:0.006995941765624034\n",
      "train loss:0.001699847562334131\n",
      "train loss:0.002486636751925522\n",
      "train loss:0.011174769060868783\n",
      "train loss:0.0064957822235259385\n",
      "train loss:0.01185213722744734\n",
      "train loss:0.003362543320908873\n",
      "train loss:0.004579016107847555\n",
      "train loss:0.011832061465242804\n",
      "train loss:0.0009374864195631161\n",
      "train loss:0.0060848308398128315\n",
      "train loss:0.016127130715060892\n",
      "train loss:0.039720504726142\n",
      "train loss:0.008344245538371358\n",
      "train loss:0.0014967263179558972\n",
      "train loss:0.023945617427114287\n",
      "train loss:0.0029593623586356933\n",
      "train loss:0.0026742238671047546\n",
      "train loss:0.0008758002904392533\n",
      "train loss:0.007679471742532682\n",
      "train loss:0.0016055608226982871\n",
      "train loss:0.003616553952646553\n",
      "train loss:0.004460693824370436\n",
      "train loss:0.001781319793379348\n",
      "train loss:0.07597339757549197\n",
      "train loss:0.002165052389916087\n",
      "train loss:0.01664591475054651\n",
      "train loss:0.0060186927163730156\n",
      "train loss:0.0027602470411976225\n",
      "train loss:0.0035435072375972544\n",
      "train loss:0.0029168241832593926\n",
      "train loss:0.010428896971429867\n",
      "train loss:0.012692687816633241\n",
      "train loss:0.00821579674934195\n",
      "train loss:0.0046108284951806465\n",
      "train loss:0.010790697698197549\n",
      "train loss:0.0035490100121609576\n",
      "train loss:0.009552746994228601\n",
      "train loss:0.005674272850388707\n",
      "train loss:0.009163616124732972\n",
      "train loss:0.0032468634872494045\n",
      "train loss:0.0077639143707769346\n",
      "train loss:0.004846506175143679\n",
      "train loss:0.00478553533416583\n",
      "train loss:0.024573060436029612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006785126102136479\n",
      "train loss:0.01393383985097256\n",
      "train loss:0.01589041016910988\n",
      "train loss:0.016554046030407145\n",
      "train loss:0.034319298882559995\n",
      "train loss:0.012815520580565919\n",
      "train loss:0.021197047308642553\n",
      "train loss:0.05492667813928787\n",
      "train loss:0.008150092536021742\n",
      "train loss:0.03971742498143989\n",
      "train loss:0.005311784082839653\n",
      "train loss:0.02873292959032801\n",
      "train loss:0.002868029810319224\n",
      "train loss:0.0007606506223488438\n",
      "train loss:0.009354827206438708\n",
      "train loss:0.004409039462789648\n",
      "train loss:0.0032959627432397397\n",
      "train loss:0.029017637382546785\n",
      "train loss:0.011031463559297667\n",
      "train loss:0.002504835330320163\n",
      "train loss:0.007192091490003481\n",
      "train loss:0.004952600692542174\n",
      "train loss:0.006782881868669433\n",
      "train loss:0.013299565470742028\n",
      "train loss:0.006347088130628386\n",
      "train loss:0.010581441834654487\n",
      "train loss:0.01502260825370336\n",
      "train loss:0.0006420819642950913\n",
      "train loss:0.010413119901066388\n",
      "train loss:0.002808446236559597\n",
      "train loss:0.006797066657120523\n",
      "train loss:0.009412763561691078\n",
      "train loss:0.006510510057366423\n",
      "train loss:0.0008991996751611393\n",
      "train loss:0.004651663080072536\n",
      "train loss:0.012271155043782966\n",
      "train loss:0.03359933061853506\n",
      "train loss:0.0004566578852267163\n",
      "train loss:0.0023107234592826794\n",
      "train loss:0.011765583454321528\n",
      "train loss:0.0017445949602697974\n",
      "train loss:0.006820625169841043\n",
      "train loss:0.00902493826649301\n",
      "train loss:0.01979926510170075\n",
      "train loss:0.007032097561618542\n",
      "train loss:0.02065506203859667\n",
      "train loss:0.006298805498519633\n",
      "train loss:0.005333672596503207\n",
      "train loss:0.05755406036524567\n",
      "train loss:0.006128067403945757\n",
      "train loss:0.02267563241711921\n",
      "train loss:0.013073283434131822\n",
      "train loss:0.03387742109490019\n",
      "train loss:0.013247624930797975\n",
      "train loss:0.01969875514670052\n",
      "train loss:0.0023866655995270127\n",
      "train loss:0.002623258987569776\n",
      "train loss:0.0012774551210220629\n",
      "train loss:0.09306849145672097\n",
      "train loss:0.0014411197441686666\n",
      "train loss:0.02388086028579324\n",
      "train loss:0.006451169748240317\n",
      "train loss:0.02379302718358102\n",
      "train loss:0.01700452294259523\n",
      "train loss:0.01767721712153389\n",
      "train loss:0.002487266902342111\n",
      "train loss:0.0109251847285897\n",
      "train loss:0.050748091906366664\n",
      "train loss:0.0016193655243267422\n",
      "train loss:0.002932941513908946\n",
      "train loss:0.022454508261297176\n",
      "train loss:0.0035518679593656366\n",
      "train loss:0.003475681299001136\n",
      "train loss:0.006764121590048432\n",
      "train loss:0.0005750236478897092\n",
      "train loss:0.009998108973652926\n",
      "train loss:0.02116237504702422\n",
      "train loss:0.003375141093852753\n",
      "train loss:0.010474520682229727\n",
      "train loss:0.006153293387058367\n",
      "train loss:0.01173317731858772\n",
      "train loss:0.007254959938581737\n",
      "train loss:0.008777268829986888\n",
      "train loss:0.0026766563942323134\n",
      "train loss:0.009714802230237983\n",
      "train loss:0.00868021121364353\n",
      "train loss:0.006281240325214813\n",
      "train loss:0.0007248814124315903\n",
      "train loss:0.009813976542060118\n",
      "train loss:0.014427524716955315\n",
      "train loss:0.02564665327463478\n",
      "train loss:0.002548712242993999\n",
      "train loss:0.0032875281347617847\n",
      "train loss:0.009203782572632586\n",
      "train loss:0.001580984065873379\n",
      "train loss:0.015814209093742992\n",
      "train loss:0.006778680175684196\n",
      "train loss:0.00960813660215544\n",
      "train loss:0.0006707759577629814\n",
      "train loss:0.007127533419711154\n",
      "train loss:0.002169455980544616\n",
      "train loss:0.012803300001002334\n",
      "train loss:0.00657218984507223\n",
      "train loss:0.012494939202996776\n",
      "train loss:0.004258492991555511\n",
      "train loss:0.002716788878822165\n",
      "train loss:0.010702796520334491\n",
      "train loss:0.0038489109517159882\n",
      "train loss:0.009748269078302268\n",
      "train loss:0.009499328830372968\n",
      "train loss:0.027345099521628318\n",
      "train loss:0.007244844000597934\n",
      "train loss:0.006360246275861811\n",
      "train loss:0.0027857504672781737\n",
      "train loss:0.00024580932233492935\n",
      "train loss:0.00553036264326983\n",
      "train loss:0.010141524669886383\n",
      "train loss:0.0038733097397593286\n",
      "train loss:0.0037876060830987503\n",
      "train loss:0.01081974574556737\n",
      "train loss:0.005662714158537715\n",
      "train loss:0.0016077751021019002\n",
      "train loss:0.012161291591350647\n",
      "train loss:0.0075359746067176015\n",
      "train loss:0.005122385229479009\n",
      "train loss:0.003163959376310127\n",
      "train loss:0.006098539212723736\n",
      "train loss:0.009969885104230044\n",
      "train loss:0.0009361581231826066\n",
      "train loss:0.010635154941061478\n",
      "train loss:0.007099769208172639\n",
      "train loss:0.00194430986149129\n",
      "train loss:0.0029962440892231036\n",
      "train loss:0.008640531722334907\n",
      "train loss:0.014462497376817271\n",
      "train loss:0.0054728929137127435\n",
      "train loss:0.005170515728312052\n",
      "train loss:0.006291227531625964\n",
      "train loss:0.010551325803809847\n",
      "train loss:0.002183166113992125\n",
      "train loss:0.0004630378555225191\n",
      "train loss:0.012293848713093455\n",
      "train loss:0.001496322696836089\n",
      "train loss:0.005712844634963207\n",
      "train loss:0.003676435671119659\n",
      "train loss:0.0012344993238686966\n",
      "train loss:0.00632786883016973\n",
      "train loss:0.007999106834306552\n",
      "train loss:0.013343828388835752\n",
      "train loss:0.010979488255967904\n",
      "train loss:0.001753545453561137\n",
      "train loss:0.018113254583077297\n",
      "train loss:0.001152363915430908\n",
      "train loss:0.014589030658555652\n",
      "train loss:0.004863923016773471\n",
      "train loss:0.0020023053429035643\n",
      "train loss:0.0062115599228572075\n",
      "train loss:0.007989762545906793\n",
      "train loss:0.04336237920605206\n",
      "train loss:0.00291781978986574\n",
      "train loss:0.0006682505443028112\n",
      "train loss:0.0019974709569658754\n",
      "train loss:0.0247446590354311\n",
      "train loss:0.004259919131325945\n",
      "train loss:0.0022791695606349336\n",
      "train loss:0.009016640144008502\n",
      "train loss:0.005501922887692354\n",
      "train loss:0.005842102307453467\n",
      "train loss:0.001578378572361945\n",
      "train loss:0.006371545639502593\n",
      "train loss:0.003246703954471957\n",
      "train loss:0.003898896417667399\n",
      "train loss:0.0019266073725004724\n",
      "train loss:0.016669423887589633\n",
      "train loss:0.004696635304276547\n",
      "train loss:0.002285330707545267\n",
      "train loss:0.004811566115217164\n",
      "train loss:0.00290392594592764\n",
      "train loss:0.005487692391937607\n",
      "train loss:0.006815320301134452\n",
      "train loss:0.007953334613656226\n",
      "train loss:0.04613949812770643\n",
      "train loss:0.01821863520636309\n",
      "train loss:0.016626121794981435\n",
      "train loss:0.0027219832871586704\n",
      "train loss:0.0038503865275584742\n",
      "train loss:0.006382217987599935\n",
      "train loss:0.006906568265549302\n",
      "train loss:0.003751202711229829\n",
      "train loss:0.005633860127625047\n",
      "train loss:0.0454854075971101\n",
      "train loss:0.003097524655196784\n",
      "train loss:0.0026841858419286765\n",
      "train loss:0.005040706032963516\n",
      "train loss:0.0023944477852292805\n",
      "train loss:0.00795958643375188\n",
      "train loss:0.10400237082817347\n",
      "train loss:0.000993408106668956\n",
      "train loss:0.019792496902292428\n",
      "train loss:0.006480743817100735\n",
      "train loss:0.017078033387769986\n",
      "train loss:0.004303551662526511\n",
      "train loss:0.003187641151764134\n",
      "train loss:0.008236016379502865\n",
      "train loss:0.0047536054479581915\n",
      "train loss:0.0015843422208175152\n",
      "train loss:0.01876340022030068\n",
      "train loss:0.006661359675163637\n",
      "train loss:0.0022695255267175763\n",
      "train loss:0.0034028038541719275\n",
      "train loss:0.0134176878831264\n",
      "train loss:0.005097291574866832\n",
      "train loss:0.016853695332689985\n",
      "train loss:0.019672772566127223\n",
      "train loss:0.0012997887351309891\n",
      "train loss:0.013424309466336177\n",
      "train loss:0.0044661627400625495\n",
      "train loss:0.007909753291283685\n",
      "train loss:0.007210522654004965\n",
      "train loss:0.0011579103749619955\n",
      "train loss:0.0310737989098922\n",
      "train loss:0.0024848976626359325\n",
      "train loss:0.006197876029075971\n",
      "train loss:0.004444564345419553\n",
      "train loss:0.003073666015433507\n",
      "train loss:0.005979070006118489\n",
      "train loss:0.013964733730835257\n",
      "train loss:0.005577571870767888\n",
      "train loss:0.0011431609034758998\n",
      "train loss:0.0018094646092842407\n",
      "train loss:0.017256771615295374\n",
      "train loss:0.001249285336991644\n",
      "train loss:0.0027365202556032973\n",
      "train loss:0.009145859518922739\n",
      "train loss:0.003843024064161567\n",
      "train loss:0.0007739215967118627\n",
      "train loss:0.0035525532756407983\n",
      "train loss:0.00261838138969509\n",
      "train loss:0.012065075619744809\n",
      "train loss:0.019223473531697958\n",
      "train loss:0.021781991377770673\n",
      "train loss:0.007809244340159165\n",
      "train loss:0.0025864542929604946\n",
      "train loss:0.00036151023465540703\n",
      "train loss:0.007277551042516034\n",
      "train loss:0.00476391346423968\n",
      "train loss:0.00579788230924655\n",
      "train loss:0.0035838494136635353\n",
      "train loss:0.004000880766846775\n",
      "train loss:0.0016635092971031928\n",
      "train loss:0.0026595489863327658\n",
      "train loss:0.003615329218916595\n",
      "train loss:0.010093299838662185\n",
      "train loss:0.0036728668394696716\n",
      "train loss:0.004069445343341998\n",
      "train loss:0.009782149967607717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016696165522137147\n",
      "train loss:0.0014998644790934412\n",
      "train loss:0.0026057982587668303\n",
      "train loss:0.006167346676228138\n",
      "train loss:0.03801938303400405\n",
      "train loss:0.008631576787887585\n",
      "train loss:0.003773587083459619\n",
      "train loss:0.0066299757491161395\n",
      "train loss:0.05759541268436637\n",
      "train loss:0.0014793349680664\n",
      "train loss:0.0029889849415779737\n",
      "train loss:0.006790069981906486\n",
      "train loss:0.00939560882949852\n",
      "train loss:0.014240167248646948\n",
      "train loss:0.00767538997377739\n",
      "train loss:0.010591661039986051\n",
      "train loss:0.002324372125940458\n",
      "train loss:0.032639717802742566\n",
      "train loss:0.043505039671480346\n",
      "train loss:0.00670883888900488\n",
      "train loss:0.007431344005198151\n",
      "train loss:0.030221509950543558\n",
      "train loss:0.004823649917907885\n",
      "train loss:0.005036230562427991\n",
      "train loss:0.005971759634996128\n",
      "train loss:0.0010289171388193916\n",
      "train loss:0.0018348751060968437\n",
      "train loss:0.008132576127138798\n",
      "train loss:0.0031218601022880597\n",
      "train loss:0.02436342838902329\n",
      "train loss:0.06561715117244893\n",
      "train loss:0.007934900007334779\n",
      "train loss:0.0007316437749537798\n",
      "train loss:0.006987576477203608\n",
      "train loss:0.00422658897000672\n",
      "train loss:0.005814911571561277\n",
      "train loss:0.0303922064483397\n",
      "train loss:0.001841001690260547\n",
      "train loss:0.040270301565650375\n",
      "train loss:0.005349239492548962\n",
      "train loss:0.008981417085519302\n",
      "train loss:0.03216547996440481\n",
      "train loss:0.012906943206275043\n",
      "train loss:0.0022935152793620954\n",
      "train loss:0.006699186507656303\n",
      "train loss:0.009343551834196726\n",
      "train loss:0.01657182558391303\n",
      "train loss:0.013324338270610914\n",
      "train loss:0.01230988594419958\n",
      "train loss:0.0032641905074227784\n",
      "train loss:0.010606673097171854\n",
      "train loss:0.0007246856924367926\n",
      "train loss:0.009454526206372202\n",
      "train loss:0.005491124018833229\n",
      "train loss:0.009943207452493288\n",
      "train loss:0.0016545077490704974\n",
      "train loss:0.0012893258534273284\n",
      "train loss:0.005684551813079003\n",
      "train loss:0.036408989222085436\n",
      "train loss:0.0063682912069350514\n",
      "train loss:0.002870773474442908\n",
      "train loss:0.0005324100305460233\n",
      "train loss:0.0023843773042860335\n",
      "train loss:0.013457153667927636\n",
      "train loss:0.023390864628636692\n",
      "train loss:0.01711391264422199\n",
      "train loss:0.004307723258620488\n",
      "train loss:0.003688447227503483\n",
      "train loss:0.0064429938530022055\n",
      "train loss:0.0022909217688429143\n",
      "train loss:0.0381940485013262\n",
      "train loss:0.011756332748033732\n",
      "train loss:0.002268722573614044\n",
      "train loss:0.001194753793565059\n",
      "train loss:0.0037966597557736325\n",
      "train loss:0.027671739134453158\n",
      "train loss:0.026968539715824982\n",
      "train loss:0.00766426041790777\n",
      "train loss:0.003928114518905235\n",
      "train loss:0.003743306973552594\n",
      "train loss:0.009012695256614692\n",
      "train loss:0.007116080622301996\n",
      "train loss:0.011617875547684637\n",
      "train loss:0.014299418262967245\n",
      "train loss:0.054444696800907036\n",
      "train loss:0.0024984219660787827\n",
      "train loss:0.0024746127559192223\n",
      "train loss:0.014234798362047867\n",
      "train loss:0.019916012100384912\n",
      "train loss:0.0621273684156007\n",
      "train loss:0.002196983226132378\n",
      "train loss:0.003298697432829046\n",
      "train loss:0.004203935922906915\n",
      "train loss:0.003862899614971001\n",
      "train loss:0.006520152338124686\n",
      "train loss:0.008909724392397997\n",
      "train loss:0.0052982918478248035\n",
      "train loss:0.002350290103317388\n",
      "train loss:0.0027780492510734007\n",
      "train loss:0.0021403601712299985\n",
      "train loss:0.013466155296888145\n",
      "train loss:0.014180637935679807\n",
      "train loss:0.005556921418797671\n",
      "train loss:0.0070757831460521526\n",
      "train loss:0.0006794735083861403\n",
      "train loss:0.006871451797620747\n",
      "train loss:0.004007459932869039\n",
      "train loss:0.019475217438110193\n",
      "train loss:0.004902395911344582\n",
      "train loss:0.0027809680639340867\n",
      "train loss:0.0017795131673150311\n",
      "train loss:0.0026812867181156726\n",
      "train loss:0.023391313804390787\n",
      "train loss:0.0009445885543241636\n",
      "train loss:0.0070501544092832664\n",
      "train loss:0.005187300568195267\n",
      "train loss:0.005717555637058263\n",
      "train loss:0.001821932551089596\n",
      "train loss:0.0029246254600784833\n",
      "train loss:0.006214285867485115\n",
      "train loss:0.0009775705953222788\n",
      "train loss:0.0015402124965441196\n",
      "train loss:0.004687983008654615\n",
      "train loss:0.0026136292827860287\n",
      "train loss:0.007746937540130522\n",
      "train loss:0.0030507535783487073\n",
      "train loss:0.00734203483212738\n",
      "train loss:0.0026119320598928454\n",
      "train loss:0.0011325351865674215\n",
      "train loss:0.01180701976134735\n",
      "train loss:0.0011581745822352948\n",
      "train loss:0.0011925387706037969\n",
      "train loss:0.01776678548381735\n",
      "train loss:0.019001865360558617\n",
      "train loss:0.004507787455950156\n",
      "train loss:0.009953604281632172\n",
      "train loss:0.001774866109523091\n",
      "train loss:0.01584841630843763\n",
      "train loss:0.002197922077744303\n",
      "train loss:0.001154094148840776\n",
      "train loss:0.0015906228389216991\n",
      "train loss:0.010080258585324993\n",
      "train loss:0.0024778748321952547\n",
      "train loss:0.010955264812324188\n",
      "train loss:0.0030843080350435037\n",
      "train loss:0.010500295715779878\n",
      "train loss:0.011108501108895118\n",
      "train loss:0.0016255377510148228\n",
      "train loss:0.008971256423507556\n",
      "train loss:0.002400800998254828\n",
      "train loss:0.021452637433078535\n",
      "train loss:0.004725381119538146\n",
      "train loss:0.05108414502338517\n",
      "train loss:0.0006075114827764751\n",
      "train loss:0.0040817730700587794\n",
      "train loss:0.02058506644119048\n",
      "train loss:0.002591106657425514\n",
      "train loss:0.01579249097609161\n",
      "train loss:0.003096669641628322\n",
      "train loss:0.006597157024844215\n",
      "train loss:0.0033810715991975\n",
      "train loss:0.0043695913694039535\n",
      "train loss:0.006909369029090171\n",
      "train loss:0.023330233083656338\n",
      "train loss:0.007425292548505429\n",
      "train loss:0.0024394571534411525\n",
      "train loss:0.005049070396822445\n",
      "train loss:0.029605836336552685\n",
      "train loss:0.009428712474639042\n",
      "train loss:0.001773004150226177\n",
      "train loss:0.00541766650567269\n",
      "train loss:0.002034732158796662\n",
      "train loss:0.01439580101407082\n",
      "train loss:0.0016016190935018893\n",
      "train loss:0.0009532169944168244\n",
      "train loss:0.0020540945396494243\n",
      "train loss:0.00662288320478068\n",
      "train loss:0.0208457201575315\n",
      "train loss:0.01645382999467608\n",
      "train loss:0.0046009969782842735\n",
      "train loss:0.00316935651441913\n",
      "train loss:0.0028500350210793318\n",
      "train loss:0.007345925423420513\n",
      "train loss:0.018298259004053578\n",
      "train loss:0.03056365770314836\n",
      "train loss:0.004511361133297874\n",
      "train loss:0.0009538220386956599\n",
      "train loss:0.006794198929862748\n",
      "train loss:0.0016945400201362631\n",
      "train loss:0.007228778443842128\n",
      "train loss:0.004530598989603144\n",
      "train loss:0.001401627305397131\n",
      "train loss:0.00523445325102788\n",
      "train loss:0.008292057758793048\n",
      "train loss:0.006092034375029917\n",
      "train loss:0.0877423209289545\n",
      "train loss:0.003948533724023994\n",
      "train loss:0.013776398057768379\n",
      "train loss:0.012982577761619032\n",
      "train loss:0.06294820802192659\n",
      "train loss:0.004726026535344746\n",
      "train loss:0.007690512597973337\n",
      "train loss:0.0024284053876697494\n",
      "train loss:0.01887615225768098\n",
      "train loss:0.002633633908044188\n",
      "train loss:0.0011011155735046738\n",
      "train loss:0.004307023703603122\n",
      "train loss:0.0025536270874382057\n",
      "train loss:0.0034759756904631073\n",
      "train loss:0.007116467185938959\n",
      "train loss:0.002163513557590715\n",
      "train loss:0.004925321716674751\n",
      "train loss:0.010748237363363588\n",
      "train loss:0.0010236183541707064\n",
      "train loss:0.004870128627570311\n",
      "train loss:0.00330941257731127\n",
      "train loss:0.0010942107190858462\n",
      "train loss:0.0028081999688295894\n",
      "train loss:0.0011293709446372458\n",
      "train loss:0.006710144354563963\n",
      "train loss:0.0013081231261916168\n",
      "train loss:0.0011267314395904747\n",
      "train loss:0.015391177431121514\n",
      "train loss:0.0010578792101378946\n",
      "train loss:0.019636228316279137\n",
      "train loss:0.003107882510954442\n",
      "train loss:0.01071798410297748\n",
      "train loss:0.008223144488966373\n",
      "train loss:0.09735104940462608\n",
      "train loss:0.014636480563831515\n",
      "train loss:0.003302260929302924\n",
      "train loss:0.004837873442899604\n",
      "train loss:0.0118522046177765\n",
      "train loss:0.03973238755408642\n",
      "train loss:0.006400415714212559\n",
      "train loss:0.008079290433382836\n",
      "train loss:0.001410685071258576\n",
      "train loss:0.009991039513102859\n",
      "train loss:0.003136171086399624\n",
      "train loss:0.0015482230657199764\n",
      "train loss:0.0026535542227854396\n",
      "train loss:0.0012582603744079393\n",
      "train loss:0.022249656499711223\n",
      "train loss:0.004530577180572845\n",
      "train loss:0.0019611008270764433\n",
      "train loss:0.0016890536130342425\n",
      "train loss:0.03472829268788067\n",
      "train loss:0.0015102127877679443\n",
      "train loss:0.002824709315722453\n",
      "train loss:0.0017055525135904013\n",
      "train loss:0.008075205067407092\n",
      "train loss:0.0010122202637971771\n",
      "train loss:0.05426182442355307\n",
      "train loss:0.0033934942803259325\n",
      "train loss:0.010424671665058663\n",
      "train loss:0.007650018620016023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0030190602161467768\n",
      "train loss:0.003378038801211433\n",
      "train loss:0.0019507722087888169\n",
      "train loss:0.0017620057867112151\n",
      "train loss:0.003682699910469251\n",
      "train loss:0.0012767878208604859\n",
      "train loss:0.0059870329326572646\n",
      "train loss:0.001997823930236508\n",
      "train loss:0.0021721815243831194\n",
      "=== epoch:11, train acc:0.99, test acc:0.988 ===\n",
      "train loss:0.011961377146653195\n",
      "train loss:0.0028964706924532392\n",
      "train loss:0.00169472822663259\n",
      "train loss:0.00501231569253639\n",
      "train loss:0.018877915827400803\n",
      "train loss:0.014552205870316031\n",
      "train loss:0.0018772478539538398\n",
      "train loss:0.0026415570447212507\n",
      "train loss:0.0066471310139899565\n",
      "train loss:0.003628614169642856\n",
      "train loss:0.00881355377716026\n",
      "train loss:0.0015699319888430791\n",
      "train loss:0.003726471222967231\n",
      "train loss:0.005444499068888203\n",
      "train loss:0.012016827855645808\n",
      "train loss:0.004001742344378093\n",
      "train loss:0.004341255738553906\n",
      "train loss:0.019079904541642677\n",
      "train loss:0.0020319809999841385\n",
      "train loss:0.0016291744691865227\n",
      "train loss:0.017607313008474575\n",
      "train loss:0.0025688699849999753\n",
      "train loss:0.001470296910248438\n",
      "train loss:0.009315317596531713\n",
      "train loss:0.0040632715465273965\n",
      "train loss:0.004726928205002806\n",
      "train loss:0.02556949664990006\n",
      "train loss:0.0009912358472053192\n",
      "train loss:0.004474697854684251\n",
      "train loss:0.005965750707870799\n",
      "train loss:0.0028507707680634504\n",
      "train loss:0.012283341877654293\n",
      "train loss:0.01822342201270974\n",
      "train loss:0.004913316380187879\n",
      "train loss:0.0029084436478474278\n",
      "train loss:0.0021976129261134423\n",
      "train loss:0.00322843166939475\n",
      "train loss:0.021833152183127372\n",
      "train loss:0.010182863360715165\n",
      "train loss:0.0031203573527433244\n",
      "train loss:0.008313527948651178\n",
      "train loss:0.009760722152320718\n",
      "train loss:0.01584420521459015\n",
      "train loss:0.003091157727061021\n",
      "train loss:0.01004192864264839\n",
      "train loss:0.016441093606966283\n",
      "train loss:0.010029659485321116\n",
      "train loss:0.04057407683526559\n",
      "train loss:0.0026843916248376664\n",
      "train loss:0.009283260364213626\n",
      "train loss:0.0011063871095893546\n",
      "train loss:0.0048519505049446745\n",
      "train loss:0.0028569043120012434\n",
      "train loss:0.0016394263887267834\n",
      "train loss:0.017776479175078047\n",
      "train loss:0.00504723185433847\n",
      "train loss:0.008362034554766909\n",
      "train loss:0.004821345735979347\n",
      "train loss:0.0015967620665616\n",
      "train loss:0.021827957919754244\n",
      "train loss:0.0010426016310960216\n",
      "train loss:0.0009958528485530774\n",
      "train loss:0.0007672823560026868\n",
      "train loss:0.00907645791674475\n",
      "train loss:0.00602989328775744\n",
      "train loss:0.005065994306898633\n",
      "train loss:0.0024940115628962574\n",
      "train loss:0.013375167465089424\n",
      "train loss:0.010681270617814969\n",
      "train loss:0.003819207421717103\n",
      "train loss:0.008485416496776454\n",
      "train loss:0.02058025602714185\n",
      "train loss:0.04521804025920096\n",
      "train loss:0.004716680929111713\n",
      "train loss:0.008750261092965653\n",
      "train loss:0.004347522233956895\n",
      "train loss:0.005519710861190737\n",
      "train loss:0.005751817028873613\n",
      "train loss:0.00990789508641039\n",
      "train loss:0.02317323547361898\n",
      "train loss:0.0029441322607160884\n",
      "train loss:0.003323423994012833\n",
      "train loss:0.01431843385296559\n",
      "train loss:0.007804098563729132\n",
      "train loss:0.0880908011411997\n",
      "train loss:0.008836569682613737\n",
      "train loss:0.0024937037803643837\n",
      "train loss:0.0006558894952595518\n",
      "train loss:0.0015196613856587825\n",
      "train loss:0.01630570834789698\n",
      "train loss:0.009349469562643778\n",
      "train loss:0.004854280591504688\n",
      "train loss:0.0028891776485693737\n",
      "train loss:0.07575890783887977\n",
      "train loss:0.003063033527849283\n",
      "train loss:0.0043040076206369085\n",
      "train loss:0.0008693242466595009\n",
      "train loss:0.06340418225483255\n",
      "train loss:0.031977864440176286\n",
      "train loss:0.00372517513303913\n",
      "train loss:0.0052633016677358915\n",
      "train loss:0.0022114608013427245\n",
      "train loss:0.01854126545069471\n",
      "train loss:0.0028025910254434344\n",
      "train loss:0.007954668048556473\n",
      "train loss:0.002693046349800528\n",
      "train loss:0.005127189037352533\n",
      "train loss:0.03278455184478853\n",
      "train loss:0.0031933699240844176\n",
      "train loss:0.0038391244207937997\n",
      "train loss:0.007153543416017652\n",
      "train loss:0.0065460809075719465\n",
      "train loss:0.012863118045600691\n",
      "train loss:0.016383889697709555\n",
      "train loss:0.014107653357335832\n",
      "train loss:0.002836650257129304\n",
      "train loss:0.005232777555656388\n",
      "train loss:0.004965353679803761\n",
      "train loss:0.0037386590122635804\n",
      "train loss:0.009805090255419544\n",
      "train loss:0.0014864808589984111\n",
      "train loss:0.001498449565186669\n",
      "train loss:0.009378863204048304\n",
      "train loss:0.001047066415590523\n",
      "train loss:0.021098133033149988\n",
      "train loss:0.00969057869914721\n",
      "train loss:0.004586854689211413\n",
      "train loss:0.01598336172817319\n",
      "train loss:0.004779155459538634\n",
      "train loss:0.006899639974904604\n",
      "train loss:0.0011295607108988625\n",
      "train loss:0.04783282260109936\n",
      "train loss:0.0037052303336211445\n",
      "train loss:0.002329948963183747\n",
      "train loss:0.0009098135554792552\n",
      "train loss:0.0015811856853943519\n",
      "train loss:0.001420171058483532\n",
      "train loss:0.004539840822875485\n",
      "train loss:0.003980592755288276\n",
      "train loss:0.020442331691356532\n",
      "train loss:0.0017128006978494195\n",
      "train loss:0.03364162906878303\n",
      "train loss:0.0008815579569756913\n",
      "train loss:0.0037562698706654456\n",
      "train loss:0.008516591032616793\n",
      "train loss:0.0056184885918027\n",
      "train loss:0.00826542077299712\n",
      "train loss:0.003623550888009819\n",
      "train loss:0.0032793548242330745\n",
      "train loss:0.007541762721083614\n",
      "train loss:0.004595865436100374\n",
      "train loss:0.015426256443802265\n",
      "train loss:0.0035054174045821935\n",
      "train loss:0.01684594909512059\n",
      "train loss:0.0013162880109617403\n",
      "train loss:0.003516356716129312\n",
      "train loss:0.0021540200372592863\n",
      "train loss:0.008419469209538056\n",
      "train loss:0.00945797405341033\n",
      "train loss:0.011456742350846975\n",
      "train loss:0.011428298189710003\n",
      "train loss:0.0037457251737237824\n",
      "train loss:0.008299109712447593\n",
      "train loss:0.007020990194090263\n",
      "train loss:0.004962116787507278\n",
      "train loss:0.0037131728823523967\n",
      "train loss:0.014507667123289493\n",
      "train loss:0.009771331610314706\n",
      "train loss:0.0049583701792244965\n",
      "train loss:0.05134815773377719\n",
      "train loss:0.003989372565742841\n",
      "train loss:0.021524599540908355\n",
      "train loss:0.002316596801080441\n",
      "train loss:0.007447357229674121\n",
      "train loss:0.0036954071538482817\n",
      "train loss:0.007202681038593637\n",
      "train loss:0.009137818017067572\n",
      "train loss:0.002161415672645433\n",
      "train loss:0.003283381786520531\n",
      "train loss:0.016770692658134193\n",
      "train loss:0.008888869809072435\n",
      "train loss:0.006789091776817079\n",
      "train loss:0.03441651837455553\n",
      "train loss:0.0011879177714252882\n",
      "train loss:0.0025661531452412034\n",
      "train loss:0.013396515015143941\n",
      "train loss:0.0053757212658204\n",
      "train loss:0.02870371975686744\n",
      "train loss:0.0014831777692203751\n",
      "train loss:0.004330197444496501\n",
      "train loss:0.0010349681512974707\n",
      "train loss:0.0018193472448504533\n",
      "train loss:0.03018034496635447\n",
      "train loss:0.0005060292443588915\n",
      "train loss:0.0034456806331080096\n",
      "train loss:0.015031721732251818\n",
      "train loss:0.005400565586496735\n",
      "train loss:0.005787559964670623\n",
      "train loss:0.0073868104888022154\n",
      "train loss:0.0017290908641555735\n",
      "train loss:0.0024388577170480537\n",
      "train loss:0.005230469883288788\n",
      "train loss:0.02569610656916507\n",
      "train loss:0.0009390936383734303\n",
      "train loss:0.004572865937892531\n",
      "train loss:0.005380530327466809\n",
      "train loss:0.005248252522447074\n",
      "train loss:0.000816265467402504\n",
      "train loss:0.02632083468443648\n",
      "train loss:0.0009777874485293785\n",
      "train loss:0.005805268763847524\n",
      "train loss:0.000847483951454126\n",
      "train loss:0.002867428630235891\n",
      "train loss:0.003913145127364022\n",
      "train loss:0.009945013859090858\n",
      "train loss:0.008659841277138203\n",
      "train loss:0.008695363491619021\n",
      "train loss:0.014495137259700959\n",
      "train loss:0.002070549764918976\n",
      "train loss:0.013290262773041104\n",
      "train loss:0.015607385557710756\n",
      "train loss:0.02745430013381649\n",
      "train loss:0.012058772826552173\n",
      "train loss:0.03141045951840677\n",
      "train loss:0.0016392117716495362\n",
      "train loss:0.00760689791366147\n",
      "train loss:0.014677662013943134\n",
      "train loss:0.0013728151766558728\n",
      "train loss:0.016829493203968083\n",
      "train loss:0.012338463248666815\n",
      "train loss:0.005970084244055286\n",
      "train loss:0.006465906663674716\n",
      "train loss:0.008134732422927475\n",
      "train loss:0.010387323919993202\n",
      "train loss:0.0027542444867128114\n",
      "train loss:0.01475387574783349\n",
      "train loss:0.011005217235514515\n",
      "train loss:0.002488693898653597\n",
      "train loss:0.0005700697743365061\n",
      "train loss:0.0019138738462105725\n",
      "train loss:0.0017332752382687314\n",
      "train loss:0.008634016549577236\n",
      "train loss:0.0013788255309826736\n",
      "train loss:0.00704892698483554\n",
      "train loss:0.011937379461921449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005052148075877042\n",
      "train loss:0.0019056195022755062\n",
      "train loss:0.003905565380421024\n",
      "train loss:0.0024478916016956857\n",
      "train loss:0.004783161496363316\n",
      "train loss:0.003863123518412236\n",
      "train loss:0.0022206190250970864\n",
      "train loss:0.006960996012323953\n",
      "train loss:0.047485691818769424\n",
      "train loss:0.016236845047404087\n",
      "train loss:0.0033338582732515038\n",
      "train loss:0.0017852487513892916\n",
      "train loss:0.004252394814269437\n",
      "train loss:0.006111208275522859\n",
      "train loss:0.022792488485266726\n",
      "train loss:0.006235456597831474\n",
      "train loss:0.0011715192476962925\n",
      "train loss:0.0023950730361878394\n",
      "train loss:0.004759718841539221\n",
      "train loss:0.005169660618892962\n",
      "train loss:0.0008246534132751528\n",
      "train loss:0.016403475725156533\n",
      "train loss:0.0033532626712505127\n",
      "train loss:0.0035661334584320215\n",
      "train loss:0.0035560142157556205\n",
      "train loss:0.012241223045862918\n",
      "train loss:0.008818630822337189\n",
      "train loss:0.004138429535019709\n",
      "train loss:0.0028590484232890144\n",
      "train loss:0.007095203253179063\n",
      "train loss:0.0012916914246528161\n",
      "train loss:0.0021345382861663507\n",
      "train loss:0.01849052348067781\n",
      "train loss:0.0010943374397538832\n",
      "train loss:0.0011782908017031442\n",
      "train loss:0.007678920738455544\n",
      "train loss:0.007658386859290159\n",
      "train loss:0.004881295084606774\n",
      "train loss:0.0056881312284374685\n",
      "train loss:0.009067871668909225\n",
      "train loss:0.016580688312364852\n",
      "train loss:0.004995314892162761\n",
      "train loss:0.00414270333066749\n",
      "train loss:0.0036119986230496812\n",
      "train loss:0.004822660862434554\n",
      "train loss:0.010350160133398997\n",
      "train loss:0.01023497362704141\n",
      "train loss:0.007973382578982563\n",
      "train loss:0.011434351663881815\n",
      "train loss:0.0016948464913589581\n",
      "train loss:0.0008311476169571351\n",
      "train loss:0.00474380986202806\n",
      "train loss:0.0012925843948425105\n",
      "train loss:0.0013860216746054215\n",
      "train loss:0.003224529087067659\n",
      "train loss:0.00698430770706403\n",
      "train loss:0.002040162067024696\n",
      "train loss:0.0015351272763929923\n",
      "train loss:0.011564475645760453\n",
      "train loss:0.0008541534054529769\n",
      "train loss:0.0031024167767948886\n",
      "train loss:0.0017973429886832966\n",
      "train loss:0.0036379833570883936\n",
      "train loss:0.010147144387162526\n",
      "train loss:0.002400602719099074\n",
      "train loss:0.014892493625114795\n",
      "train loss:0.002461213740190525\n",
      "train loss:0.003321257284112629\n",
      "train loss:0.0007633463039017509\n",
      "train loss:0.006840645978842327\n",
      "train loss:0.000319319772273017\n",
      "train loss:0.0011862771442833224\n",
      "train loss:0.0023694687949171213\n",
      "train loss:0.004029628600728295\n",
      "train loss:0.01065973051866969\n",
      "train loss:0.011814547837226987\n",
      "train loss:0.0006805627919907138\n",
      "train loss:0.007804998385723213\n",
      "train loss:0.001305686037699383\n",
      "train loss:0.009553073937880798\n",
      "train loss:0.0020818888778922793\n",
      "train loss:0.03646380298487225\n",
      "train loss:0.0013341217907754078\n",
      "train loss:0.0016012321967578211\n",
      "train loss:0.002573335553453713\n",
      "train loss:0.004086186817439157\n",
      "train loss:0.046672759630338984\n",
      "train loss:0.03664002314443357\n",
      "train loss:0.0024506738120278954\n",
      "train loss:0.0016871109816282072\n",
      "train loss:0.012987355835132011\n",
      "train loss:0.00548487184235547\n",
      "train loss:0.000563851635944876\n",
      "train loss:0.004738614311406785\n",
      "train loss:0.006553413962565016\n",
      "train loss:0.002265158155949214\n",
      "train loss:0.0009032645922639155\n",
      "train loss:0.006683070394616037\n",
      "train loss:0.001994081680232848\n",
      "train loss:0.0027879611379138924\n",
      "train loss:0.0026883368731062222\n",
      "train loss:0.0062752880661058105\n",
      "train loss:0.008902099514617205\n",
      "train loss:0.007973459480152031\n",
      "train loss:0.0012966900031160843\n",
      "train loss:0.010432779116277833\n",
      "train loss:0.0005219672654645767\n",
      "train loss:0.0015173866364405508\n",
      "train loss:0.004223420542054842\n",
      "train loss:0.0036956278587231945\n",
      "train loss:0.003090236896996259\n",
      "train loss:0.014534423984259992\n",
      "train loss:0.0028978342436828558\n",
      "train loss:0.0028277681704498066\n",
      "train loss:0.00423096713909371\n",
      "train loss:0.00972224258030264\n",
      "train loss:0.004732846431539133\n",
      "train loss:0.0008033850114495908\n",
      "train loss:0.00710595818499793\n",
      "train loss:0.0031221180345028863\n",
      "train loss:0.0009783595218476693\n",
      "train loss:0.005544969064669291\n",
      "train loss:0.0025252297524176797\n",
      "train loss:0.001732098657562843\n",
      "train loss:0.0367281019562658\n",
      "train loss:0.00976179522522124\n",
      "train loss:0.03665004825536829\n",
      "train loss:0.01125379311845327\n",
      "train loss:0.005362268858687068\n",
      "train loss:0.016890349908139903\n",
      "train loss:0.0013355530771067422\n",
      "train loss:0.011881864669270898\n",
      "train loss:0.0033875812013061278\n",
      "train loss:0.005597660398975085\n",
      "train loss:0.008390610800814678\n",
      "train loss:0.01578657903626516\n",
      "train loss:0.0025348279942979147\n",
      "train loss:0.003773553998303329\n",
      "train loss:0.015651630627597193\n",
      "train loss:0.04302951567460519\n",
      "train loss:0.033203366819310666\n",
      "train loss:0.009941466577561769\n",
      "train loss:0.0017866297226820844\n",
      "train loss:0.013357211996323557\n",
      "train loss:0.0033359593147831716\n",
      "train loss:0.0013486521728310274\n",
      "train loss:0.0011735809922796333\n",
      "train loss:0.004737023810679062\n",
      "train loss:0.008685038391594237\n",
      "train loss:0.003433807853266885\n",
      "train loss:0.0036986209224168687\n",
      "train loss:0.004200024201885886\n",
      "train loss:0.16639951385954008\n",
      "train loss:0.007129856792842611\n",
      "train loss:0.0028546091696659798\n",
      "train loss:0.020099001437533355\n",
      "train loss:0.0024220211919667115\n",
      "train loss:0.008674384607380885\n",
      "train loss:0.010058584974438558\n",
      "train loss:0.0070282274416209\n",
      "train loss:0.010020214455090673\n",
      "train loss:0.015468684433350938\n",
      "train loss:0.02329018784152191\n",
      "train loss:0.002213442863225085\n",
      "train loss:0.002205499467758677\n",
      "train loss:0.0019615674309384538\n",
      "train loss:0.008959624818430321\n",
      "train loss:0.02139469719977142\n",
      "train loss:0.0028376582156638187\n",
      "train loss:0.0026996860720817813\n",
      "train loss:0.038138358197382156\n",
      "train loss:0.0013469427694644492\n",
      "train loss:0.00437888377106142\n",
      "train loss:0.03228631586898414\n",
      "train loss:0.00896262068508237\n",
      "train loss:0.00517820866057728\n",
      "train loss:0.004543021847452171\n",
      "train loss:0.0014820615346917765\n",
      "train loss:0.0036602692927329393\n",
      "train loss:0.006299795131724623\n",
      "train loss:0.007264463075535559\n",
      "train loss:0.0037745952477717558\n",
      "train loss:0.001100776343443864\n",
      "train loss:0.012849359857310567\n",
      "train loss:0.008463709272455638\n",
      "train loss:0.0011479890013607965\n",
      "train loss:0.0013850259053608516\n",
      "train loss:0.003375197035219144\n",
      "train loss:0.0015649250219564215\n",
      "train loss:0.0024571751828538473\n",
      "train loss:0.0020701833045191137\n",
      "train loss:0.004506176289281109\n",
      "train loss:0.0033936445081002866\n",
      "train loss:0.0010242910968247133\n",
      "train loss:0.006634833441193683\n",
      "train loss:0.0062519254334022474\n",
      "train loss:0.006578306365574294\n",
      "train loss:0.0011570419599534567\n",
      "train loss:0.002208812237483157\n",
      "train loss:0.009579736953933195\n",
      "train loss:0.008807432231980761\n",
      "train loss:0.0028956730192840085\n",
      "train loss:0.0036372722899723976\n",
      "train loss:0.004801701606487065\n",
      "train loss:0.000675233230782237\n",
      "train loss:0.003691154538262699\n",
      "train loss:0.003755925534132749\n",
      "train loss:0.0009338563676305491\n",
      "train loss:0.009127719160506491\n",
      "train loss:0.011252413104429631\n",
      "train loss:0.002353992214250826\n",
      "train loss:0.05978339567626529\n",
      "train loss:0.0011833920550671888\n",
      "train loss:0.0027948742704291584\n",
      "train loss:0.010173330209801988\n",
      "train loss:0.0005322979620431005\n",
      "train loss:0.007589505711247542\n",
      "train loss:0.0016676165316877668\n",
      "train loss:0.012992137778653289\n",
      "train loss:0.0010545600473692706\n",
      "train loss:0.0012467161696860908\n",
      "train loss:0.009620116715072936\n",
      "train loss:0.006065390140326658\n",
      "train loss:0.0016110968714365642\n",
      "train loss:0.004456834914910171\n",
      "train loss:0.02454283049060797\n",
      "train loss:0.0005279136881947689\n",
      "train loss:0.017247291724586066\n",
      "train loss:0.003113160193367261\n",
      "train loss:0.01710904928882416\n",
      "train loss:0.0005725527927961307\n",
      "train loss:0.0040796669634958\n",
      "train loss:0.04219759384424413\n",
      "train loss:0.00893500270093126\n",
      "train loss:0.006319581439417331\n",
      "train loss:0.031550764549069396\n",
      "train loss:0.003178753327957322\n",
      "train loss:0.024717746514905693\n",
      "train loss:0.025088624150167313\n",
      "train loss:0.0035046727817946936\n",
      "train loss:0.010966864371828335\n",
      "train loss:0.01868866642445294\n",
      "train loss:0.0044713152894163884\n",
      "train loss:0.007014411619715701\n",
      "train loss:0.01627713987493098\n",
      "train loss:0.009425708061895667\n",
      "train loss:0.0016657020396553944\n",
      "train loss:0.0038040280728684757\n",
      "train loss:0.003222224707741599\n",
      "train loss:0.02116287224527133\n",
      "train loss:0.005679018427290025\n",
      "train loss:0.03059189693051593\n",
      "train loss:0.0024563645361302057\n",
      "train loss:0.003625692163157496\n",
      "train loss:0.0456263407178645\n",
      "train loss:0.001929172947146723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008442485983571143\n",
      "train loss:0.037406085138921595\n",
      "train loss:0.004640734669548542\n",
      "train loss:0.008074039719387282\n",
      "train loss:0.00820300309800251\n",
      "train loss:0.002006279503974752\n",
      "train loss:0.0011206514977600273\n",
      "train loss:0.004220787889620069\n",
      "train loss:0.013871988273567235\n",
      "train loss:0.005154257045389409\n",
      "train loss:0.0038740471483508783\n",
      "train loss:0.004375082188652021\n",
      "train loss:0.006926079603165671\n",
      "train loss:0.000834543294853521\n",
      "train loss:0.002721810799107991\n",
      "train loss:0.014994228885585176\n",
      "train loss:0.0032339088933238396\n",
      "train loss:0.002834346570907551\n",
      "train loss:0.00494610698365334\n",
      "train loss:0.0002579324167768835\n",
      "train loss:0.026517982340175498\n",
      "train loss:0.0024239935367889156\n",
      "train loss:0.005314374239826599\n",
      "train loss:0.0020202974973090016\n",
      "train loss:0.016461660558085848\n",
      "train loss:0.016525175543163483\n",
      "train loss:0.004821622602127887\n",
      "train loss:0.001128970763227064\n",
      "train loss:0.04618868087350467\n",
      "train loss:0.0048097230810502135\n",
      "train loss:0.0016473384406807056\n",
      "train loss:0.0013279871503023516\n",
      "train loss:0.0038210289305292394\n",
      "train loss:0.00834678082386039\n",
      "train loss:0.010485686333400992\n",
      "train loss:0.013246396363458823\n",
      "train loss:0.0012464658198568723\n",
      "train loss:0.004246401246690359\n",
      "train loss:0.011144199283603027\n",
      "train loss:0.00187629749497314\n",
      "train loss:0.004530543474257589\n",
      "train loss:0.004922355281104305\n",
      "train loss:0.0007635467003445039\n",
      "train loss:0.0030797435428881127\n",
      "train loss:0.020907451488464245\n",
      "train loss:0.010256093178417138\n",
      "train loss:0.00812020956683628\n",
      "train loss:0.0035039083327629596\n",
      "train loss:0.001111272597264651\n",
      "train loss:0.005531057093660669\n",
      "train loss:0.0029224965973617834\n",
      "train loss:0.023131182058433845\n",
      "train loss:0.050816338757870214\n",
      "train loss:0.01081318452854656\n",
      "train loss:0.0018174268722409167\n",
      "train loss:0.0007240023452148596\n",
      "train loss:0.00564109511507824\n",
      "train loss:0.01917611186952087\n",
      "train loss:0.003214559207223468\n",
      "train loss:0.004695568542835507\n",
      "train loss:0.00181386432092075\n",
      "train loss:0.005821935853285645\n",
      "train loss:0.00350648790687422\n",
      "train loss:0.004495192473715755\n",
      "train loss:0.004107296338467781\n",
      "train loss:0.007610152980406227\n",
      "train loss:0.005035390729454562\n",
      "train loss:0.0022817614129492856\n",
      "train loss:0.0009743395674499062\n",
      "train loss:0.000567699676558286\n",
      "train loss:0.0012446349008314924\n",
      "train loss:0.0034973930182248163\n",
      "train loss:0.005699189085994355\n",
      "train loss:0.00398709691663713\n",
      "train loss:0.005529779598373272\n",
      "train loss:0.0005308196862652183\n",
      "train loss:0.003323858388855725\n",
      "train loss:0.0017987019487690215\n",
      "train loss:0.0030247316795818974\n",
      "train loss:0.021975294273153607\n",
      "train loss:0.000799502210239405\n",
      "train loss:0.011810820955391424\n",
      "train loss:0.0022356367194004355\n",
      "train loss:0.0021488558904691054\n",
      "train loss:0.002979591466426231\n",
      "train loss:0.0013371860494966602\n",
      "train loss:0.00039957253625457785\n",
      "train loss:0.001774792593774239\n",
      "train loss:0.006072599390662962\n",
      "train loss:0.008351741401242268\n",
      "train loss:0.003200913967344129\n",
      "train loss:0.001790627378971256\n",
      "train loss:0.0004951377549977915\n",
      "train loss:0.006928948154928611\n",
      "train loss:0.02831852200776396\n",
      "train loss:0.000867185511294773\n",
      "train loss:0.0138677767108154\n",
      "train loss:0.014733619352170135\n",
      "train loss:0.005521690273955009\n",
      "=== epoch:12, train acc:0.995, test acc:0.984 ===\n",
      "train loss:0.000509829137516095\n",
      "train loss:0.0046119689495617375\n",
      "train loss:0.0008460217626301951\n",
      "train loss:0.0077342327136452945\n",
      "train loss:0.05745380394514757\n",
      "train loss:0.013584959066402438\n",
      "train loss:0.004195198728477967\n",
      "train loss:0.001430278223203654\n",
      "train loss:0.009582638547751444\n",
      "train loss:0.0032141553931092524\n",
      "train loss:0.013875472823750692\n",
      "train loss:0.0022679696025059517\n",
      "train loss:0.0018685587777430178\n",
      "train loss:0.00421284294694451\n",
      "train loss:0.0017633013608841987\n",
      "train loss:0.02106478113761777\n",
      "train loss:0.003882187368389675\n",
      "train loss:0.0009174594607358096\n",
      "train loss:0.0022128383761287353\n",
      "train loss:0.0012214629353402128\n",
      "train loss:0.017106065448800233\n",
      "train loss:0.004407071183906025\n",
      "train loss:0.001053544016723267\n",
      "train loss:0.0008011002314952713\n",
      "train loss:0.0028817370133535454\n",
      "train loss:0.009039202673275872\n",
      "train loss:0.005671273733844362\n",
      "train loss:0.004213384295736958\n",
      "train loss:0.009638188027816458\n",
      "train loss:0.005603289011085787\n",
      "train loss:0.003975050803309907\n",
      "train loss:0.003456358702464413\n",
      "train loss:0.001333670972709583\n",
      "train loss:0.007643204710492339\n",
      "train loss:0.0050042194372525136\n",
      "train loss:0.0032386572083338634\n",
      "train loss:0.005265696991334751\n",
      "train loss:0.03292257282716496\n",
      "train loss:0.017850116792620715\n",
      "train loss:0.002762936319578259\n",
      "train loss:0.00741876502792585\n",
      "train loss:0.0010595267913027944\n",
      "train loss:0.0029017078127811856\n",
      "train loss:0.004432775362606335\n",
      "train loss:0.0013566369743075147\n",
      "train loss:0.0271504348393242\n",
      "train loss:0.003432244883694765\n",
      "train loss:0.0005008189420092297\n",
      "train loss:0.0006675498617696423\n",
      "train loss:0.014171902123793864\n",
      "train loss:0.0009897191113959825\n",
      "train loss:0.0004768076246748554\n",
      "train loss:0.004859754182129227\n",
      "train loss:0.0023307973393373437\n",
      "train loss:0.007346374337403371\n",
      "train loss:0.015520074885222678\n",
      "train loss:0.004411156604390808\n",
      "train loss:0.00045915182854219425\n",
      "train loss:0.0003863245208107017\n",
      "train loss:0.021570684591179393\n",
      "train loss:0.0032106168859440867\n",
      "train loss:0.008887828573183796\n",
      "train loss:0.001672458457159786\n",
      "train loss:0.003819361725575716\n",
      "train loss:0.003852042641463726\n",
      "train loss:0.012608808362534703\n",
      "train loss:0.0015788433956511908\n",
      "train loss:0.002340365428792372\n",
      "train loss:0.006888350542346651\n",
      "train loss:0.0036722638222442543\n",
      "train loss:0.017661630330392034\n",
      "train loss:0.003815986388979978\n",
      "train loss:0.00787102395513548\n",
      "train loss:0.020009905592092907\n",
      "train loss:0.001613468903333423\n",
      "train loss:0.0015165294081580653\n",
      "train loss:0.00868538389437803\n",
      "train loss:0.005809568102578148\n",
      "train loss:0.0017782921725699816\n",
      "train loss:0.004465304584407925\n",
      "train loss:0.006446353804275659\n",
      "train loss:0.0038554038246446914\n",
      "train loss:0.000590246118204815\n",
      "train loss:0.009897321255330103\n",
      "train loss:0.005062717787241523\n",
      "train loss:0.002086894344521923\n",
      "train loss:0.0023331413409767416\n",
      "train loss:0.007480616553252841\n",
      "train loss:0.0028691187759957433\n",
      "train loss:0.0013691520145236657\n",
      "train loss:0.0040358900312610834\n",
      "train loss:0.0018340848338515442\n",
      "train loss:0.0065617722585586576\n",
      "train loss:0.008759620430630178\n",
      "train loss:0.0013958011276183305\n",
      "train loss:0.0022639967777403746\n",
      "train loss:0.0042899142726250915\n",
      "train loss:0.0008268499801194038\n",
      "train loss:0.0030023220443949335\n",
      "train loss:0.004121871614592274\n",
      "train loss:0.0036758015884974034\n",
      "train loss:0.024717983179645433\n",
      "train loss:0.006140505856204333\n",
      "train loss:0.011796340044676286\n",
      "train loss:0.007160596387179464\n",
      "train loss:0.005407455327455282\n",
      "train loss:0.003022149442164898\n",
      "train loss:0.0009674066036193128\n",
      "train loss:0.004594261251486019\n",
      "train loss:0.00935982188779504\n",
      "train loss:0.0038236715400619702\n",
      "train loss:0.0012711248113156791\n",
      "train loss:0.01156624177208933\n",
      "train loss:0.007046448916945603\n",
      "train loss:0.030702063967026537\n",
      "train loss:0.0025852032198840713\n",
      "train loss:0.0004119851366109452\n",
      "train loss:0.002596727516749992\n",
      "train loss:0.010573354358374693\n",
      "train loss:0.004578478005642899\n",
      "train loss:0.026946662235036657\n",
      "train loss:0.024360760949365286\n",
      "train loss:0.0008932873381937574\n",
      "train loss:0.0008258311041981857\n",
      "train loss:0.0007420157070153986\n",
      "train loss:0.0025850438641008334\n",
      "train loss:0.0017656632685877928\n",
      "train loss:0.0033617321111442055\n",
      "train loss:0.0014285820894742048\n",
      "train loss:0.00492546960572305\n",
      "train loss:0.0026356445177113203\n",
      "train loss:0.0008561987052844602\n",
      "train loss:0.005096433542721248\n",
      "train loss:0.006279504587525582\n",
      "train loss:0.003917487566346588\n",
      "train loss:0.0010927454060827432\n",
      "train loss:0.0013106143546397222\n",
      "train loss:0.0005375764444755039\n",
      "train loss:0.0011905370063350147\n",
      "train loss:0.0053047111251781935\n",
      "train loss:0.0011528713420033338\n",
      "train loss:0.001907420472409876\n",
      "train loss:0.0019635201763899884\n",
      "train loss:0.00958476229402\n",
      "train loss:0.0004235642331936216\n",
      "train loss:0.008748974121887134\n",
      "train loss:0.0009927400866406296\n",
      "train loss:0.012159704614620062\n",
      "train loss:0.006879977798419948\n",
      "train loss:0.019036365180151983\n",
      "train loss:0.001993115504597323\n",
      "train loss:0.006840613128566141\n",
      "train loss:0.0031329578731450775\n",
      "train loss:0.004729561355679774\n",
      "train loss:0.008511928315554928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005761245398127823\n",
      "train loss:0.004379750063726088\n",
      "train loss:0.002966650753919856\n",
      "train loss:0.0032987871642768314\n",
      "train loss:0.017675049537086877\n",
      "train loss:0.004432291615061411\n",
      "train loss:0.0275348239822198\n",
      "train loss:0.0006421813409902709\n",
      "train loss:0.010621041053574086\n",
      "train loss:0.0026718739562287853\n",
      "train loss:0.027454262588247156\n",
      "train loss:0.0024416625135233036\n",
      "train loss:0.011378453279700633\n",
      "train loss:0.005345537479306113\n",
      "train loss:0.0010925402754604838\n",
      "train loss:0.003629334208010761\n",
      "train loss:0.013539470930418067\n",
      "train loss:0.007202170550432116\n",
      "train loss:0.008365609606336023\n",
      "train loss:0.009723358876223928\n",
      "train loss:0.01794087262594317\n",
      "train loss:0.01639038456415816\n",
      "train loss:0.0037338666000191834\n",
      "train loss:0.005062941121069752\n",
      "train loss:0.005728173530798891\n",
      "train loss:0.003678305828195992\n",
      "train loss:0.0031271550725007436\n",
      "train loss:0.0018148270706940769\n",
      "train loss:0.003011004891168868\n",
      "train loss:0.0010408286153428903\n",
      "train loss:0.0047322911267164295\n",
      "train loss:0.02380313711007035\n",
      "train loss:0.006811755187771559\n",
      "train loss:0.0016120409562466478\n",
      "train loss:0.01569639137376605\n",
      "train loss:0.04838647462895252\n",
      "train loss:0.005920312414469845\n",
      "train loss:0.00460294206908508\n",
      "train loss:0.006288833322037267\n",
      "train loss:0.005937721369085641\n",
      "train loss:0.005526546823960908\n",
      "train loss:0.0033764572149403084\n",
      "train loss:0.013791480441717081\n",
      "train loss:0.007193859168345197\n",
      "train loss:0.002275758665544785\n",
      "train loss:0.0009969035004585972\n",
      "train loss:0.02556184372035255\n",
      "train loss:0.007153041105527957\n",
      "train loss:0.0013845236312647554\n",
      "train loss:0.0010265425211109546\n",
      "train loss:0.0025443149666238896\n",
      "train loss:0.00338873952098485\n",
      "train loss:0.007613201504941292\n",
      "train loss:0.008171606679710173\n",
      "train loss:0.0009168491063429146\n",
      "train loss:0.002904315670877469\n",
      "train loss:0.00397546536185941\n",
      "train loss:0.015963265154627957\n",
      "train loss:0.01417400280594901\n",
      "train loss:0.0033608049557474267\n",
      "train loss:0.004836877003594337\n",
      "train loss:0.002066746655501633\n",
      "train loss:0.0024412755448150296\n",
      "train loss:0.0017735212063992721\n",
      "train loss:0.003227678242081775\n",
      "train loss:0.003223414046812379\n",
      "train loss:0.0064335425753200915\n",
      "train loss:0.015996250774766522\n",
      "train loss:0.003185143192196944\n",
      "train loss:0.006118222790068651\n",
      "train loss:0.002420194400867274\n",
      "train loss:0.003624759125471385\n",
      "train loss:0.0009230277976267418\n",
      "train loss:0.001269544038324395\n",
      "train loss:0.01770188359292959\n",
      "train loss:0.00028488570217717786\n",
      "train loss:0.00280228550855192\n",
      "train loss:0.000758470985869744\n",
      "train loss:0.010711742380676759\n",
      "train loss:0.0013739624862393843\n",
      "train loss:0.0003043655195721362\n",
      "train loss:0.003446258899911886\n",
      "train loss:0.004571915003456658\n",
      "train loss:0.016207435932000025\n",
      "train loss:0.01770913243018748\n",
      "train loss:0.013442248401800331\n",
      "train loss:0.002703182929061072\n",
      "train loss:0.0006012023788188926\n",
      "train loss:0.0012762913076343957\n",
      "train loss:0.0028832445300541426\n",
      "train loss:0.009557230299751059\n",
      "train loss:0.000547775830402074\n",
      "train loss:0.005240895169825882\n",
      "train loss:0.0007399481897337254\n",
      "train loss:0.003634544190897517\n",
      "train loss:0.009050574953691585\n",
      "train loss:0.004913748447708989\n",
      "train loss:0.002784848170609402\n",
      "train loss:0.023671901347150186\n",
      "train loss:0.008025149897676458\n",
      "train loss:0.006357095922794468\n",
      "train loss:0.0021983957327896273\n",
      "train loss:0.004111053567745363\n",
      "train loss:0.0017789735767595421\n",
      "train loss:0.010789965963118526\n",
      "train loss:0.0021270375646722005\n",
      "train loss:0.002697381041962546\n",
      "train loss:0.008871872146936074\n",
      "train loss:0.004139352742164728\n",
      "train loss:0.01124238613260123\n",
      "train loss:0.0010051547982223973\n",
      "train loss:0.0027342996372117607\n",
      "train loss:0.007738668175029034\n",
      "train loss:0.004911703088339946\n",
      "train loss:0.003403861781629569\n",
      "train loss:0.012784925878455233\n",
      "train loss:0.001522241080274303\n",
      "train loss:0.0026907556967120123\n",
      "train loss:0.003987815708522687\n",
      "train loss:0.005923961094955393\n",
      "train loss:0.003211209904670625\n",
      "train loss:0.0004910322952314386\n",
      "train loss:0.010600668610670135\n",
      "train loss:0.0003501704956644714\n",
      "train loss:0.05408290806602998\n",
      "train loss:0.00583123224909064\n",
      "train loss:0.003196477642497428\n",
      "train loss:0.00033573305310133556\n",
      "train loss:0.0008411141190425148\n",
      "train loss:0.00501948871754973\n",
      "train loss:0.001286478388257264\n",
      "train loss:0.0027995719944364657\n",
      "train loss:0.007346343872317279\n",
      "train loss:0.0013612355945154182\n",
      "train loss:0.016120672768846787\n",
      "train loss:0.004898103518803232\n",
      "train loss:0.013859671799537612\n",
      "train loss:0.006034192800601733\n",
      "train loss:0.003636529355233894\n",
      "train loss:0.0037111770869823063\n",
      "train loss:0.0005399240507796378\n",
      "train loss:0.0031056354995931414\n",
      "train loss:0.0008701464789140801\n",
      "train loss:0.011864200599834628\n",
      "train loss:0.003199241620972325\n",
      "train loss:0.0014236239007689821\n",
      "train loss:0.0026085068631696434\n",
      "train loss:0.0037967175854604373\n",
      "train loss:0.0020291362583319465\n",
      "train loss:0.02118649359493044\n",
      "train loss:0.0027022730805657154\n",
      "train loss:0.011601261694673758\n",
      "train loss:0.002747494338482646\n",
      "train loss:0.003060637157031658\n",
      "train loss:0.0009315364605018376\n",
      "train loss:0.0013636365582160598\n",
      "train loss:0.0018789083104101226\n",
      "train loss:0.008065023380508594\n",
      "train loss:0.006585031900624807\n",
      "train loss:0.004089369320852689\n",
      "train loss:0.0001590368805064944\n",
      "train loss:0.00464398359113014\n",
      "train loss:0.0033216938135111\n",
      "train loss:0.0015414605547881233\n",
      "train loss:0.0011182631264672665\n",
      "train loss:0.08212538228069147\n",
      "train loss:0.011380560384689827\n",
      "train loss:0.008121820269591679\n",
      "train loss:0.0029641819186346364\n",
      "train loss:0.005134929736860151\n",
      "train loss:0.0012086800577847659\n",
      "train loss:0.0029645735210222855\n",
      "train loss:0.023776712158152195\n",
      "train loss:0.006360693070514463\n",
      "train loss:0.00810299003381329\n",
      "train loss:0.001026177161098\n",
      "train loss:0.0004166175440725733\n",
      "train loss:0.0018814140407437216\n",
      "train loss:0.010255290101645038\n",
      "train loss:0.0044588285895261\n",
      "train loss:0.007750055607373034\n",
      "train loss:0.029341876058302165\n",
      "train loss:0.008007647888524944\n",
      "train loss:0.001706555822587788\n",
      "train loss:0.001080019348324078\n",
      "train loss:0.006656989596375193\n",
      "train loss:0.00316202072532528\n",
      "train loss:0.015040106424547646\n",
      "train loss:0.002572305347558202\n",
      "train loss:0.002803551495740739\n",
      "train loss:0.000543488159999902\n",
      "train loss:0.0010655242026713\n",
      "train loss:0.006498451565396485\n",
      "train loss:0.007773873021287666\n",
      "train loss:0.03788285463381941\n",
      "train loss:0.025930917769986392\n",
      "train loss:0.0057970954970544145\n",
      "train loss:0.000719793093642034\n",
      "train loss:0.0004694686683232898\n",
      "train loss:0.0019110674479325513\n",
      "train loss:0.026938168952109338\n",
      "train loss:0.004595595073221329\n",
      "train loss:0.01450598928096497\n",
      "train loss:0.010533852195535738\n",
      "train loss:0.0031704976735114276\n",
      "train loss:0.0020151245317733286\n",
      "train loss:0.014079757613326473\n",
      "train loss:0.006086147727336072\n",
      "train loss:0.0017770140315864756\n",
      "train loss:0.0008077717522312028\n",
      "train loss:0.025620179370097376\n",
      "train loss:0.0045475782534710055\n",
      "train loss:0.006661725138666307\n",
      "train loss:0.0035714047004681447\n",
      "train loss:0.0014098028788940608\n",
      "train loss:0.00919193183750596\n",
      "train loss:0.002633478341100901\n",
      "train loss:0.02326734245706609\n",
      "train loss:0.002617328461055904\n",
      "train loss:0.005355763997117369\n",
      "train loss:0.00541349775967755\n",
      "train loss:0.013862167262383585\n",
      "train loss:0.04309328182249707\n",
      "train loss:0.017282160855712336\n",
      "train loss:0.006854999602420507\n",
      "train loss:0.0184550877752609\n",
      "train loss:0.008097589758737584\n",
      "train loss:0.0012420566660846157\n",
      "train loss:0.008590279411664289\n",
      "train loss:0.0064873457809886915\n",
      "train loss:0.0016569826854991763\n",
      "train loss:0.00414319775715413\n",
      "train loss:0.0035518753362700733\n",
      "train loss:0.00591558325844328\n",
      "train loss:0.008586442984550418\n",
      "train loss:0.005874284976703132\n",
      "train loss:0.001164714487425698\n",
      "train loss:0.002040266123476768\n",
      "train loss:0.013452029522788034\n",
      "train loss:0.0011497047684989323\n",
      "train loss:0.0019175063504604836\n",
      "train loss:0.0024347470413101685\n",
      "train loss:0.003747101254041562\n",
      "train loss:0.003981913891076746\n",
      "train loss:0.00324455869553812\n",
      "train loss:0.010535136977531098\n",
      "train loss:0.01398252094123489\n",
      "train loss:0.0049598948772972\n",
      "train loss:0.017943805323110688\n",
      "train loss:0.009460096113789715\n",
      "train loss:0.013065885361706102\n",
      "train loss:0.013616130538517578\n",
      "train loss:0.0019750569543975052\n",
      "train loss:0.0047463881117743465\n",
      "train loss:0.005456853152683968\n",
      "train loss:0.002627949101131394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00223908621896084\n",
      "train loss:0.001889010579523704\n",
      "train loss:0.0035182072091188886\n",
      "train loss:0.011700270679138695\n",
      "train loss:0.0038859626517343967\n",
      "train loss:0.0037119626918303205\n",
      "train loss:0.003570967663906823\n",
      "train loss:0.0003747729768559931\n",
      "train loss:0.0014881914725377796\n",
      "train loss:0.0013290809535209372\n",
      "train loss:0.0029138030665637566\n",
      "train loss:0.0013389591598979606\n",
      "train loss:0.004198703237589114\n",
      "train loss:0.00045506288535144456\n",
      "train loss:0.004089196120932368\n",
      "train loss:0.004343081106427625\n",
      "train loss:0.04760391265946248\n",
      "train loss:0.0033538279989379126\n",
      "train loss:0.02736124704823823\n",
      "train loss:0.00659279117279667\n",
      "train loss:0.00630899644673098\n",
      "train loss:0.015052625415470889\n",
      "train loss:0.0015114586276794681\n",
      "train loss:0.008017616134857347\n",
      "train loss:0.010467715976656959\n",
      "train loss:0.009072270142553527\n",
      "train loss:0.007834022187636742\n",
      "train loss:0.0066334105089807275\n",
      "train loss:0.005350258632561352\n",
      "train loss:0.008044060523419341\n",
      "train loss:0.0004944850338128221\n",
      "train loss:0.0003588091350468173\n",
      "train loss:0.0012627475396449217\n",
      "train loss:0.002829596242147044\n",
      "train loss:0.003454077706626202\n",
      "train loss:0.0002657804864516686\n",
      "train loss:0.002395599102100807\n",
      "train loss:0.0040617117065517485\n",
      "train loss:0.010488406440615265\n",
      "train loss:0.0005255425075179967\n",
      "train loss:0.004378395206245775\n",
      "train loss:0.015895301610079147\n",
      "train loss:0.0012751900846934058\n",
      "train loss:0.00795665992231414\n",
      "train loss:0.0034388812737418057\n",
      "train loss:0.004955720696089963\n",
      "train loss:0.0051254039025212935\n",
      "train loss:0.0010500996260321366\n",
      "train loss:0.007120082073322087\n",
      "train loss:0.006387537126938585\n",
      "train loss:0.011789551663148178\n",
      "train loss:0.001880529077437084\n",
      "train loss:0.00580818376905245\n",
      "train loss:0.018055316303104293\n",
      "train loss:0.0012375457331502394\n",
      "train loss:0.05323970725622431\n",
      "train loss:0.0006222088517082896\n",
      "train loss:0.000727487690058376\n",
      "train loss:0.0006568319578423027\n",
      "train loss:0.0019364085401419862\n",
      "train loss:0.001805438316736209\n",
      "train loss:0.0125341473931929\n",
      "train loss:0.0019337484730576053\n",
      "train loss:0.0006633081286726484\n",
      "train loss:0.002804929541378735\n",
      "train loss:0.004120396761320839\n",
      "train loss:0.002174473644718583\n",
      "train loss:0.002543358813411582\n",
      "train loss:0.0016362655635906822\n",
      "train loss:0.0028404294318445317\n",
      "train loss:0.0019984808860498927\n",
      "train loss:0.008765171355894939\n",
      "train loss:0.0012633494587467168\n",
      "train loss:0.00750097414456098\n",
      "train loss:0.005579057528758254\n",
      "train loss:0.006179188178844429\n",
      "train loss:0.006205432897062826\n",
      "train loss:0.000512382007609186\n",
      "train loss:0.0017016179274312179\n",
      "train loss:0.0007753908931951149\n",
      "train loss:0.008968158690318537\n",
      "train loss:0.006510886295231636\n",
      "train loss:0.0013404480520425501\n",
      "train loss:0.0022941641816405594\n",
      "train loss:0.0034995506960700216\n",
      "train loss:0.005444312554146101\n",
      "train loss:0.003126470758638214\n",
      "train loss:0.0010350147264614014\n",
      "train loss:0.003478085644647223\n",
      "train loss:0.04249649259633936\n",
      "train loss:0.0005601561848919907\n",
      "train loss:0.0010524499615051698\n",
      "train loss:0.005971215846575566\n",
      "train loss:0.0035799887048175655\n",
      "train loss:0.004217736351339219\n",
      "train loss:0.0056109765266255714\n",
      "train loss:0.0013315135186920163\n",
      "train loss:0.0021860439210381983\n",
      "train loss:0.005156960610130196\n",
      "train loss:0.00834189011834937\n",
      "train loss:0.0020690105350271016\n",
      "train loss:0.002102488555506323\n",
      "train loss:0.0016144063878473231\n",
      "train loss:0.006260463040622075\n",
      "train loss:0.000503375241206222\n",
      "train loss:0.004635052062457637\n",
      "train loss:0.0008257790522645843\n",
      "train loss:0.004994374562133552\n",
      "train loss:0.000590339818253821\n",
      "train loss:0.0003890779668858046\n",
      "train loss:0.0012937921035665676\n",
      "train loss:0.005964444024524436\n",
      "train loss:0.0005019291922258135\n",
      "train loss:0.0013505164099940276\n",
      "train loss:0.0013534056698132097\n",
      "train loss:0.0014050351104475237\n",
      "train loss:0.00036154422207587537\n",
      "train loss:0.0011987645843541967\n",
      "train loss:0.0008003811341473126\n",
      "train loss:0.0005159207475445562\n",
      "train loss:0.0002702809984140091\n",
      "train loss:0.0009921100814665508\n",
      "train loss:0.003631127508274395\n",
      "train loss:0.0025915740701958154\n",
      "train loss:0.005061271634986675\n",
      "train loss:0.0030801693164631046\n",
      "train loss:0.0020538506770683336\n",
      "train loss:0.006049328452737924\n",
      "train loss:0.013406699403934328\n",
      "train loss:0.0023649561045199973\n",
      "train loss:0.005592331673917475\n",
      "train loss:0.0011035831549553832\n",
      "train loss:0.0017710203250391825\n",
      "train loss:0.0032781610670307533\n",
      "train loss:0.003065267377209699\n",
      "train loss:0.001639269904319602\n",
      "train loss:0.0021157013063610904\n",
      "train loss:0.005273718510822459\n",
      "train loss:0.0006736459603912455\n",
      "train loss:0.004303827708992562\n",
      "train loss:0.011831150886136312\n",
      "train loss:0.0007398036742333474\n",
      "train loss:0.0017210602791888064\n",
      "train loss:0.0008607637927324037\n",
      "train loss:0.0007820796185951596\n",
      "train loss:0.0027394488534819854\n",
      "train loss:0.010366154910284744\n",
      "train loss:0.006821953292872582\n",
      "train loss:0.001161773421711286\n",
      "train loss:0.0030413374848132944\n",
      "train loss:0.0020867266251727756\n",
      "train loss:0.017891686464945652\n",
      "train loss:0.0010435587770288635\n",
      "train loss:0.00856067438678485\n",
      "train loss:0.002412926202413357\n",
      "train loss:0.003800824110944296\n",
      "train loss:0.003235002946753775\n",
      "train loss:0.003693628402965746\n",
      "train loss:0.0031112466340773013\n",
      "train loss:0.004072746956300343\n",
      "train loss:0.007659042855581982\n",
      "train loss:0.018710345524845014\n",
      "train loss:0.0044427478843331826\n",
      "train loss:0.0007784207560048222\n",
      "train loss:0.0006027678800433285\n",
      "train loss:0.0031981221594417062\n",
      "train loss:0.004966367023359073\n",
      "train loss:0.004986296986151223\n",
      "train loss:0.005773267603229631\n",
      "train loss:0.0032500930926645465\n",
      "train loss:0.001651647462250618\n",
      "train loss:0.007330160840068911\n",
      "train loss:0.0015694849184233882\n",
      "train loss:0.00412424664427816\n",
      "train loss:0.0021343975366164957\n",
      "train loss:0.0028858592262687387\n",
      "train loss:0.003177971676446811\n",
      "train loss:0.00905155711430153\n",
      "train loss:0.061990825670147416\n",
      "train loss:0.00265486659679678\n",
      "train loss:0.0015465603648344207\n",
      "train loss:0.004490969626832691\n",
      "train loss:0.015235999372466325\n",
      "train loss:0.002263741380227828\n",
      "train loss:0.004193299026259014\n",
      "train loss:0.0009164031329171414\n",
      "train loss:0.007603103071666736\n",
      "train loss:0.0002506938429518978\n",
      "train loss:0.006340355107053179\n",
      "=== epoch:13, train acc:0.994, test acc:0.987 ===\n",
      "train loss:0.001413569503564992\n",
      "train loss:0.007464786138860904\n",
      "train loss:0.0023880999549025545\n",
      "train loss:4.9148823563061034e-05\n",
      "train loss:0.009339992355825229\n",
      "train loss:0.0019244634333532348\n",
      "train loss:0.0009262138992364913\n",
      "train loss:0.006203990200713176\n",
      "train loss:0.0041142800614412355\n",
      "train loss:0.0024883469060179406\n",
      "train loss:0.0009259834486559389\n",
      "train loss:0.007833362405410082\n",
      "train loss:0.010429342553636695\n",
      "train loss:0.011142613308444732\n",
      "train loss:0.007211254760708257\n",
      "train loss:0.00386747506614789\n",
      "train loss:0.00038727506135179037\n",
      "train loss:0.0027502697901582674\n",
      "train loss:0.0015136114648902298\n",
      "train loss:0.01000534573253323\n",
      "train loss:0.007704839611565445\n",
      "train loss:0.010174640485492341\n",
      "train loss:0.005146446039752311\n",
      "train loss:0.000493606059355121\n",
      "train loss:0.0047531128626707555\n",
      "train loss:0.023617341206182595\n",
      "train loss:0.0023787127038805006\n",
      "train loss:0.002301049995110607\n",
      "train loss:0.0013022443831164098\n",
      "train loss:0.0054880901856631525\n",
      "train loss:0.00638630825137377\n",
      "train loss:0.0009987569785782984\n",
      "train loss:0.0033689481775554656\n",
      "train loss:0.010066198011437093\n",
      "train loss:0.0052921593372891205\n",
      "train loss:0.0024496021557955903\n",
      "train loss:0.03200629303212535\n",
      "train loss:0.001998680111549577\n",
      "train loss:0.0050735392094251675\n",
      "train loss:0.03687276849024992\n",
      "train loss:0.0063798161560834595\n",
      "train loss:0.0007431998598666453\n",
      "train loss:0.0009510344180677012\n",
      "train loss:0.0033834574637178895\n",
      "train loss:0.0003471657520802047\n",
      "train loss:0.001988428899313553\n",
      "train loss:0.0019263077977572781\n",
      "train loss:0.0021467325889716377\n",
      "train loss:0.01438171309848708\n",
      "train loss:0.0011376406258921383\n",
      "train loss:0.009983566816546531\n",
      "train loss:0.007653308573837445\n",
      "train loss:0.006575660517171218\n",
      "train loss:0.02524485473488022\n",
      "train loss:0.004951942591500586\n",
      "train loss:0.009330113689738424\n",
      "train loss:0.0005487803508430171\n",
      "train loss:0.035016193508910276\n",
      "train loss:0.0013193144975604107\n",
      "train loss:0.004979782595643255\n",
      "train loss:0.0041493344862441875\n",
      "train loss:0.002185541740293623\n",
      "train loss:0.006481652057886121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012081748066294706\n",
      "train loss:0.006854816363310162\n",
      "train loss:0.012531404119820084\n",
      "train loss:0.0052785108486584935\n",
      "train loss:0.0022567618370874423\n",
      "train loss:0.0017338652646433047\n",
      "train loss:0.0036025198725081996\n",
      "train loss:0.0014108128220027764\n",
      "train loss:0.009377987292398441\n",
      "train loss:0.0009030108531767532\n",
      "train loss:0.0034562577445062725\n",
      "train loss:0.00622043617421184\n",
      "train loss:0.015478514727444333\n",
      "train loss:0.010215776479195778\n",
      "train loss:0.007382539222832469\n",
      "train loss:0.002438004053599143\n",
      "train loss:0.0017655490275938132\n",
      "train loss:0.01774794522190057\n",
      "train loss:0.000970618816997837\n",
      "train loss:0.00375853814348055\n",
      "train loss:0.008535018035191085\n",
      "train loss:0.008090411904499006\n",
      "train loss:0.0035592087361177365\n",
      "train loss:0.0022814568674248033\n",
      "train loss:0.0008277203648699189\n",
      "train loss:0.0159861866119524\n",
      "train loss:0.0036616983479598525\n",
      "train loss:0.0006570310497123461\n",
      "train loss:0.004438337315822276\n",
      "train loss:0.0020363160886967906\n",
      "train loss:0.0021033253009218825\n",
      "train loss:0.0025345671358246004\n",
      "train loss:0.009405438409231862\n",
      "train loss:0.0015565233884941995\n",
      "train loss:0.006517995163736896\n",
      "train loss:0.0017203549752886895\n",
      "train loss:0.004174156277523863\n",
      "train loss:0.003558641553807884\n",
      "train loss:0.003335938082094019\n",
      "train loss:0.0007153088070979255\n",
      "train loss:0.06077486378015925\n",
      "train loss:0.01440531322238656\n",
      "train loss:0.0028566719696563147\n",
      "train loss:0.007804976820539321\n",
      "train loss:0.0025423030379430256\n",
      "train loss:0.015275731064682895\n",
      "train loss:0.0029976058797674503\n",
      "train loss:0.008170788707795045\n",
      "train loss:0.00044058962257302\n",
      "train loss:0.002818384765233834\n",
      "train loss:0.0014802095513940057\n",
      "train loss:0.0008343999215412391\n",
      "train loss:0.013881780736194015\n",
      "train loss:0.001211755466140499\n",
      "train loss:0.003275275849757516\n",
      "train loss:0.0062062133742785755\n",
      "train loss:0.00109065066865585\n",
      "train loss:0.020296746734271648\n",
      "train loss:0.00038451176127517786\n",
      "train loss:0.000379211132237557\n",
      "train loss:0.014812845856079292\n",
      "train loss:0.0012686035346197943\n",
      "train loss:0.0009542121871984534\n",
      "train loss:0.014914367585575596\n",
      "train loss:0.014489470419172399\n",
      "train loss:0.004611058238721382\n",
      "train loss:0.0005258434358227657\n",
      "train loss:0.003256602046299499\n",
      "train loss:0.003117429595826522\n",
      "train loss:0.002181219990324046\n",
      "train loss:0.0017236196267951848\n",
      "train loss:0.005433273136592661\n",
      "train loss:0.16036814204455233\n",
      "train loss:0.004539716851289505\n",
      "train loss:0.004537363713806027\n",
      "train loss:0.007050121031447678\n",
      "train loss:0.02294391080784656\n",
      "train loss:0.00021404083140131862\n",
      "train loss:0.0025369373483699695\n",
      "train loss:0.008450784788655371\n",
      "train loss:0.004803991305193071\n",
      "train loss:0.0005736811504592669\n",
      "train loss:0.0556428396811293\n",
      "train loss:0.01116669848486167\n",
      "train loss:0.004122833586097976\n",
      "train loss:0.004213912757711472\n",
      "train loss:0.004134757841384712\n",
      "train loss:0.0008754664342572719\n",
      "train loss:0.0006683674221381291\n",
      "train loss:0.002607572085808593\n",
      "train loss:0.009722128421218244\n",
      "train loss:0.005531382575055785\n",
      "train loss:0.003032956632718191\n",
      "train loss:0.004664870246263575\n",
      "train loss:0.002377790090173588\n",
      "train loss:0.002045589551468567\n",
      "train loss:0.0018238979000510327\n",
      "train loss:0.026952771379209914\n",
      "train loss:0.006014789973949028\n",
      "train loss:0.001023867240279874\n",
      "train loss:0.0029705102029005887\n",
      "train loss:0.006327173998658885\n",
      "train loss:0.002780860774412539\n",
      "train loss:0.0020518142040147663\n",
      "train loss:0.0020439067109425646\n",
      "train loss:0.0052154401540838\n",
      "train loss:0.0006179698092014882\n",
      "train loss:0.0019700005471180197\n",
      "train loss:0.00027887572490064064\n",
      "train loss:0.00922407422348825\n",
      "train loss:0.00017333361813536293\n",
      "train loss:0.0022247316483316347\n",
      "train loss:0.004340601263664024\n",
      "train loss:0.005204769387635919\n",
      "train loss:0.0013225709378745262\n",
      "train loss:0.0007473035319730495\n",
      "train loss:0.0013384722300283944\n",
      "train loss:0.03092257534217738\n",
      "train loss:0.002980635001711993\n",
      "train loss:0.0029006187178137305\n",
      "train loss:0.0030949467269651737\n",
      "train loss:0.0069517968929937255\n",
      "train loss:0.0019135436001597144\n",
      "train loss:0.001442803060340606\n",
      "train loss:0.004287960612487931\n",
      "train loss:0.000628878125597515\n",
      "train loss:0.003587210902649005\n",
      "train loss:0.014973278146127634\n",
      "train loss:0.0028932266191323613\n",
      "train loss:0.005320340544058092\n",
      "train loss:0.00117502939365198\n",
      "train loss:0.0005786379807893072\n",
      "train loss:0.0016374475203415183\n",
      "train loss:0.0022060354139963236\n",
      "train loss:0.0022611671478560747\n",
      "train loss:0.009834205813218444\n",
      "train loss:0.0065083706479884176\n",
      "train loss:0.0012254983327103976\n",
      "train loss:0.008976320749763615\n",
      "train loss:0.002405093559937652\n",
      "train loss:0.005053459695213651\n",
      "train loss:0.004608884300772727\n",
      "train loss:0.0010278958830778635\n",
      "train loss:0.018003019153713835\n",
      "train loss:0.02328390087460897\n",
      "train loss:0.009036145933558082\n",
      "train loss:0.001571669445847213\n",
      "train loss:0.002402578716711957\n",
      "train loss:0.0007268579507607841\n",
      "train loss:0.0016625333610134345\n",
      "train loss:0.0025505464887204472\n",
      "train loss:0.0002440072073511336\n",
      "train loss:0.019348748707969047\n",
      "train loss:0.005242969798324484\n",
      "train loss:0.006438455688086151\n",
      "train loss:0.0022003117032656956\n",
      "train loss:0.0015544557701995692\n",
      "train loss:0.0008709768594359253\n",
      "train loss:0.008273515561581101\n",
      "train loss:0.0010865167858114554\n",
      "train loss:0.0011343730909795346\n",
      "train loss:0.0015629253046016058\n",
      "train loss:0.012494849523135962\n",
      "train loss:0.0021086152714614244\n",
      "train loss:0.001932660181473561\n",
      "train loss:0.032366732193964076\n",
      "train loss:0.002762449239766792\n",
      "train loss:0.00043441188522004505\n",
      "train loss:0.0008362799279018277\n",
      "train loss:0.0004977124181352289\n",
      "train loss:0.0006674410115242825\n",
      "train loss:0.0047355093938352836\n",
      "train loss:0.002393681205519951\n",
      "train loss:0.004282081141989255\n",
      "train loss:0.0005236161086210824\n",
      "train loss:0.0016184266263309882\n",
      "train loss:0.0005667795159245515\n",
      "train loss:0.0011426185052142738\n",
      "train loss:0.0027588553357845032\n",
      "train loss:0.0013348602733841426\n",
      "train loss:0.000901287595001516\n",
      "train loss:0.00012291191063575706\n",
      "train loss:0.0017448219474683166\n",
      "train loss:0.004078129497551156\n",
      "train loss:0.002613692608882396\n",
      "train loss:0.008970497377422178\n",
      "train loss:0.0038497752942908327\n",
      "train loss:0.0005611793201169905\n",
      "train loss:0.01198833372192968\n",
      "train loss:0.0020728985067212293\n",
      "train loss:0.0002008465836386115\n",
      "train loss:0.0006552402110463123\n",
      "train loss:0.00025768249145766164\n",
      "train loss:0.0012828815901837975\n",
      "train loss:0.012643671963963281\n",
      "train loss:0.0002931416091547906\n",
      "train loss:0.0038334256068328805\n",
      "train loss:0.0052539821184903945\n",
      "train loss:0.0006662985361007366\n",
      "train loss:0.0016026601655003232\n",
      "train loss:0.0019245514881759275\n",
      "train loss:0.007049867085448441\n",
      "train loss:0.00858475937007257\n",
      "train loss:0.001957714109831124\n",
      "train loss:0.006860842560455973\n",
      "train loss:0.0011521454709697038\n",
      "train loss:0.0006945226448946448\n",
      "train loss:0.006998976119964781\n",
      "train loss:0.0017298746433093914\n",
      "train loss:0.0046209769556966335\n",
      "train loss:0.0008527504165878\n",
      "train loss:0.0021049949232056255\n",
      "train loss:0.00026036300133705856\n",
      "train loss:0.010038429867638659\n",
      "train loss:0.006014757372115618\n",
      "train loss:0.0025449654380376068\n",
      "train loss:0.0010771429774584884\n",
      "train loss:0.000844576504998406\n",
      "train loss:0.0005759191488798123\n",
      "train loss:0.007763097036901263\n",
      "train loss:0.0008990441330593621\n",
      "train loss:0.0031635908585268256\n",
      "train loss:0.001427739094641506\n",
      "train loss:0.004039908051516893\n",
      "train loss:0.005250407480317845\n",
      "train loss:0.0006678285185233698\n",
      "train loss:0.003171822869944494\n",
      "train loss:0.002717662050378885\n",
      "train loss:0.002337480938776912\n",
      "train loss:0.009085982184051539\n",
      "train loss:0.0008603454355904331\n",
      "train loss:0.0007527378726064554\n",
      "train loss:0.004383308835779796\n",
      "train loss:0.006243670259251515\n",
      "train loss:0.002498690787177303\n",
      "train loss:0.001489724764128659\n",
      "train loss:0.0019251424436569008\n",
      "train loss:0.0011611758086687394\n",
      "train loss:0.001988516313605019\n",
      "train loss:0.0003833183724958837\n",
      "train loss:0.0037254279814694386\n",
      "train loss:0.0011858601211653598\n",
      "train loss:0.0012387416698329131\n",
      "train loss:0.0023950733561838673\n",
      "train loss:0.002766040273221734\n",
      "train loss:0.0007343158461570618\n",
      "train loss:0.003340802287638324\n",
      "train loss:0.009637532064031232\n",
      "train loss:0.0010864353802210657\n",
      "train loss:0.002811373356004268\n",
      "train loss:0.003925213691545772\n",
      "train loss:0.00174484034801096\n",
      "train loss:0.0004674617412290623\n",
      "train loss:0.0011630724736115601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0037620263579526835\n",
      "train loss:0.004006302936600417\n",
      "train loss:0.004337249251541276\n",
      "train loss:0.002537382371843503\n",
      "train loss:0.032429394646565246\n",
      "train loss:0.0002675187411741668\n",
      "train loss:0.0002492953747677613\n",
      "train loss:0.009032995885861662\n",
      "train loss:0.0019392593166618365\n",
      "train loss:0.004743541912158705\n",
      "train loss:0.002490121155113249\n",
      "train loss:0.0030358387574316087\n",
      "train loss:0.006454275149145681\n",
      "train loss:0.001293556878686045\n",
      "train loss:0.003179876935458377\n",
      "train loss:0.00044229087804336845\n",
      "train loss:0.0020113761847420867\n",
      "train loss:0.0008355176079954717\n",
      "train loss:0.0009637374069412438\n",
      "train loss:0.01123184966394302\n",
      "train loss:0.003951657530608315\n",
      "train loss:0.0011808363894952223\n",
      "train loss:0.0008223439194047263\n",
      "train loss:0.005518812089842938\n",
      "train loss:0.0019278347329056691\n",
      "train loss:0.0006686533902150637\n",
      "train loss:0.0008747567201137697\n",
      "train loss:0.0008506200475894165\n",
      "train loss:0.0014141108241716117\n",
      "train loss:0.00031566459384719934\n",
      "train loss:0.0011296218177468346\n",
      "train loss:0.0017295865882758408\n",
      "train loss:0.007803772358673069\n",
      "train loss:0.007090297728989209\n",
      "train loss:0.0022618288993177093\n",
      "train loss:0.001269157148356715\n",
      "train loss:0.004315589772513935\n",
      "train loss:0.0032443186601128333\n",
      "train loss:0.0026033902386559337\n",
      "train loss:0.00831361440148917\n",
      "train loss:0.001439787740821562\n",
      "train loss:0.002853659240370385\n",
      "train loss:0.001386542641630987\n",
      "train loss:0.006931273096528756\n",
      "train loss:0.0011668710528709644\n",
      "train loss:0.005626982718698135\n",
      "train loss:0.004637414718556722\n",
      "train loss:0.0012494559002185453\n",
      "train loss:0.00024026136893120858\n",
      "train loss:0.0005378030353925449\n",
      "train loss:0.0003422663570521302\n",
      "train loss:0.004326425902690598\n",
      "train loss:0.0009319872428854559\n",
      "train loss:0.0006100986084648179\n",
      "train loss:0.002842379210423547\n",
      "train loss:0.007326453045587052\n",
      "train loss:0.005598389820613827\n",
      "train loss:0.0008845869296987716\n",
      "train loss:0.005256847238132099\n",
      "train loss:0.0007355858263831143\n",
      "train loss:0.0011556347842678514\n",
      "train loss:0.009200201420713677\n",
      "train loss:0.00013663098052868746\n",
      "train loss:0.0012839663169726997\n",
      "train loss:0.0010397009141327118\n",
      "train loss:0.00020958948664858757\n",
      "train loss:0.004047882405281889\n",
      "train loss:0.004059930561459698\n",
      "train loss:0.0016274728724769217\n",
      "train loss:0.00034168014512819545\n",
      "train loss:0.0023048716782424973\n",
      "train loss:0.004288508451977571\n",
      "train loss:0.0005267564968018919\n",
      "train loss:0.0006884809694934014\n",
      "train loss:0.000550687825081815\n",
      "train loss:0.00335103029049207\n",
      "train loss:0.007744141748447904\n",
      "train loss:0.0019761176823487967\n",
      "train loss:0.016292147536188004\n",
      "train loss:0.0036648744963883075\n",
      "train loss:6.86745852903393e-05\n",
      "train loss:0.0018256394027371717\n",
      "train loss:9.113824900603295e-05\n",
      "train loss:0.0008803373593922148\n",
      "train loss:0.0006739613715376718\n",
      "train loss:0.0023743751158894016\n",
      "train loss:0.0008531172152111989\n",
      "train loss:0.0013956813391857081\n",
      "train loss:0.0007451921504836521\n",
      "train loss:0.0026632789385140202\n",
      "train loss:0.0010866789089831134\n",
      "train loss:0.0022133663947628696\n",
      "train loss:0.0002645631116966316\n",
      "train loss:0.002029227585959649\n",
      "train loss:0.012940983931852256\n",
      "train loss:0.0004218080978825809\n",
      "train loss:0.00306840922854664\n",
      "train loss:0.0010174430755570535\n",
      "train loss:0.005247378629634061\n",
      "train loss:0.0028701920245349983\n",
      "train loss:0.002124510369222458\n",
      "train loss:0.001058972425380743\n",
      "train loss:0.005868931795737096\n",
      "train loss:0.0007045568132759208\n",
      "train loss:0.001330385102089158\n",
      "train loss:0.0008634036035882162\n",
      "train loss:0.0005278074561448602\n",
      "train loss:0.007298685840528139\n",
      "train loss:0.001253349824079073\n",
      "train loss:0.0004764388174853563\n",
      "train loss:0.00046991891578589893\n",
      "train loss:0.0012023593087652784\n",
      "train loss:0.012219716372162893\n",
      "train loss:0.0008606329607420835\n",
      "train loss:0.004425446114303438\n",
      "train loss:0.0004568286778806087\n",
      "train loss:0.0026500167225728313\n",
      "train loss:0.006782633763672981\n",
      "train loss:0.007735022314121375\n",
      "train loss:0.0005014694539854671\n",
      "train loss:0.0011656484146600609\n",
      "train loss:0.0013202915995736836\n",
      "train loss:0.00446592209686648\n",
      "train loss:0.0017280354717648441\n",
      "train loss:0.003948138214331345\n",
      "train loss:0.006927431274213984\n",
      "train loss:0.0007296450071058711\n",
      "train loss:0.005465358014501173\n",
      "train loss:0.001132136689393778\n",
      "train loss:0.007858812203258948\n",
      "train loss:0.024464002502625502\n",
      "train loss:0.0016780086370539221\n",
      "train loss:0.007399074222492193\n",
      "train loss:0.00695473928988468\n",
      "train loss:0.0006268766094107868\n",
      "train loss:0.0011745780490240022\n",
      "train loss:0.006597892392067048\n",
      "train loss:0.00099224464020465\n",
      "train loss:0.0023243810285630442\n",
      "train loss:0.00019906386393260628\n",
      "train loss:0.004487270982291191\n",
      "train loss:0.0010154114222785892\n",
      "train loss:0.002608138775469126\n",
      "train loss:0.007934948020045091\n",
      "train loss:0.012318846406744023\n",
      "train loss:0.00383566726998936\n",
      "train loss:0.005311655475873339\n",
      "train loss:0.001552060783403896\n",
      "train loss:0.003949339287225578\n",
      "train loss:0.013650793409362993\n",
      "train loss:0.02574339391114416\n",
      "train loss:0.007251964545759886\n",
      "train loss:0.0025302626411747085\n",
      "train loss:0.0022450930989486757\n",
      "train loss:0.005901351402639191\n",
      "train loss:0.04798851049271564\n",
      "train loss:0.041553577253951667\n",
      "train loss:0.00024348214907876132\n",
      "train loss:0.001084898408229614\n",
      "train loss:0.0009022841708919138\n",
      "train loss:0.014030023445536798\n",
      "train loss:0.0005593003189489569\n",
      "train loss:0.07056238586571757\n",
      "train loss:0.046267481329941934\n",
      "train loss:0.002871877742760741\n",
      "train loss:0.0026188803966378043\n",
      "train loss:0.0014334750199417221\n",
      "train loss:0.018678518616294035\n",
      "train loss:0.03333807852199258\n",
      "train loss:0.024929939297163372\n",
      "train loss:0.011399555317609498\n",
      "train loss:0.003357321214217632\n",
      "train loss:0.0035284917738347887\n",
      "train loss:0.0018637000836129103\n",
      "train loss:0.029040720540423896\n",
      "train loss:0.002436336363000485\n",
      "train loss:0.0014640534753671433\n",
      "train loss:0.00048172995098185687\n",
      "train loss:0.0011506606367631125\n",
      "train loss:0.014666766482096923\n",
      "train loss:0.00666608702939806\n",
      "train loss:0.008575501958168674\n",
      "train loss:0.0016678430694532006\n",
      "train loss:0.002026886078722138\n",
      "train loss:0.0040622252708832456\n",
      "train loss:0.004230555278632989\n",
      "train loss:0.0016745842100409458\n",
      "train loss:0.000275351602482252\n",
      "train loss:0.007174365950914765\n",
      "train loss:0.0009401320363570443\n",
      "train loss:0.0036867176767278477\n",
      "train loss:0.02454858081283259\n",
      "train loss:0.003235004298381756\n",
      "train loss:0.0034418394165522813\n",
      "train loss:0.0002477360588427319\n",
      "train loss:0.0019420757135785339\n",
      "train loss:0.0018337296568955433\n",
      "train loss:0.0019399997303468088\n",
      "train loss:0.0018672354209376576\n",
      "train loss:0.00038359127068312486\n",
      "train loss:0.001945371182822083\n",
      "train loss:0.0008892642613659861\n",
      "train loss:0.0026308911917437647\n",
      "train loss:0.0013059332327469476\n",
      "train loss:0.00017737935375793662\n",
      "train loss:0.006322139477302705\n",
      "train loss:0.005381501802062069\n",
      "train loss:0.0025002240899376633\n",
      "train loss:0.0004251321623582671\n",
      "train loss:0.006397682686988236\n",
      "train loss:0.0036024317645024445\n",
      "train loss:0.011914415128149607\n",
      "train loss:0.0004560990600697517\n",
      "train loss:0.00045151363731112885\n",
      "train loss:0.002210105169224597\n",
      "train loss:0.004693351389409212\n",
      "train loss:0.0009451621021063088\n",
      "train loss:0.02519075498683146\n",
      "train loss:0.006070854637131406\n",
      "train loss:0.0029998751359737452\n",
      "train loss:0.0016768023704426135\n",
      "train loss:0.0011178291231374923\n",
      "train loss:0.005723491027881465\n",
      "train loss:0.00541696535479687\n",
      "train loss:0.03117343749103378\n",
      "train loss:0.012585323219964481\n",
      "train loss:0.0019294153433793279\n",
      "train loss:0.01889010729779986\n",
      "train loss:0.008676216254979604\n",
      "train loss:0.0017529715105304752\n",
      "train loss:0.006567267589216018\n",
      "train loss:0.001830744447592361\n",
      "train loss:0.004317188434716416\n",
      "train loss:0.004871302769138341\n",
      "train loss:0.00612503874190187\n",
      "train loss:0.0016302743189492205\n",
      "train loss:0.0027779432633990987\n",
      "train loss:0.004279724178098713\n",
      "train loss:0.006880469329386775\n",
      "train loss:0.004036147279547282\n",
      "train loss:0.0021079492233022747\n",
      "train loss:0.0016230800647817018\n",
      "train loss:0.0012605395798605562\n",
      "train loss:0.0005539390082468979\n",
      "train loss:0.0013347622060257641\n",
      "train loss:0.0019514882145985643\n",
      "train loss:0.0048191486130850615\n",
      "train loss:0.002076353654679213\n",
      "train loss:0.0010862678422761411\n",
      "train loss:0.0033397432399374033\n",
      "train loss:0.0014762763044505797\n",
      "train loss:0.00258901406158064\n",
      "train loss:0.001286066217340155\n",
      "train loss:0.007792596707850462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007179318278986567\n",
      "train loss:0.00028156534241715106\n",
      "train loss:0.0005922551470662226\n",
      "train loss:0.003315096604219635\n",
      "train loss:0.022260659469756243\n",
      "train loss:0.0023644095819344746\n",
      "train loss:0.0006664596857114397\n",
      "train loss:0.00012010406337751712\n",
      "train loss:0.0016220314641215744\n",
      "train loss:0.005082377505314903\n",
      "train loss:0.005009103829854046\n",
      "train loss:0.0004421692913650796\n",
      "train loss:0.0016670261747815695\n",
      "train loss:0.0008491211371811833\n",
      "train loss:0.0013812188130249905\n",
      "train loss:0.00014165910454835167\n",
      "train loss:0.004450367340305207\n",
      "train loss:0.0025523007692795185\n",
      "train loss:0.002983375047761284\n",
      "train loss:0.0015697394761316386\n",
      "train loss:0.0016760452167391756\n",
      "train loss:0.0015874035061133943\n",
      "train loss:0.0013655110264164483\n",
      "train loss:0.03278814723239156\n",
      "train loss:0.00019487298088436723\n",
      "train loss:0.0009968803062952547\n",
      "train loss:0.007713225830252291\n",
      "train loss:0.003936151890112975\n",
      "train loss:0.0003909670104104857\n",
      "=== epoch:14, train acc:0.996, test acc:0.988 ===\n",
      "train loss:0.010726787090674247\n",
      "train loss:0.0009525676087433989\n",
      "train loss:0.0006283326201410627\n",
      "train loss:0.00418570421124738\n",
      "train loss:0.0007303771549795764\n",
      "train loss:0.011504498428124002\n",
      "train loss:0.0013874192830585495\n",
      "train loss:0.004503310103546918\n",
      "train loss:0.0008604838771660055\n",
      "train loss:0.0005106047253650823\n",
      "train loss:0.00028168332014856756\n",
      "train loss:0.006997956440902985\n",
      "train loss:0.0025132828718536972\n",
      "train loss:0.002354123260578494\n",
      "train loss:0.0033831610889446606\n",
      "train loss:0.0004991070074803958\n",
      "train loss:0.002954036242396536\n",
      "train loss:0.0007299272438086978\n",
      "train loss:0.00231054128433309\n",
      "train loss:0.002235873247479546\n",
      "train loss:0.003257296983209576\n",
      "train loss:0.0005995608616261808\n",
      "train loss:0.0008710794688949138\n",
      "train loss:0.010784963128615342\n",
      "train loss:0.005292676584200204\n",
      "train loss:0.0024877895461087375\n",
      "train loss:0.0004399501249855864\n",
      "train loss:0.0027149017398872166\n",
      "train loss:0.0004707329142945156\n",
      "train loss:0.0017949095672502163\n",
      "train loss:0.007715990724253224\n",
      "train loss:0.0017920150432599628\n",
      "train loss:0.005148618658635961\n",
      "train loss:0.0005806473176537983\n",
      "train loss:0.0027813912168167822\n",
      "train loss:0.011218801382189152\n",
      "train loss:0.0024689909581844614\n",
      "train loss:0.0003479529671914104\n",
      "train loss:0.0006572625847843094\n",
      "train loss:0.0031646653601792264\n",
      "train loss:0.0031243827492363767\n",
      "train loss:0.0011421112852468885\n",
      "train loss:0.0003450341934183937\n",
      "train loss:0.0033070038200192155\n",
      "train loss:0.0031084827056399515\n",
      "train loss:0.0075157001712162505\n",
      "train loss:0.006695842030259905\n",
      "train loss:0.005799495485097552\n",
      "train loss:0.0009812981121365275\n",
      "train loss:0.000477013236845066\n",
      "train loss:0.0008635865792708247\n",
      "train loss:0.0007320944370602799\n",
      "train loss:0.004243586605666789\n",
      "train loss:0.0006794392974121329\n",
      "train loss:0.017912919715002397\n",
      "train loss:0.03902034585225393\n",
      "train loss:0.0013509990903529687\n",
      "train loss:0.00021389870195417883\n",
      "train loss:0.00149791412821315\n",
      "train loss:0.00470558580697868\n",
      "train loss:0.0006192284749473271\n",
      "train loss:0.019213009406414898\n",
      "train loss:0.0002790514382005574\n",
      "train loss:0.001727970974070285\n",
      "train loss:0.001144822532750834\n",
      "train loss:0.0006921154937295786\n",
      "train loss:0.0009942201033475164\n",
      "train loss:0.009070596086204722\n",
      "train loss:0.00430481313772656\n",
      "train loss:9.722543758003845e-05\n",
      "train loss:0.005580309788104475\n",
      "train loss:0.004266791203615621\n",
      "train loss:0.00370755112782745\n",
      "train loss:0.003205351395399802\n",
      "train loss:0.0009860003187773152\n",
      "train loss:0.004372107769485866\n",
      "train loss:0.018721946968405463\n",
      "train loss:0.0028414885305500415\n",
      "train loss:0.0024164455581576426\n",
      "train loss:0.0024650696127545765\n",
      "train loss:0.005397328181713603\n",
      "train loss:0.0012337196959307493\n",
      "train loss:0.015182220534853477\n",
      "train loss:0.00016746290137409405\n",
      "train loss:0.0012228827996063776\n",
      "train loss:0.006786420103673535\n",
      "train loss:0.0013191551329563634\n",
      "train loss:0.0023142235363305856\n",
      "train loss:0.045517034425482494\n",
      "train loss:0.0030178303716726813\n",
      "train loss:0.004946773791014334\n",
      "train loss:0.006591204734284967\n",
      "train loss:0.0022934515114656343\n",
      "train loss:0.00484078194542832\n",
      "train loss:0.00844574332082867\n",
      "train loss:0.0005939012561680751\n",
      "train loss:0.0009331285080377646\n",
      "train loss:0.0033608208497335336\n",
      "train loss:0.0017837417606052363\n",
      "train loss:0.015232224686969215\n",
      "train loss:0.0020889841135407175\n",
      "train loss:0.004665365195969496\n",
      "train loss:0.0008786314601023388\n",
      "train loss:0.0017858286183564454\n",
      "train loss:0.0022850639303007713\n",
      "train loss:0.0010698797189175355\n",
      "train loss:0.003479361343484206\n",
      "train loss:0.012781736981712834\n",
      "train loss:0.01989369254709937\n",
      "train loss:0.002947918804546757\n",
      "train loss:0.0011681083519191906\n",
      "train loss:0.0020805100092158263\n",
      "train loss:0.0011739499532831756\n",
      "train loss:0.0025593448413924725\n",
      "train loss:0.0048859258304280815\n",
      "train loss:0.0005529195324243895\n",
      "train loss:0.0004051625322867985\n",
      "train loss:0.0046943766358785\n",
      "train loss:0.0014733166880032853\n",
      "train loss:0.0024509212959243254\n",
      "train loss:0.0016131785890534437\n",
      "train loss:0.003269909674895689\n",
      "train loss:0.001399163377155544\n",
      "train loss:0.001169243321749631\n",
      "train loss:0.0010689333324039893\n",
      "train loss:0.029893894484918204\n",
      "train loss:0.0065764789264014635\n",
      "train loss:0.0018466536099795595\n",
      "train loss:0.002522419621831574\n",
      "train loss:0.009961548846674256\n",
      "train loss:0.001723586960328768\n",
      "train loss:0.0018622768581438235\n",
      "train loss:0.003323807890343913\n",
      "train loss:0.0019561189078201426\n",
      "train loss:0.0016073675588491585\n",
      "train loss:0.0069412197031440215\n",
      "train loss:0.0026708582651522577\n",
      "train loss:0.00024809291859625526\n",
      "train loss:0.0016704263164685584\n",
      "train loss:0.018962910113751646\n",
      "train loss:0.0024315144198599863\n",
      "train loss:0.001526882173507636\n",
      "train loss:0.01231493417593689\n",
      "train loss:0.009828446294210836\n",
      "train loss:0.0026155819238415684\n",
      "train loss:0.001592468534850519\n",
      "train loss:0.0014571888767840673\n",
      "train loss:0.003973049235113011\n",
      "train loss:0.0021628588498823925\n",
      "train loss:0.004262909023797085\n",
      "train loss:0.003799151106600855\n",
      "train loss:0.002184099213080658\n",
      "train loss:0.009486197014411842\n",
      "train loss:0.0014183858585859477\n",
      "train loss:0.0003404766650032845\n",
      "train loss:0.0007693836418175982\n",
      "train loss:0.0021469334131345593\n",
      "train loss:0.016800648279602846\n",
      "train loss:0.00046966167656581424\n",
      "train loss:0.0023705869226406297\n",
      "train loss:0.003151116736640094\n",
      "train loss:0.007325238774003291\n",
      "train loss:0.0030047609315100804\n",
      "train loss:0.0024916722006287665\n",
      "train loss:0.002471296382449826\n",
      "train loss:0.003051299218361481\n",
      "train loss:0.005050342580265261\n",
      "train loss:0.0019474093988582563\n",
      "train loss:0.008364841146886454\n",
      "train loss:0.00043144210888622456\n",
      "train loss:0.005103232858559993\n",
      "train loss:0.0004683384262838539\n",
      "train loss:0.004172884648050762\n",
      "train loss:0.003418111739391371\n",
      "train loss:0.0005829761375190481\n",
      "train loss:0.0026490812261934322\n",
      "train loss:0.0012184304071522793\n",
      "train loss:0.0028368481104334075\n",
      "train loss:0.002141888718027889\n",
      "train loss:0.003555590839942061\n",
      "train loss:0.0007797547009847241\n",
      "train loss:0.0007625119021002511\n",
      "train loss:0.0010133361711776225\n",
      "train loss:0.0002341864925361512\n",
      "train loss:0.0048892170357796895\n",
      "train loss:0.000814912192438696\n",
      "train loss:0.0008754932457133312\n",
      "train loss:0.0011006265100029586\n",
      "train loss:0.0014736261797731387\n",
      "train loss:0.014805392565285978\n",
      "train loss:0.0002826481022403899\n",
      "train loss:0.0028396636186680617\n",
      "train loss:0.000975275921820568\n",
      "train loss:0.003286557264024276\n",
      "train loss:0.003724689187322768\n",
      "train loss:0.004211739343421865\n",
      "train loss:0.005898271305614671\n",
      "train loss:0.003159524731483847\n",
      "train loss:0.004269639181663282\n",
      "train loss:0.0025414975169188335\n",
      "train loss:0.00042481569742857343\n",
      "train loss:0.001673096560113673\n",
      "train loss:0.003983453619451454\n",
      "train loss:0.0005935778542339002\n",
      "train loss:0.0025580083280289994\n",
      "train loss:0.0003922589984925605\n",
      "train loss:0.00393211250889181\n",
      "train loss:0.002365078334044012\n",
      "train loss:0.001095485915052223\n",
      "train loss:0.0037613141344071048\n",
      "train loss:0.00013350423737209597\n",
      "train loss:0.0004707541378239716\n",
      "train loss:0.0003753497257671748\n",
      "train loss:0.000561460079009394\n",
      "train loss:0.0006196901761248613\n",
      "train loss:0.003812132400670152\n",
      "train loss:0.003633310539429644\n",
      "train loss:0.002107916520492855\n",
      "train loss:0.0003218813857224292\n",
      "train loss:0.004134414105229967\n",
      "train loss:0.0021411799994105335\n",
      "train loss:0.0015971321393866355\n",
      "train loss:0.0006983607064327135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009642607789724963\n",
      "train loss:0.0007576798439586211\n",
      "train loss:0.005149856219349741\n",
      "train loss:0.0003736374701484666\n",
      "train loss:0.0007673215928097878\n",
      "train loss:0.00037703580206105555\n",
      "train loss:0.00261432422587096\n",
      "train loss:0.0008531669202097347\n",
      "train loss:0.0022672511020326524\n",
      "train loss:0.0015282367164005971\n",
      "train loss:0.00041028834838135564\n",
      "train loss:0.003958488812978853\n",
      "train loss:0.0055430508687242495\n",
      "train loss:0.003205166732982311\n",
      "train loss:0.0012544803472926103\n",
      "train loss:0.0019995434520933054\n",
      "train loss:0.0016572123340631293\n",
      "train loss:0.01594902433177918\n",
      "train loss:0.02362367583293905\n",
      "train loss:0.00015247928257527065\n",
      "train loss:0.0010874229559745656\n",
      "train loss:0.0006229814735596313\n",
      "train loss:0.0006350995940027631\n",
      "train loss:0.00293741423897044\n",
      "train loss:0.00016923979635150106\n",
      "train loss:0.002425426557113494\n",
      "train loss:0.0008691083623655091\n",
      "train loss:0.0012528121485131474\n",
      "train loss:0.01175095339668674\n",
      "train loss:0.0012935470392570266\n",
      "train loss:0.00396665373457791\n",
      "train loss:0.004834459950522903\n",
      "train loss:0.0025694896374820007\n",
      "train loss:0.0022112188891772137\n",
      "train loss:0.0028421653101538963\n",
      "train loss:0.0006985731881362342\n",
      "train loss:0.0018355991094020508\n",
      "train loss:0.00881308596242068\n",
      "train loss:0.004816526755419176\n",
      "train loss:0.00946373685856686\n",
      "train loss:0.05406595649647738\n",
      "train loss:0.001880258932655488\n",
      "train loss:0.00047314333550769826\n",
      "train loss:0.011226816256915401\n",
      "train loss:0.0023677284631979153\n",
      "train loss:0.008441938154955107\n",
      "train loss:0.0036617347590068143\n",
      "train loss:0.01951482986839862\n",
      "train loss:0.0033942973864867247\n",
      "train loss:0.005731365562725814\n",
      "train loss:0.0038159633159483546\n",
      "train loss:0.00226656624380997\n",
      "train loss:0.0010789112944067753\n",
      "train loss:0.00021183255486554423\n",
      "train loss:0.0034520011779657083\n",
      "train loss:0.006773819835524149\n",
      "train loss:0.0006818222506155011\n",
      "train loss:0.0011511845977849181\n",
      "train loss:0.003162689160962807\n",
      "train loss:0.0007751981541021208\n",
      "train loss:0.007401769902660552\n",
      "train loss:0.0004951916856974744\n",
      "train loss:0.0006965135338601717\n",
      "train loss:0.0113909879127704\n",
      "train loss:0.01601989105170691\n",
      "train loss:0.003479468603629168\n",
      "train loss:0.001995544121139857\n",
      "train loss:0.0017759742572193414\n",
      "train loss:0.004970989280417085\n",
      "train loss:0.003320164899247704\n",
      "train loss:0.005035307131719469\n",
      "train loss:0.0028722528134266425\n",
      "train loss:0.003267330970824777\n",
      "train loss:0.006353399686011766\n",
      "train loss:0.010672188957544071\n",
      "train loss:0.002882523794142857\n",
      "train loss:0.001112065167245327\n",
      "train loss:0.00016002867017230472\n",
      "train loss:0.009365302206272894\n",
      "train loss:0.0013631320518696336\n",
      "train loss:0.0027270906732188823\n",
      "train loss:0.0004438213429906104\n",
      "train loss:0.0010602865868561263\n",
      "train loss:0.020099096382366878\n",
      "train loss:0.002068330099315368\n",
      "train loss:0.06648000270744678\n",
      "train loss:0.0018094731902523076\n",
      "train loss:0.003660362639436333\n",
      "train loss:0.00897222279869135\n",
      "train loss:0.0017787828380981293\n",
      "train loss:0.003029528871328918\n",
      "train loss:0.00415028177507827\n",
      "train loss:0.007266450071494585\n",
      "train loss:0.009919074271927807\n",
      "train loss:0.015207291214223484\n",
      "train loss:0.0003004621592748002\n",
      "train loss:0.0018913431739996853\n",
      "train loss:0.005119516448046732\n",
      "train loss:0.0014017139492588642\n",
      "train loss:0.0007450939994829611\n",
      "train loss:0.007353721917049005\n",
      "train loss:0.0008647299031386739\n",
      "train loss:0.009398491230779986\n",
      "train loss:0.000639251614738976\n",
      "train loss:0.0018245467912509827\n",
      "train loss:0.024157206299846558\n",
      "train loss:0.0018797163714543506\n",
      "train loss:0.0007467289665019886\n",
      "train loss:0.012438098357568135\n",
      "train loss:0.002844309986234128\n",
      "train loss:0.0013598090541526652\n",
      "train loss:0.002247696382383454\n",
      "train loss:0.002095392139004972\n",
      "train loss:0.0010326314087205216\n",
      "train loss:0.01183095726398085\n",
      "train loss:0.00027003081022317104\n",
      "train loss:0.0017401080189269683\n",
      "train loss:0.005905927871893452\n",
      "train loss:0.00318654700263702\n",
      "train loss:0.0005473644169350928\n",
      "train loss:0.009216826819245176\n",
      "train loss:0.011945465363919924\n",
      "train loss:0.0013960639011213096\n",
      "train loss:0.002235700676954919\n",
      "train loss:0.0003935794098472449\n",
      "train loss:0.0032882947694191328\n",
      "train loss:0.0017212971217052744\n",
      "train loss:0.0011293973612833286\n",
      "train loss:0.0009709472023529672\n",
      "train loss:0.009884357862839982\n",
      "train loss:0.0013949566610203857\n",
      "train loss:0.008719474608887364\n",
      "train loss:0.001186742329910237\n",
      "train loss:0.002829715823279807\n",
      "train loss:0.018703878959372963\n",
      "train loss:0.0022037641644788945\n",
      "train loss:0.15227989699770245\n",
      "train loss:0.002186373250141638\n",
      "train loss:0.00033718140534470494\n",
      "train loss:0.000607113680067198\n",
      "train loss:0.010456215185831398\n",
      "train loss:0.003606130249850947\n",
      "train loss:0.003504471203665482\n",
      "train loss:0.0005007125913378399\n",
      "train loss:0.005737601532126597\n",
      "train loss:0.001333844648021007\n",
      "train loss:0.037299865843850886\n",
      "train loss:0.004021346256043119\n",
      "train loss:0.002690499613668691\n",
      "train loss:0.0009928098366228525\n",
      "train loss:0.004836178884638432\n",
      "train loss:0.0036541293238151673\n",
      "train loss:0.0014408026526352472\n",
      "train loss:0.0023903687925564306\n",
      "train loss:0.0013022509335642502\n",
      "train loss:0.02481443064316653\n",
      "train loss:0.00475873249984214\n",
      "train loss:0.0004014003074258344\n",
      "train loss:0.024295451610789498\n",
      "train loss:0.0010554725499008302\n",
      "train loss:8.783701419144528e-05\n",
      "train loss:0.00208358816007324\n",
      "train loss:0.0037237898874480967\n",
      "train loss:0.006481301835821026\n",
      "train loss:0.0009200080109496135\n",
      "train loss:0.002012472694048623\n",
      "train loss:0.003212265739620836\n",
      "train loss:0.0006819028081060252\n",
      "train loss:0.0017680753858326814\n",
      "train loss:0.0007621162189897532\n",
      "train loss:0.0017736809613776055\n",
      "train loss:0.001040950439174952\n",
      "train loss:0.0029113088677898717\n",
      "train loss:0.0005872339964904787\n",
      "train loss:0.004311454481419886\n",
      "train loss:0.00020631716199959464\n",
      "train loss:0.00022251017226423303\n",
      "train loss:0.0007375451151938045\n",
      "train loss:0.001338135778119896\n",
      "train loss:0.005454865392469069\n",
      "train loss:0.0016259849132013284\n",
      "train loss:0.002120396080910314\n",
      "train loss:0.0036297290649427035\n",
      "train loss:0.004545784270450787\n",
      "train loss:0.0041665272562527575\n",
      "train loss:0.0001560461630233154\n",
      "train loss:0.0003991087903300011\n",
      "train loss:0.0015097899099015986\n",
      "train loss:0.0007487915455678777\n",
      "train loss:0.006473187737597011\n",
      "train loss:0.0020671686189543477\n",
      "train loss:0.0036956689889699594\n",
      "train loss:0.003059461617264555\n",
      "train loss:0.0029896018994325386\n",
      "train loss:0.0014695624530993547\n",
      "train loss:0.0004913767548344337\n",
      "train loss:0.0011032593817933906\n",
      "train loss:0.0029757050853771246\n",
      "train loss:0.00041053312196570065\n",
      "train loss:0.00038893738618425667\n",
      "train loss:0.0028570304869210035\n",
      "train loss:0.0007886149239346906\n",
      "train loss:0.0011035643924741988\n",
      "train loss:0.0010604261317065107\n",
      "train loss:0.000179589728236155\n",
      "train loss:0.001303206618886457\n",
      "train loss:0.00730841874861378\n",
      "train loss:0.0007250092066596242\n",
      "train loss:0.0018227362978719933\n",
      "train loss:0.004892232392403845\n",
      "train loss:0.00047158610964259656\n",
      "train loss:0.0006695251630876122\n",
      "train loss:0.001432776492027249\n",
      "train loss:0.001631148874668823\n",
      "train loss:0.02705697117278805\n",
      "train loss:0.004639030208598899\n",
      "train loss:0.0005346735779873685\n",
      "train loss:0.0007225421711605806\n",
      "train loss:0.00924062542620062\n",
      "train loss:0.0010024767423396422\n",
      "train loss:0.0011228438910020969\n",
      "train loss:0.0014546647337921005\n",
      "train loss:0.002161979930942008\n",
      "train loss:0.0003915508357934461\n",
      "train loss:0.001660219283916976\n",
      "train loss:0.00034267919402951265\n",
      "train loss:0.0074293533619673125\n",
      "train loss:0.002337102769167139\n",
      "train loss:9.005768544035489e-05\n",
      "train loss:0.0008101800430872873\n",
      "train loss:0.012950134327476746\n",
      "train loss:0.0021009416907820165\n",
      "train loss:0.0025048408383335414\n",
      "train loss:0.0037815261336635576\n",
      "train loss:0.0023022544915181423\n",
      "train loss:0.00011157366903725828\n",
      "train loss:0.0019824294412976967\n",
      "train loss:0.0016995938677604907\n",
      "train loss:0.019010408321819418\n",
      "train loss:0.00019391479916061502\n",
      "train loss:0.003030452039047843\n",
      "train loss:0.0013010206817471613\n",
      "train loss:0.0032826444299958683\n",
      "train loss:0.003570743663996321\n",
      "train loss:0.0014001948257915007\n",
      "train loss:0.0013183026882276536\n",
      "train loss:0.00025324535352440504\n",
      "train loss:0.004649010222748815\n",
      "train loss:0.002292483311989611\n",
      "train loss:0.0006622752387635645\n",
      "train loss:0.0013365355088620608\n",
      "train loss:0.005969633309024336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0037622549401103646\n",
      "train loss:0.004302636397129727\n",
      "train loss:0.0008356845727144229\n",
      "train loss:0.0016856894115977652\n",
      "train loss:0.0006509701795830048\n",
      "train loss:0.007365759574041113\n",
      "train loss:0.00046980517829264996\n",
      "train loss:0.001735075536870169\n",
      "train loss:0.0006003612114228287\n",
      "train loss:0.0006066381362469611\n",
      "train loss:0.0010469908565220144\n",
      "train loss:0.010901619869686052\n",
      "train loss:0.0039681586907001345\n",
      "train loss:0.009870178545503984\n",
      "train loss:0.00046958233042904504\n",
      "train loss:0.01711676518503766\n",
      "train loss:0.0018656256936093265\n",
      "train loss:0.0010476735465520806\n",
      "train loss:0.002958537520870193\n",
      "train loss:0.000980700773179733\n",
      "train loss:0.0011856284469833759\n",
      "train loss:0.0034622822350138236\n",
      "train loss:0.002111176463224815\n",
      "train loss:0.0011300538425672573\n",
      "train loss:0.011692098662716411\n",
      "train loss:0.004131038019958918\n",
      "train loss:0.0005362252723621111\n",
      "train loss:0.0020933513173681125\n",
      "train loss:7.671308469798476e-05\n",
      "train loss:0.004362674466261561\n",
      "train loss:0.0011092200835826284\n",
      "train loss:0.012564159519643847\n",
      "train loss:0.0004805255417212205\n",
      "train loss:0.00234200015198831\n",
      "train loss:0.005588257710628479\n",
      "train loss:0.001867042856003564\n",
      "train loss:0.0028695577409425387\n",
      "train loss:0.000537621817799299\n",
      "train loss:0.0037609226123423434\n",
      "train loss:0.007160921678409962\n",
      "train loss:0.0013629974700087482\n",
      "train loss:0.0008162999887518666\n",
      "train loss:0.0026962932530296933\n",
      "train loss:0.0009708802766361074\n",
      "train loss:0.00025851548585875033\n",
      "train loss:0.00516426961717539\n",
      "train loss:0.000763600932889608\n",
      "train loss:0.004400664751786141\n",
      "train loss:0.005660640644409512\n",
      "train loss:0.002195426744084867\n",
      "train loss:0.0035957350908640082\n",
      "train loss:0.0005604438035971634\n",
      "train loss:0.005339394891358964\n",
      "train loss:0.0042274832721527576\n",
      "train loss:0.00022148741188660192\n",
      "train loss:0.003924719446594529\n",
      "train loss:0.0001663230660252812\n",
      "train loss:0.002145903713312201\n",
      "train loss:0.004266201639554224\n",
      "train loss:0.005289490104114389\n",
      "train loss:0.0007015235371507001\n",
      "train loss:0.004077160842775601\n",
      "train loss:0.0009597671858576008\n",
      "train loss:0.003873812595311094\n",
      "train loss:0.026867820122506148\n",
      "train loss:0.0004793582619490385\n",
      "train loss:0.000821170243164602\n",
      "train loss:0.000955564344370679\n",
      "train loss:0.0006923224167915148\n",
      "train loss:0.0033390393047161545\n",
      "train loss:0.0009242368783240755\n",
      "train loss:0.0006392738136254067\n",
      "train loss:4.407134839650423e-05\n",
      "train loss:0.0005807727703066316\n",
      "train loss:0.0019331405617295627\n",
      "train loss:0.002439673600437621\n",
      "train loss:0.0007899802803150212\n",
      "train loss:0.0016789164072167522\n",
      "train loss:0.0018270325986046922\n",
      "train loss:0.0017861547152559088\n",
      "train loss:0.0013111666457595315\n",
      "train loss:0.0027513466670239057\n",
      "train loss:6.492798330666845e-05\n",
      "train loss:0.005068147668879414\n",
      "train loss:7.494781365329037e-05\n",
      "train loss:0.001966260046958787\n",
      "train loss:0.0003516457109395447\n",
      "train loss:0.00118920759068557\n",
      "train loss:0.00038522568182458453\n",
      "train loss:0.029792841153397247\n",
      "train loss:0.001027426536358302\n",
      "train loss:0.003032943140390781\n",
      "train loss:0.008100013943215285\n",
      "train loss:0.0002611697611577524\n",
      "train loss:0.0004935668605759357\n",
      "train loss:0.0024520985988869416\n",
      "train loss:0.0007116063421079416\n",
      "train loss:0.0010009151944880522\n",
      "train loss:0.00020185612050282916\n",
      "train loss:0.0013204286593007076\n",
      "train loss:0.0017423298284619034\n",
      "train loss:0.0010867189992411722\n",
      "train loss:0.0013084769263212535\n",
      "train loss:0.0036139531510423787\n",
      "train loss:0.002837205351708119\n",
      "train loss:0.007321568899655835\n",
      "train loss:0.006358556055550402\n",
      "train loss:0.0006882297239892936\n",
      "train loss:0.0005271983107248351\n",
      "train loss:0.0022540148783452996\n",
      "train loss:0.00038107963809617414\n",
      "train loss:0.003288653617930715\n",
      "train loss:0.002456085208740085\n",
      "train loss:0.001174308052691993\n",
      "train loss:0.0019388596274605493\n",
      "train loss:0.001625543220471844\n",
      "train loss:0.0004125209373142276\n",
      "train loss:0.00038618804930287324\n",
      "train loss:0.0006926225135685482\n",
      "train loss:0.002723899447731509\n",
      "train loss:0.002809168193984648\n",
      "train loss:0.015706584037368528\n",
      "train loss:0.00644159064342056\n",
      "train loss:0.002993431815712132\n",
      "train loss:0.058260105737613505\n",
      "=== epoch:15, train acc:0.998, test acc:0.989 ===\n",
      "train loss:0.009142358265429118\n",
      "train loss:0.0009663204078364404\n",
      "train loss:0.0006168653561761472\n",
      "train loss:0.00557331059042542\n",
      "train loss:0.0013173627951194437\n",
      "train loss:0.0053842208552222605\n",
      "train loss:0.0040680686018330576\n",
      "train loss:0.001607515599985249\n",
      "train loss:0.003395101568967891\n",
      "train loss:0.0018259910475077997\n",
      "train loss:0.002983141616110296\n",
      "train loss:0.005014552617418807\n",
      "train loss:0.00012142269787268227\n",
      "train loss:0.0004062151182960339\n",
      "train loss:0.0030269608516113877\n",
      "train loss:0.00015076394472145847\n",
      "train loss:0.0001414897890463363\n",
      "train loss:0.0012860833154555483\n",
      "train loss:0.01859313073338499\n",
      "train loss:0.004141904957307612\n",
      "train loss:0.002472299559102998\n",
      "train loss:0.0024427484612593335\n",
      "train loss:0.03834978246987049\n",
      "train loss:0.001420282903040952\n",
      "train loss:0.0015217014576767687\n",
      "train loss:0.011374514289770701\n",
      "train loss:0.033590961760136324\n",
      "train loss:0.0005384166815510095\n",
      "train loss:0.0007654498320109435\n",
      "train loss:0.004452673794370169\n",
      "train loss:0.006541230747012615\n",
      "train loss:0.0008276414877712653\n",
      "train loss:0.007345529672374821\n",
      "train loss:0.0012509100785267682\n",
      "train loss:0.0001972020647444132\n",
      "train loss:0.0015298687376303771\n",
      "train loss:0.0021441737654330786\n",
      "train loss:0.0013377689932593507\n",
      "train loss:0.001111933778054276\n",
      "train loss:0.0034016215531393525\n",
      "train loss:0.001226138110893739\n",
      "train loss:0.0016559336941188467\n",
      "train loss:0.0013585728615655923\n",
      "train loss:0.0018771804662191043\n",
      "train loss:0.008131619274073713\n",
      "train loss:0.003909330228502945\n",
      "train loss:0.000453871069910365\n",
      "train loss:0.0003703774553525809\n",
      "train loss:0.0008136166614797832\n",
      "train loss:0.004815503815102782\n",
      "train loss:0.002465967571688059\n",
      "train loss:0.0005475444546246892\n",
      "train loss:0.006604335446133001\n",
      "train loss:0.002823112237828178\n",
      "train loss:0.0003166913968120316\n",
      "train loss:0.004487666266923477\n",
      "train loss:0.003988039759118072\n",
      "train loss:0.00018323436034259398\n",
      "train loss:0.001255666568234889\n",
      "train loss:0.0005754963895847429\n",
      "train loss:0.000504187549957299\n",
      "train loss:0.006201559021309361\n",
      "train loss:0.0011232197151821968\n",
      "train loss:0.000784038709301089\n",
      "train loss:0.00037027238168764215\n",
      "train loss:0.0003332379177399683\n",
      "train loss:0.000312267457827549\n",
      "train loss:0.0042836444696464845\n",
      "train loss:0.000173153189038078\n",
      "train loss:0.0006533354986089601\n",
      "train loss:0.0040051057444773835\n",
      "train loss:0.0017655196902822332\n",
      "train loss:0.0030247212980097555\n",
      "train loss:0.0009770851801953633\n",
      "train loss:0.0010797833209823875\n",
      "train loss:0.001140624774843521\n",
      "train loss:0.004943401548841092\n",
      "train loss:0.02432383650585237\n",
      "train loss:0.0007577200691836224\n",
      "train loss:0.0018792700089063287\n",
      "train loss:0.0033244419248443864\n",
      "train loss:0.007925605757166655\n",
      "train loss:0.0023069638611742426\n",
      "train loss:0.001543554700304648\n",
      "train loss:0.00437302628089754\n",
      "train loss:0.00042752189736593513\n",
      "train loss:0.00797359413152724\n",
      "train loss:0.0007184439491549617\n",
      "train loss:0.00019446755855898482\n",
      "train loss:0.0035897751197812694\n",
      "train loss:0.0005740897956245089\n",
      "train loss:0.00014905986030608358\n",
      "train loss:0.0005254245092808661\n",
      "train loss:0.000531584371909122\n",
      "train loss:0.0054622136255453035\n",
      "train loss:0.0005798047228722177\n",
      "train loss:0.00011186793807785371\n",
      "train loss:0.0010733176166607924\n",
      "train loss:0.0008264595284034475\n",
      "train loss:0.0009412533275191142\n",
      "train loss:0.00040062351338736736\n",
      "train loss:0.0019298758084128702\n",
      "train loss:0.002110138791901174\n",
      "train loss:0.0007867413940658782\n",
      "train loss:0.00813922052621977\n",
      "train loss:0.014139795770586057\n",
      "train loss:0.019906419462009703\n",
      "train loss:0.0003355709558010886\n",
      "train loss:0.023703629460865582\n",
      "train loss:0.0019631204796734325\n",
      "train loss:0.018041101191795167\n",
      "train loss:0.0013388571861313872\n",
      "train loss:0.003545226549316813\n",
      "train loss:0.000975681233264557\n",
      "train loss:0.003342534422874963\n",
      "train loss:0.007165876578801121\n",
      "train loss:0.011273451978398708\n",
      "train loss:0.007003146858526064\n",
      "train loss:0.0012481980527091078\n",
      "train loss:0.0008779445015505452\n",
      "train loss:0.0012777590754158013\n",
      "train loss:0.0009956119632812475\n",
      "train loss:0.006360478415525903\n",
      "train loss:0.003491636450603247\n",
      "train loss:0.004040412712193746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008621746493624037\n",
      "train loss:0.0008167932824845821\n",
      "train loss:0.004769960597899273\n",
      "train loss:0.007293680144671636\n",
      "train loss:0.00045233011108684467\n",
      "train loss:0.00015449187321890575\n",
      "train loss:0.0018046806655251204\n",
      "train loss:0.0023315275371414094\n",
      "train loss:0.008583089465918611\n",
      "train loss:0.002960139143051617\n",
      "train loss:0.0011169679079018027\n",
      "train loss:0.0272639480463084\n",
      "train loss:0.004855421330333735\n",
      "train loss:3.1054294479705965e-05\n",
      "train loss:0.012296836269153682\n",
      "train loss:0.005287232084935509\n",
      "train loss:0.003448108299138479\n",
      "train loss:0.004776228003299811\n",
      "train loss:0.004908300294946279\n",
      "train loss:0.0017675547325490906\n",
      "train loss:0.00834122599652321\n",
      "train loss:0.008920832040367026\n",
      "train loss:0.00413014510713925\n",
      "train loss:0.000809495749365955\n",
      "train loss:0.0021540322457954445\n",
      "train loss:0.00314820028406587\n",
      "train loss:0.007213944071114768\n",
      "train loss:0.0026903364362051273\n",
      "train loss:0.0007995521957735723\n",
      "train loss:0.0066163612168963415\n",
      "train loss:0.002187970892616586\n",
      "train loss:0.000846911773045373\n",
      "train loss:0.0007725443681730551\n",
      "train loss:0.0008899708048331319\n",
      "train loss:0.001915525529181706\n",
      "train loss:0.0012875539924350336\n",
      "train loss:0.014034840855195168\n",
      "train loss:0.002234178925645674\n",
      "train loss:0.004529242597465296\n",
      "train loss:0.0011561228805821561\n",
      "train loss:0.0009614862131152095\n",
      "train loss:0.009345150998986444\n",
      "train loss:0.0019733302758848316\n",
      "train loss:0.0012962688016294485\n",
      "train loss:0.0006587352025709388\n",
      "train loss:0.0005594340747056285\n",
      "train loss:0.007599852718921044\n",
      "train loss:0.0021933579192101598\n",
      "train loss:0.009863479830657232\n",
      "train loss:0.0019270586950515948\n",
      "train loss:0.0022868121650091826\n",
      "train loss:0.0004854110210737294\n",
      "train loss:0.003993327639807565\n",
      "train loss:0.0007464019058398873\n",
      "train loss:0.0008688123577577383\n",
      "train loss:0.0010054193314942364\n",
      "train loss:0.002003881553150931\n",
      "train loss:0.00036329011650460284\n",
      "train loss:0.04794858883646346\n",
      "train loss:0.017297578534458943\n",
      "train loss:0.0028152706825504492\n",
      "train loss:0.005091001286616378\n",
      "train loss:0.016715830822845248\n",
      "train loss:0.009640138421547685\n",
      "train loss:0.00289944914515795\n",
      "train loss:0.001516148166747787\n",
      "train loss:0.0021636004876190917\n",
      "train loss:0.0006149817263565188\n",
      "train loss:0.002173492536881679\n",
      "train loss:0.00035060732791976384\n",
      "train loss:0.003527338562073967\n",
      "train loss:0.0015065361572513506\n",
      "train loss:0.0019300918754009502\n",
      "train loss:0.004892857657282979\n",
      "train loss:0.005047767279706262\n",
      "train loss:0.0019012547461671966\n",
      "train loss:0.006633158310908602\n",
      "train loss:0.0024477226013799704\n",
      "train loss:0.0020409341995730056\n",
      "train loss:0.0011416831365961388\n",
      "train loss:0.0194712322727662\n",
      "train loss:0.000298534217037484\n",
      "train loss:0.0015370208784046674\n",
      "train loss:0.0016427442323698458\n",
      "train loss:0.0008688852764308552\n",
      "train loss:0.00033920703383385787\n",
      "train loss:0.0032013316548196464\n",
      "train loss:0.0018724802167613677\n",
      "train loss:0.0008591018331141442\n",
      "train loss:0.014423569647935959\n",
      "train loss:0.0013048185428332496\n",
      "train loss:4.2609593382812326e-05\n",
      "train loss:0.0012066970685914676\n",
      "train loss:0.004262983408584398\n",
      "train loss:0.00034763087492881134\n",
      "train loss:0.014444174512924759\n",
      "train loss:0.002733304999554213\n",
      "train loss:0.015252696117942393\n",
      "train loss:0.0028677696732200817\n",
      "train loss:0.0007897968274099276\n",
      "train loss:0.0006957598046419129\n",
      "train loss:8.918037708879051e-05\n",
      "train loss:0.0011798142609087956\n",
      "train loss:0.0010743613284145018\n",
      "train loss:4.267542581489499e-05\n",
      "train loss:0.0017541790195887198\n",
      "train loss:0.003204308471745161\n",
      "train loss:0.002025462361991533\n",
      "train loss:0.0032011076305753588\n",
      "train loss:0.001783845896210722\n",
      "train loss:0.01530235550920764\n",
      "train loss:0.014073452524403438\n",
      "train loss:0.005671698326817279\n",
      "train loss:0.002609332923869605\n",
      "train loss:0.003678304837697454\n",
      "train loss:0.0016059817516233751\n",
      "train loss:0.0005163889441462585\n",
      "train loss:0.0035636256857388966\n",
      "train loss:0.0011638107330557593\n",
      "train loss:0.0014256335706236104\n",
      "train loss:0.003120247344783203\n",
      "train loss:0.0005434442687128133\n",
      "train loss:0.0009639103526884303\n",
      "train loss:0.009760071483227694\n",
      "train loss:0.0035995492275060505\n",
      "train loss:0.005264088123162317\n",
      "train loss:0.0002407440197604492\n",
      "train loss:0.0011248445209829092\n",
      "train loss:0.003942805479331085\n",
      "train loss:0.001555939213856215\n",
      "train loss:0.00048327502489482516\n",
      "train loss:0.0015062155220244148\n",
      "train loss:0.00031384049825125223\n",
      "train loss:0.0003390098466421614\n",
      "train loss:0.0006552336822055033\n",
      "train loss:0.004391799936836108\n",
      "train loss:0.0008341141721389254\n",
      "train loss:0.005974130117412388\n",
      "train loss:0.0009152514986297642\n",
      "train loss:0.0015572488028645303\n",
      "train loss:0.000739456880761237\n",
      "train loss:0.0013196393982925182\n",
      "train loss:0.003995827798025344\n",
      "train loss:0.002261015734959185\n",
      "train loss:0.0007349254632471011\n",
      "train loss:0.0003325317298195024\n",
      "train loss:0.004343590634011438\n",
      "train loss:0.000851555186854967\n",
      "train loss:0.00011092430213809645\n",
      "train loss:0.0016838802307161452\n",
      "train loss:0.0001355482060153446\n",
      "train loss:0.00015850005491736745\n",
      "train loss:0.0039073767780474465\n",
      "train loss:0.002443095887239106\n",
      "train loss:0.0005452562875410446\n",
      "train loss:0.014622214111202871\n",
      "train loss:0.0003421103050801975\n",
      "train loss:0.007012142924856519\n",
      "train loss:0.004476100361153799\n",
      "train loss:0.011033306050819225\n",
      "train loss:0.001543652823882091\n",
      "train loss:0.003532877862164246\n",
      "train loss:0.0013509768952829084\n",
      "train loss:0.001406620250432199\n",
      "train loss:0.003429909604779622\n",
      "train loss:0.0029947860022864715\n",
      "train loss:0.0005559977199260361\n",
      "train loss:0.0010128807800466831\n",
      "train loss:0.0005244427371322093\n",
      "train loss:0.00224044874482078\n",
      "train loss:0.0008617741365230114\n",
      "train loss:0.008725297294689807\n",
      "train loss:0.0016361320524087219\n",
      "train loss:0.00010302844639990068\n",
      "train loss:0.0036562984924102867\n",
      "train loss:0.002521221346605822\n",
      "train loss:0.003052214993946346\n",
      "train loss:0.003810391003292481\n",
      "train loss:0.0009655050949857681\n",
      "train loss:0.0005814303869719845\n",
      "train loss:0.0012495180200011219\n",
      "train loss:0.0005048861786789651\n",
      "train loss:0.032394467941590045\n",
      "train loss:0.003617586240976905\n",
      "train loss:0.00345708823878709\n",
      "train loss:0.006042364621427092\n",
      "train loss:0.00329522652282581\n",
      "train loss:0.00671082610189001\n",
      "train loss:0.001030737567286767\n",
      "train loss:0.001717651627288807\n",
      "train loss:0.005227884739962061\n",
      "train loss:0.0019756652444390243\n",
      "train loss:0.0002953401099517843\n",
      "train loss:0.004113321415475765\n",
      "train loss:0.003919581106494403\n",
      "train loss:0.00147421416010243\n",
      "train loss:0.000416903133711116\n",
      "train loss:0.0013859764495816813\n",
      "train loss:0.0010229921968816465\n",
      "train loss:0.001386177364628186\n",
      "train loss:0.0026320333572012245\n",
      "train loss:0.016445904726831825\n",
      "train loss:0.005280777869121341\n",
      "train loss:0.0041096867690422695\n",
      "train loss:0.0052011784751859625\n",
      "train loss:0.0005770343280531447\n",
      "train loss:0.00250555991808806\n",
      "train loss:0.0006153918483767637\n",
      "train loss:0.0005370540730444682\n",
      "train loss:0.005822774511919867\n",
      "train loss:0.013383064350907994\n",
      "train loss:0.0013320967644031567\n",
      "train loss:0.005575298451526035\n",
      "train loss:0.003513477671063042\n",
      "train loss:0.0032259627120241564\n",
      "train loss:0.001149337107223259\n",
      "train loss:0.0014962765515341245\n",
      "train loss:0.0015039747508378625\n",
      "train loss:0.001090375420084686\n",
      "train loss:0.0034949700379286438\n",
      "train loss:0.0027227137171094685\n",
      "train loss:0.014022629417377992\n",
      "train loss:0.006969423276737191\n",
      "train loss:0.01601713539447214\n",
      "train loss:0.0028709090308667367\n",
      "train loss:0.0005635370413820491\n",
      "train loss:0.0017850311910621326\n",
      "train loss:0.0025414180307673363\n",
      "train loss:0.004766209440036076\n",
      "train loss:0.0004638691469064142\n",
      "train loss:0.00031897081906498035\n",
      "train loss:0.0016097773093188186\n",
      "train loss:0.0022893513892311636\n",
      "train loss:0.0033473355145817374\n",
      "train loss:0.002441083663508846\n",
      "train loss:0.0009566189364741357\n",
      "train loss:0.00276845784025777\n",
      "train loss:0.0008331240894440167\n",
      "train loss:0.0009458041481549478\n",
      "train loss:0.0075817435032220935\n",
      "train loss:0.004981075909989644\n",
      "train loss:0.004230129049403736\n",
      "train loss:0.008958588680404708\n",
      "train loss:0.004714586988638803\n",
      "train loss:0.004445024361225229\n",
      "train loss:0.0010811152879739612\n",
      "train loss:0.001265203765710879\n",
      "train loss:0.0016773183043513312\n",
      "train loss:0.003250965241114696\n",
      "train loss:0.0021887070212066977\n",
      "train loss:0.0026024186692188535\n",
      "train loss:0.00033897523810178686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007157104283817869\n",
      "train loss:0.0011404375800904332\n",
      "train loss:0.0015422402129523928\n",
      "train loss:0.004035058560452462\n",
      "train loss:0.0012833044918535885\n",
      "train loss:0.0015496614752581084\n",
      "train loss:0.000626781005467949\n",
      "train loss:0.00046400331971874854\n",
      "train loss:0.0009319898959051116\n",
      "train loss:0.00034428997189188014\n",
      "train loss:0.0021513221793927908\n",
      "train loss:0.01222446383541035\n",
      "train loss:0.003227624947069932\n",
      "train loss:0.0011925793371239846\n",
      "train loss:0.0006728939806172535\n",
      "train loss:0.0043444411415973945\n",
      "train loss:0.001810513766118045\n",
      "train loss:0.0014623626233121407\n",
      "train loss:0.0012096201610544003\n",
      "train loss:0.0026525758346078654\n",
      "train loss:0.03403580321072448\n",
      "train loss:0.0019757361150298317\n",
      "train loss:0.009508622617638305\n",
      "train loss:0.0005304939740862875\n",
      "train loss:0.0010093212436555336\n",
      "train loss:0.0008469011219835086\n",
      "train loss:0.0033916986019220923\n",
      "train loss:0.0009397397109161848\n",
      "train loss:0.009999401706976824\n",
      "train loss:0.00195321972065019\n",
      "train loss:0.0030982247611349416\n",
      "train loss:0.003050225400460355\n",
      "train loss:0.0010961927197721954\n",
      "train loss:0.0007120055383952369\n",
      "train loss:0.002883061841066466\n",
      "train loss:0.006753959038102011\n",
      "train loss:0.0011160297153779294\n",
      "train loss:0.0018829616616587838\n",
      "train loss:0.001115368088871975\n",
      "train loss:0.0033248695821031953\n",
      "train loss:0.0033045136938590295\n",
      "train loss:0.0008927020598752436\n",
      "train loss:0.0066520124134970895\n",
      "train loss:0.004448659101492776\n",
      "train loss:0.005585899115663913\n",
      "train loss:0.0002523475552413786\n",
      "train loss:0.0005329289490169522\n",
      "train loss:0.0005008696204923356\n",
      "train loss:0.0003706888958976353\n",
      "train loss:0.00028729307015539407\n",
      "train loss:0.005488493260834555\n",
      "train loss:0.004108984851799864\n",
      "train loss:0.003080969372708129\n",
      "train loss:0.0027354188525954126\n",
      "train loss:0.0012572608345731656\n",
      "train loss:0.0024813258416703232\n",
      "train loss:0.001745111292084707\n",
      "train loss:0.0020180443060494784\n",
      "train loss:0.003971282547467888\n",
      "train loss:0.0024204450194026984\n",
      "train loss:0.0015663553873341385\n",
      "train loss:0.003554495130988734\n",
      "train loss:0.003029007077075005\n",
      "train loss:0.005088730030378324\n",
      "train loss:0.0009713027584272861\n",
      "train loss:0.0013163507322167937\n",
      "train loss:0.004906823155421308\n",
      "train loss:0.004572949125023379\n",
      "train loss:0.003863765829634634\n",
      "train loss:0.0013747892801223489\n",
      "train loss:0.0032612811477719062\n",
      "train loss:0.0004421401357612575\n",
      "train loss:0.000652931884131847\n",
      "train loss:0.0017961032244471998\n",
      "train loss:0.012243704943478744\n",
      "train loss:0.0016645437836341989\n",
      "train loss:0.00016032226552681203\n",
      "train loss:0.0010446802627345874\n",
      "train loss:0.0033989976993881164\n",
      "train loss:0.002357990117468245\n",
      "train loss:0.00903735676761246\n",
      "train loss:0.0013239042849249954\n",
      "train loss:0.0020679119275215448\n",
      "train loss:0.0014197878320996204\n",
      "train loss:0.00078947739517219\n",
      "train loss:0.0014415797236956359\n",
      "train loss:0.00309596763349017\n",
      "train loss:0.0002798270949419431\n",
      "train loss:0.0006152295689974624\n",
      "train loss:0.0003677464112786127\n",
      "train loss:0.0004941584401573316\n",
      "train loss:0.0006757696353525083\n",
      "train loss:0.0068935094690976105\n",
      "train loss:0.00035642484212131017\n",
      "train loss:6.876825739304425e-05\n",
      "train loss:0.014739284041896823\n",
      "train loss:0.0011817823462026815\n",
      "train loss:0.00029125136886967436\n",
      "train loss:0.0011123554928820938\n",
      "train loss:0.00019528501825655717\n",
      "train loss:0.005462914419712203\n",
      "train loss:0.0007280061902512544\n",
      "train loss:0.0016858243597292993\n",
      "train loss:0.0006238579797863635\n",
      "train loss:0.00045518552608921715\n",
      "train loss:0.0025371772243244824\n",
      "train loss:0.003682103915635243\n",
      "train loss:0.008127889462958249\n",
      "train loss:0.002458509287947427\n",
      "train loss:0.0006200988878376163\n",
      "train loss:0.00041491805304607503\n",
      "train loss:0.004055896835123018\n",
      "train loss:0.0006232683380105717\n",
      "train loss:0.0028360216540362533\n",
      "train loss:0.003768849631078167\n",
      "train loss:0.006981836256731666\n",
      "train loss:0.05532036829384651\n",
      "train loss:0.0005961235128156939\n",
      "train loss:0.0002101914246296295\n",
      "train loss:0.0008249317957146829\n",
      "train loss:0.002556636983518589\n",
      "train loss:0.0051055754647698496\n",
      "train loss:0.0009872427999243292\n",
      "train loss:0.0018101611159851802\n",
      "train loss:0.003576682115298478\n",
      "train loss:0.0005849264527235538\n",
      "train loss:0.04163437278745648\n",
      "train loss:0.0015545546607170016\n",
      "train loss:0.0015802478301538284\n",
      "train loss:0.0010976717416854905\n",
      "train loss:0.0007383977263948489\n",
      "train loss:0.0006995178989892192\n",
      "train loss:0.0007932186304349391\n",
      "train loss:0.0042452044831572605\n",
      "train loss:0.007212320655918868\n",
      "train loss:0.00545082644839502\n",
      "train loss:0.004404735466983212\n",
      "train loss:0.001808259939541878\n",
      "train loss:0.002201379540187601\n",
      "train loss:0.0001737925942783191\n",
      "train loss:0.0001805822868595845\n",
      "train loss:0.006576267734198572\n",
      "train loss:0.0008489061319370787\n",
      "train loss:0.00038762060180641956\n",
      "train loss:0.002846075512896092\n",
      "train loss:0.0004592890687266393\n",
      "train loss:0.0022393459252969426\n",
      "train loss:0.010700482128951118\n",
      "train loss:0.004046798187072997\n",
      "train loss:0.0010596293227944948\n",
      "train loss:0.0007777135188128614\n",
      "train loss:0.000310776055190067\n",
      "train loss:0.0039283105022637895\n",
      "train loss:0.0023635038417958304\n",
      "train loss:0.0006519579356031308\n",
      "train loss:0.023478761070781066\n",
      "train loss:0.001148568590575711\n",
      "train loss:0.001694879562832062\n",
      "train loss:0.01161392013508998\n",
      "train loss:0.0007600198223372286\n",
      "train loss:0.002452574588598202\n",
      "train loss:0.002729355034227979\n",
      "train loss:0.0002561580890605047\n",
      "train loss:0.0006676533004483039\n",
      "train loss:0.004661146530998562\n",
      "train loss:0.00018472065952992273\n",
      "train loss:0.001535215718238111\n",
      "train loss:0.000781894886043286\n",
      "train loss:0.0010538835434021926\n",
      "train loss:0.0025198869698430824\n",
      "train loss:0.0018808867526205972\n",
      "train loss:0.0026321585792307358\n",
      "train loss:0.0009590705000488872\n",
      "train loss:0.0055671198272457785\n",
      "train loss:0.0008768782070047448\n",
      "train loss:0.0004340252942885864\n",
      "train loss:0.0029129933404900255\n",
      "train loss:0.001330535127989149\n",
      "train loss:0.0021664403121900845\n",
      "train loss:0.00026826535565878276\n",
      "train loss:0.0002648865380060191\n",
      "train loss:0.0012469304757292043\n",
      "train loss:0.0014451862214442338\n",
      "train loss:0.00032400940485329227\n",
      "train loss:0.002674732682444017\n",
      "train loss:0.0011788450074373276\n",
      "train loss:0.005391932494696341\n",
      "train loss:0.0002337142120465224\n",
      "train loss:0.0034794110549888685\n",
      "train loss:0.00045967685201529963\n",
      "train loss:0.0012272331861318789\n",
      "train loss:0.00011123987636319844\n",
      "train loss:0.0012324931549750986\n",
      "train loss:0.0037271796463038574\n",
      "train loss:0.001651909731955031\n",
      "train loss:0.003922385240549108\n",
      "train loss:0.008134497957557475\n",
      "train loss:0.0010839152033507013\n",
      "train loss:0.002027896080183319\n",
      "train loss:0.0019700008294309484\n",
      "train loss:0.0018903794287026096\n",
      "train loss:0.001015544870994769\n",
      "train loss:0.0016672577835852983\n",
      "train loss:0.0009626627794530418\n",
      "train loss:0.0019587409724119665\n",
      "train loss:0.007195097565828002\n",
      "train loss:0.00040839518141619157\n",
      "train loss:0.006727710499192396\n",
      "train loss:0.003194545033376758\n",
      "train loss:0.01915198014373659\n",
      "train loss:0.0021044035588169085\n",
      "train loss:0.006028640952363389\n",
      "train loss:0.003189181972131237\n",
      "train loss:0.003347515566473375\n",
      "train loss:0.0024639633413320737\n",
      "train loss:0.028147356697586542\n",
      "train loss:0.002557820430574451\n",
      "train loss:0.005064249585057544\n",
      "train loss:0.0073621875266651985\n",
      "train loss:0.003239775575923501\n",
      "train loss:0.010606387221675678\n",
      "train loss:0.005405755897618659\n",
      "train loss:0.009391396874349114\n",
      "=== epoch:16, train acc:0.992, test acc:0.985 ===\n",
      "train loss:0.001559152899235316\n",
      "train loss:0.0004238319757234349\n",
      "train loss:0.0023027927301931066\n",
      "train loss:0.007765764079037746\n",
      "train loss:0.007518674228073587\n",
      "train loss:0.003993507377624904\n",
      "train loss:0.0009292411451185266\n",
      "train loss:0.0011602697056878207\n",
      "train loss:0.006584238324082354\n",
      "train loss:0.0019990376943953563\n",
      "train loss:0.005998240484647084\n",
      "train loss:0.002471150742657009\n",
      "train loss:0.0010256127147096183\n",
      "train loss:0.00589711137897634\n",
      "train loss:0.005192423808396945\n",
      "train loss:0.0010046937127976326\n",
      "train loss:0.0035350793559634614\n",
      "train loss:0.004316730858933346\n",
      "train loss:0.002288732268764464\n",
      "train loss:0.016901793258679288\n",
      "train loss:0.12907927384321533\n",
      "train loss:0.009887310840052824\n",
      "train loss:0.004987244763116675\n",
      "train loss:0.0016088515203479298\n",
      "train loss:0.00010478225594453393\n",
      "train loss:0.010422013305181627\n",
      "train loss:0.002677165547674209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009454047128231034\n",
      "train loss:0.005309687519403393\n",
      "train loss:0.0006834894844021423\n",
      "train loss:0.004784384551752341\n",
      "train loss:0.011691655940378276\n",
      "train loss:0.003485335365616771\n",
      "train loss:0.00430164582470096\n",
      "train loss:0.03726177814527868\n",
      "train loss:0.010993357552998795\n",
      "train loss:0.0009430616161997444\n",
      "train loss:0.009502762199606161\n",
      "train loss:0.012686138014302219\n",
      "train loss:0.0008674757833514123\n",
      "train loss:0.001189574370302294\n",
      "train loss:0.004064314301819994\n",
      "train loss:0.0043990840362547416\n",
      "train loss:0.004145100813180129\n",
      "train loss:0.008436230093631397\n",
      "train loss:0.0003867198461573127\n",
      "train loss:0.008057703814445061\n",
      "train loss:0.0003067467960375077\n",
      "train loss:0.005505673920164117\n",
      "train loss:0.0009054122452095358\n",
      "train loss:0.0022770066483702735\n",
      "train loss:0.0021664157237442504\n",
      "train loss:0.020836019107471224\n",
      "train loss:0.014416196508670785\n",
      "train loss:0.0003480042209458012\n",
      "train loss:0.002258226997997492\n",
      "train loss:0.0017895336041106784\n",
      "train loss:0.01124397613999254\n",
      "train loss:0.003975719520030782\n",
      "train loss:0.02479087521665764\n",
      "train loss:0.00338054782387382\n",
      "train loss:0.008555963434309498\n",
      "train loss:0.012745232486823972\n",
      "train loss:0.0011359650352303268\n",
      "train loss:0.004720392526494859\n",
      "train loss:0.004672967565631345\n",
      "train loss:0.00017680261799658914\n",
      "train loss:0.0033227402074345247\n",
      "train loss:0.010545853146546536\n",
      "train loss:0.005456311574358798\n",
      "train loss:0.016673315325994163\n",
      "train loss:0.0037188969950084356\n",
      "train loss:0.018105689125290137\n",
      "train loss:0.0031604198262516507\n",
      "train loss:0.00759878430506674\n",
      "train loss:0.0027126508522954612\n",
      "train loss:0.005749765431819154\n",
      "train loss:0.002696029673319755\n",
      "train loss:0.0007369409182154103\n",
      "train loss:0.0006001911772384135\n",
      "train loss:0.000673484477508023\n",
      "train loss:0.0024463467062278647\n",
      "train loss:0.0029689804655031976\n",
      "train loss:0.0063694254967301125\n",
      "train loss:0.0020894564301822626\n",
      "train loss:0.0013305041666107807\n",
      "train loss:0.0010156830179975723\n",
      "train loss:0.0011673454559719496\n",
      "train loss:0.0034971866580500487\n",
      "train loss:0.0361852314806918\n",
      "train loss:0.0021357735825898194\n",
      "train loss:0.008383555558638883\n",
      "train loss:0.0043927128128268605\n",
      "train loss:0.0007081564511202646\n",
      "train loss:0.0006402942587330851\n",
      "train loss:0.027335240956063492\n",
      "train loss:0.0007153222391075614\n",
      "train loss:0.0024524493988448293\n",
      "train loss:0.004198309854495663\n",
      "train loss:0.011205836023522861\n",
      "train loss:0.0001572523881717904\n",
      "train loss:0.002567835531926071\n",
      "train loss:0.014653689600061907\n",
      "train loss:0.0017973635683788869\n",
      "train loss:0.0037075532550644545\n",
      "train loss:0.0040293517950301255\n",
      "train loss:0.005132137957462121\n",
      "train loss:0.0018753120501313247\n",
      "train loss:0.0066263450066989995\n",
      "train loss:0.006741055611701498\n",
      "train loss:0.0023104814742760716\n",
      "train loss:0.0009214574514686644\n",
      "train loss:0.014282220506043134\n",
      "train loss:0.0014498922974087\n",
      "train loss:0.0026198453517734433\n",
      "train loss:0.002434888641687445\n",
      "train loss:0.00025845142280595966\n",
      "train loss:0.003507158423821477\n",
      "train loss:0.0007270138058818813\n",
      "train loss:0.00019683214576943632\n",
      "train loss:0.010077499168655251\n",
      "train loss:0.0028220361917777586\n",
      "train loss:0.002442065726885721\n",
      "train loss:0.018676004561290354\n",
      "train loss:0.0006020351282651065\n",
      "train loss:0.00018593869927434234\n",
      "train loss:0.0043008274208273965\n",
      "train loss:0.0019006802906054079\n",
      "train loss:0.0009903897691172002\n",
      "train loss:0.0011149170860230754\n",
      "train loss:0.0017758887162380333\n",
      "train loss:0.01342419576635129\n",
      "train loss:0.0023993147743997913\n",
      "train loss:0.0004579735632487596\n",
      "train loss:0.005738934492995333\n",
      "train loss:0.0022440109499706983\n",
      "train loss:0.004402394788704416\n",
      "train loss:0.00573970153549146\n",
      "train loss:0.03353905138825972\n",
      "train loss:0.00721588340993843\n",
      "train loss:0.0008157640454891365\n",
      "train loss:0.0024868705767160074\n",
      "train loss:0.0054676329687457295\n",
      "train loss:0.002195362328412252\n",
      "train loss:0.03570108691372405\n",
      "train loss:0.0038875856248495005\n",
      "train loss:0.005069183530456486\n",
      "train loss:0.013735167137826765\n",
      "train loss:0.005725575477507544\n",
      "train loss:0.0017928249177986304\n",
      "train loss:0.0006648964411296338\n",
      "train loss:0.0005804500939223456\n",
      "train loss:0.0027414085927993026\n",
      "train loss:0.0007947877604773825\n",
      "train loss:0.005991491661353316\n",
      "train loss:0.012169746081313784\n",
      "train loss:0.006260925558668065\n",
      "train loss:0.0006314788733110333\n",
      "train loss:0.0032545163263657624\n",
      "train loss:0.0006117077303684355\n",
      "train loss:0.013682104926300393\n",
      "train loss:0.0018735984720152962\n",
      "train loss:0.003988311327109535\n",
      "train loss:0.002008191685899614\n",
      "train loss:0.0035346973886493534\n",
      "train loss:0.0009383998519923299\n",
      "train loss:0.0021705315284215217\n",
      "train loss:0.0002869655442606885\n",
      "train loss:0.0032355595790416725\n",
      "train loss:0.002127965140009416\n",
      "train loss:0.0006180776480897628\n",
      "train loss:0.003601710515231959\n",
      "train loss:0.002173976418906631\n",
      "train loss:0.0004543860084911094\n",
      "train loss:0.006376023198820671\n",
      "train loss:0.0016585050989692044\n",
      "train loss:0.0018787586868804305\n",
      "train loss:0.001742164598276034\n",
      "train loss:0.0011633669752980794\n",
      "train loss:0.0004962482450394622\n",
      "train loss:0.0004085320415722306\n",
      "train loss:0.0019839575459036298\n",
      "train loss:0.0010724413275905876\n",
      "train loss:0.0002975110300573669\n",
      "train loss:0.000648151514988896\n",
      "train loss:0.002993257432101469\n",
      "train loss:0.001945725829817848\n",
      "train loss:0.0005419710854992373\n",
      "train loss:0.002365453082362694\n",
      "train loss:0.0022555860449041567\n",
      "train loss:0.00018908769591918917\n",
      "train loss:0.0008438223045616848\n",
      "train loss:0.001345570883345626\n",
      "train loss:0.002632943686922032\n",
      "train loss:5.98714023979558e-05\n",
      "train loss:0.005938375135633163\n",
      "train loss:0.0019113895120633603\n",
      "train loss:0.0034000469998307693\n",
      "train loss:0.0007202906025989594\n",
      "train loss:0.01796119735544491\n",
      "train loss:0.00042392216763160193\n",
      "train loss:2.538898523539198e-05\n",
      "train loss:0.0012362091838989395\n",
      "train loss:0.0035962590397860717\n",
      "train loss:0.0006352514197009314\n",
      "train loss:0.0007200415202640903\n",
      "train loss:0.001275396836147869\n",
      "train loss:0.0009544488328686452\n",
      "train loss:0.00933719463439494\n",
      "train loss:0.0016690894057983143\n",
      "train loss:0.0038473620253496278\n",
      "train loss:0.0037926203629439856\n",
      "train loss:0.004128739692141136\n",
      "train loss:0.006646775837997549\n",
      "train loss:0.0021352835916234863\n",
      "train loss:0.0001401236237088996\n",
      "train loss:0.0029915237332723992\n",
      "train loss:0.0005657859964862594\n",
      "train loss:0.004396478959267042\n",
      "train loss:0.0020467895349621386\n",
      "train loss:0.005671447442762695\n",
      "train loss:0.019128135805810978\n",
      "train loss:0.004158983125832892\n",
      "train loss:0.009444225327379822\n",
      "train loss:0.0028123661549138783\n",
      "train loss:0.02324692559972444\n",
      "train loss:0.0005036451053378349\n",
      "train loss:0.03491273344304273\n",
      "train loss:0.003186527829877064\n",
      "train loss:0.003089360416534764\n",
      "train loss:0.0012385398524499317\n",
      "train loss:0.0015559777355726337\n",
      "train loss:0.0007674450427097531\n",
      "train loss:0.004571358425734773\n",
      "train loss:0.0022977724284590603\n",
      "train loss:0.002253937614955274\n",
      "train loss:0.0017723891309715343\n",
      "train loss:0.00042107091545840207\n",
      "train loss:0.004824369553506244\n",
      "train loss:0.005205012963852359\n",
      "train loss:0.003911591484908077\n",
      "train loss:0.003584161462445348\n",
      "train loss:0.0007291255138057913\n",
      "train loss:0.0013110409336739809\n",
      "train loss:3.244971095248961e-05\n",
      "train loss:0.0015613469378047795\n",
      "train loss:0.0017321640637832925\n",
      "train loss:0.00026209619817214977\n",
      "train loss:0.00012500019963535702\n",
      "train loss:0.006590461525922912\n",
      "train loss:0.0007846541404402325\n",
      "train loss:0.0027371067347125265\n",
      "train loss:0.0007207969596891217\n",
      "train loss:0.0003661492053450167\n",
      "train loss:0.0032641545558632925\n",
      "train loss:0.00014556347428311913\n",
      "train loss:0.0011805966108298935\n",
      "train loss:0.013343203043616367\n",
      "train loss:0.0007751832700726386\n",
      "train loss:0.00041041473680396393\n",
      "train loss:0.007891013952202406\n",
      "train loss:0.0021978513842863105\n",
      "train loss:0.0036144781555989304\n",
      "train loss:0.0037180466539595996\n",
      "train loss:0.00043146622106680194\n",
      "train loss:0.0008228821194099041\n",
      "train loss:0.0005885778091966454\n",
      "train loss:0.0006195354385536479\n",
      "train loss:0.008422364767855984\n",
      "train loss:0.00015465811706980438\n",
      "train loss:0.0014700979181171878\n",
      "train loss:0.004524323508547074\n",
      "train loss:0.0006235334430298558\n",
      "train loss:0.00048017653636091615\n",
      "train loss:0.0007058799192664329\n",
      "train loss:0.0056058908446719145\n",
      "train loss:0.001411080033111795\n",
      "train loss:0.0037298722042297867\n",
      "train loss:0.00030418890886286533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0029142401531135256\n",
      "train loss:0.00012061707380674811\n",
      "train loss:0.0005353792416620361\n",
      "train loss:0.0008438456489168397\n",
      "train loss:0.002810122101954247\n",
      "train loss:0.002897862602081645\n",
      "train loss:0.0011818356646510354\n",
      "train loss:0.0012533741628176088\n",
      "train loss:0.0173423325135428\n",
      "train loss:0.0004682599403484973\n",
      "train loss:5.4157261945315465e-05\n",
      "train loss:0.0007480073417299777\n",
      "train loss:0.0024069867576724667\n",
      "train loss:0.00022002433267903285\n",
      "train loss:0.0038022491546287358\n",
      "train loss:0.0017592724756761752\n",
      "train loss:0.0008338402341474232\n",
      "train loss:0.00015796874953827086\n",
      "train loss:0.012669380556940309\n",
      "train loss:0.0014855628592110345\n",
      "train loss:0.010573814584685155\n",
      "train loss:0.0012571019687079904\n",
      "train loss:0.0028893531821505836\n",
      "train loss:0.0021159942828890763\n",
      "train loss:0.0013280009858716681\n",
      "train loss:0.0007685340865771222\n",
      "train loss:0.004806566511903939\n",
      "train loss:0.003529358787329512\n",
      "train loss:0.001952173212988398\n",
      "train loss:0.0003187870774641981\n",
      "train loss:0.0023469428576116153\n",
      "train loss:0.003413885059042254\n",
      "train loss:0.0002738119796606162\n",
      "train loss:0.0017627941412469476\n",
      "train loss:0.003644540167053141\n",
      "train loss:0.001105293564807999\n",
      "train loss:0.001212532360264602\n",
      "train loss:0.022690580307599982\n",
      "train loss:0.0009742627200967412\n",
      "train loss:0.003510273142396698\n",
      "train loss:0.00018672456422905365\n",
      "train loss:0.007838683591480346\n",
      "train loss:0.00675941861047449\n",
      "train loss:0.0017586424421095126\n",
      "train loss:0.004128523040953248\n",
      "train loss:0.005277292195982928\n",
      "train loss:0.003911723811331677\n",
      "train loss:0.001042348151676023\n",
      "train loss:0.0012393137644765983\n",
      "train loss:0.00711598296458463\n",
      "train loss:0.00021646731145506638\n",
      "train loss:0.0007912771889553533\n",
      "train loss:0.0024656745204090866\n",
      "train loss:0.001206884392966575\n",
      "train loss:0.0023465273279082537\n",
      "train loss:0.00029656683240191536\n",
      "train loss:0.0018126925179195185\n",
      "train loss:0.0007593373086258583\n",
      "train loss:0.0004302208263379742\n",
      "train loss:0.00027009450635996954\n",
      "train loss:0.004657950312137567\n",
      "train loss:0.0008693243959132809\n",
      "train loss:0.0002782547539099758\n",
      "train loss:0.003915500879309112\n",
      "train loss:0.0036000827909415615\n",
      "train loss:0.001855784240866145\n",
      "train loss:0.0011341708037031302\n",
      "train loss:0.0030320521161452457\n",
      "train loss:0.0008182800767489719\n",
      "train loss:0.0011958367805205911\n",
      "train loss:0.00041747993502057226\n",
      "train loss:0.001175636711673722\n",
      "train loss:0.0026961110896091393\n",
      "train loss:0.004233277001197035\n",
      "train loss:0.0004867144269724969\n",
      "train loss:0.0026968530077561646\n",
      "train loss:0.002943183862852006\n",
      "train loss:0.0013259610032734664\n",
      "train loss:0.0004201651798405427\n",
      "train loss:0.006903436544818655\n",
      "train loss:0.0008301194186952166\n",
      "train loss:0.0002779218222387115\n",
      "train loss:0.0003148816773787104\n",
      "train loss:0.0067272600671367914\n",
      "train loss:0.003176196491671393\n",
      "train loss:0.0036704322193889115\n",
      "train loss:0.0014568752512818086\n",
      "train loss:0.00025792225179894904\n",
      "train loss:0.00021371915152381448\n",
      "train loss:5.363891145754814e-05\n",
      "train loss:0.0011226077066979776\n",
      "train loss:0.0013903041317473402\n",
      "train loss:0.0007650777347638326\n",
      "train loss:0.002307255685317135\n",
      "train loss:0.00026793229873795405\n",
      "train loss:0.0004127836709976182\n",
      "train loss:0.0024289026448516982\n",
      "train loss:0.00042419072162582205\n",
      "train loss:0.016271744276066515\n",
      "train loss:0.0030437661402236303\n",
      "train loss:0.004552425623903487\n",
      "train loss:0.0036261869038587986\n",
      "train loss:0.0005305204026133443\n",
      "train loss:0.000972460178211257\n",
      "train loss:0.00046816200366032047\n",
      "train loss:0.0034934647092983483\n",
      "train loss:0.0003553644195469073\n",
      "train loss:0.00019265781894830448\n",
      "train loss:0.007614921479865259\n",
      "train loss:0.007804143401339655\n",
      "train loss:0.0004228443772197799\n",
      "train loss:0.002073357094693846\n",
      "train loss:0.006093910850361082\n",
      "train loss:0.004646718026073942\n",
      "train loss:0.0013711671814205738\n",
      "train loss:0.002302262036945142\n",
      "train loss:0.0005380146286505014\n",
      "train loss:0.0030673673491246316\n",
      "train loss:0.0007078822569701837\n",
      "train loss:0.0036436607503017252\n",
      "train loss:0.0012302746578258185\n",
      "train loss:0.0012392622768275477\n",
      "train loss:0.0034944682680803146\n",
      "train loss:0.0008389643062393897\n",
      "train loss:9.491814188181347e-05\n",
      "train loss:0.0002141055699925072\n",
      "train loss:0.00047290243983525544\n",
      "train loss:0.00464723255220099\n",
      "train loss:0.001051815697303088\n",
      "train loss:0.0036007924960553316\n",
      "train loss:9.730582642619712e-05\n",
      "train loss:0.0026014107168261923\n",
      "train loss:0.016481159272690536\n",
      "train loss:0.0013009481199723013\n",
      "train loss:0.0076587578866302184\n",
      "train loss:0.003862535829202839\n",
      "train loss:0.004338576784473089\n",
      "train loss:0.0009635643596921663\n",
      "train loss:0.002841757478459322\n",
      "train loss:0.001524971503314363\n",
      "train loss:0.00035681515940366943\n",
      "train loss:0.000580913037113776\n",
      "train loss:0.00032858655812438857\n",
      "train loss:0.00368195379162021\n",
      "train loss:0.0023473937533964066\n",
      "train loss:0.0001877573285405261\n",
      "train loss:0.0005475526792058752\n",
      "train loss:0.0008110195593663103\n",
      "train loss:0.00012833816740772075\n",
      "train loss:9.203358837394638e-05\n",
      "train loss:0.003359923271354201\n",
      "train loss:0.0008255332799506695\n",
      "train loss:0.000781868620980813\n",
      "train loss:0.00023078588639036926\n",
      "train loss:0.0008286329154765026\n",
      "train loss:0.0006331687672018528\n",
      "train loss:0.001105702458478222\n",
      "train loss:0.0017761342402574294\n",
      "train loss:0.0019057889634392217\n",
      "train loss:5.7973646404737525e-05\n",
      "train loss:0.001210203082349335\n",
      "train loss:0.0012336020845005958\n",
      "train loss:0.0012061198288878699\n",
      "train loss:0.0001816419906491697\n",
      "train loss:0.00047134524300974695\n",
      "train loss:0.0022018248932436572\n",
      "train loss:0.0009234864841849823\n",
      "train loss:0.001875624588998998\n",
      "train loss:5.775500504735259e-05\n",
      "train loss:0.0003265633274869225\n",
      "train loss:0.007022013297821208\n",
      "train loss:0.0002604428031477702\n",
      "train loss:0.008204312874537744\n",
      "train loss:0.00022135196489531727\n",
      "train loss:0.00031064486961934073\n",
      "train loss:0.005553605971539658\n",
      "train loss:0.00752654891408044\n",
      "train loss:0.0019032454506145062\n",
      "train loss:0.0019798367215867613\n",
      "train loss:0.0017045051869244946\n",
      "train loss:0.0009279444876886721\n",
      "train loss:0.0003315079266398967\n",
      "train loss:0.001439198920035611\n",
      "train loss:0.0012237573649456512\n",
      "train loss:0.0026408533802970424\n",
      "train loss:0.000672338261220115\n",
      "train loss:0.0016880190804345828\n",
      "train loss:0.0010594818323367058\n",
      "train loss:0.0003345328588674464\n",
      "train loss:0.0029960060437615064\n",
      "train loss:0.00018799270052670628\n",
      "train loss:0.0007834207943705096\n",
      "train loss:0.000545909966178274\n",
      "train loss:0.0023174355022106395\n",
      "train loss:0.003165112533772452\n",
      "train loss:0.0013570626976349314\n",
      "train loss:9.515135152411775e-05\n",
      "train loss:0.00026428133384579\n",
      "train loss:0.003083290452394894\n",
      "train loss:0.0002363472602770511\n",
      "train loss:0.00031143156655651045\n",
      "train loss:7.940131383282664e-05\n",
      "train loss:0.005238155004201863\n",
      "train loss:0.0016204844187284978\n",
      "train loss:0.00024660216171455744\n",
      "train loss:0.0017714062471621424\n",
      "train loss:9.756561885689664e-05\n",
      "train loss:0.0005869266487448368\n",
      "train loss:0.0014813348481944031\n",
      "train loss:0.018844480460111727\n",
      "train loss:0.000320324052552729\n",
      "train loss:0.00033269254321547926\n",
      "train loss:0.0028406119612795215\n",
      "train loss:0.0026360209645982314\n",
      "train loss:0.0009770821465446358\n",
      "train loss:0.00032717231902537754\n",
      "train loss:4.651989332820547e-05\n",
      "train loss:0.0012176471812138801\n",
      "train loss:0.0007250864845989663\n",
      "train loss:0.0005877708047648315\n",
      "train loss:0.0009245660882077903\n",
      "train loss:6.991256487779558e-05\n",
      "train loss:3.6244179756091116e-05\n",
      "train loss:0.0021348323682891766\n",
      "train loss:0.002228063080500678\n",
      "train loss:0.001030570775889118\n",
      "train loss:0.012678230111440297\n",
      "train loss:0.0007273315900021202\n",
      "train loss:0.0016615610514048482\n",
      "train loss:0.0011273485037645876\n",
      "train loss:0.001867355958505412\n",
      "train loss:5.0811135469749044e-05\n",
      "train loss:0.005750762075644342\n",
      "train loss:0.00010945459350584184\n",
      "train loss:0.0016180299429180097\n",
      "train loss:0.0005015732052706843\n",
      "train loss:0.0002231512853149416\n",
      "train loss:0.00019827735860367165\n",
      "train loss:0.002234824811096091\n",
      "train loss:0.0029967693937700203\n",
      "train loss:0.0017830938919089958\n",
      "train loss:0.004612330679824988\n",
      "train loss:0.002143823158681075\n",
      "train loss:0.0026317467084278094\n",
      "train loss:4.4809656143139154e-05\n",
      "train loss:0.0006577133371273844\n",
      "train loss:0.0005685678939881682\n",
      "train loss:0.0010018697939185636\n",
      "train loss:0.0021446490208517637\n",
      "train loss:0.00018687882587293376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00023608408910910994\n",
      "train loss:0.00020643704550416398\n",
      "train loss:0.0006060220941859142\n",
      "train loss:0.0011933993018564918\n",
      "train loss:0.0006311238666518808\n",
      "train loss:0.00032047608027691043\n",
      "train loss:0.0014546007360077993\n",
      "train loss:0.0003018825934984351\n",
      "train loss:7.680050537593265e-05\n",
      "train loss:0.0029991024921498326\n",
      "train loss:0.004316380026245103\n",
      "train loss:0.0004107417277288562\n",
      "train loss:0.0007852370859844686\n",
      "train loss:0.0024707301662348306\n",
      "train loss:0.002595729981596493\n",
      "train loss:0.0011276436518529423\n",
      "train loss:0.0035430148526864502\n",
      "train loss:0.0023458716490079865\n",
      "train loss:0.000348848084686064\n",
      "train loss:0.0036488783957507654\n",
      "train loss:0.0017585027018570966\n",
      "train loss:0.0012728520023678985\n",
      "train loss:0.0008900160512675102\n",
      "train loss:0.0033117836347033207\n",
      "train loss:0.0007455872538726925\n",
      "train loss:0.00013315733930068262\n",
      "train loss:0.0011734212094005412\n",
      "train loss:0.000850662358525092\n",
      "train loss:0.0018713380009293035\n",
      "train loss:0.0013906435275926577\n",
      "train loss:0.0022012281149123725\n",
      "train loss:0.0005567990514173162\n",
      "train loss:0.0005000920721451646\n",
      "train loss:0.0004601705096809944\n",
      "train loss:0.0008067685266408691\n",
      "train loss:0.00156181717322156\n",
      "train loss:0.00024104279048979758\n",
      "train loss:0.0004034024551631378\n",
      "train loss:0.004774231447124238\n",
      "train loss:0.00043679546034468123\n",
      "train loss:9.883453565120851e-05\n",
      "train loss:0.0005081432067128612\n",
      "train loss:0.00026786485674109585\n",
      "train loss:0.00041858652200144444\n",
      "train loss:0.00016507846315481057\n",
      "train loss:0.0020508584023624862\n",
      "train loss:0.00036724969520898743\n",
      "train loss:0.00039773075625090635\n",
      "train loss:0.0002363738114250782\n",
      "train loss:0.0002159528313379312\n",
      "train loss:0.00020903111151535688\n",
      "train loss:0.00016760107643005052\n",
      "train loss:0.00021745710301718894\n",
      "train loss:0.007809732721547368\n",
      "train loss:0.00048294072323343094\n",
      "train loss:0.00040912662286879143\n",
      "train loss:0.00024938587591025586\n",
      "train loss:0.0001973843825523864\n",
      "train loss:0.006603201823746902\n",
      "train loss:0.00044565324477179366\n",
      "train loss:0.0011861884240393012\n",
      "train loss:0.0012677715752624536\n",
      "train loss:0.0004279795843438887\n",
      "train loss:0.0038733986289074037\n",
      "train loss:0.0002841597610513053\n",
      "train loss:0.024104110697828123\n",
      "train loss:0.0019210340127340639\n",
      "train loss:0.0015883589216299553\n",
      "train loss:0.0032367656137858346\n",
      "train loss:0.0023363591440022607\n",
      "train loss:0.010527946240027557\n",
      "=== epoch:17, train acc:1.0, test acc:0.983 ===\n",
      "train loss:0.003437889415800999\n",
      "train loss:0.0007641012001668292\n",
      "train loss:0.0003137643938849283\n",
      "train loss:0.0006481955475374936\n",
      "train loss:0.0022198312069231924\n",
      "train loss:0.006291145643662208\n",
      "train loss:0.004301913057842335\n",
      "train loss:0.00018877080113437693\n",
      "train loss:0.00015501849181843565\n",
      "train loss:0.004026566677218682\n",
      "train loss:0.0008725807289376388\n",
      "train loss:0.00017260942090184148\n",
      "train loss:0.0007655343231346043\n",
      "train loss:0.0007003256457853713\n",
      "train loss:0.0001986568871587976\n",
      "train loss:0.00014032550308800158\n",
      "train loss:0.0001992266218476625\n",
      "train loss:0.000703826866359063\n",
      "train loss:0.00279331140749072\n",
      "train loss:0.0002241088053838184\n",
      "train loss:0.0018613736119947155\n",
      "train loss:0.0001334214010954889\n",
      "train loss:0.001742753422729158\n",
      "train loss:0.0029278374285644916\n",
      "train loss:0.0004918122627033333\n",
      "train loss:0.0007098699412608647\n",
      "train loss:0.0008878730908464631\n",
      "train loss:0.001246545154697596\n",
      "train loss:0.006810008656728777\n",
      "train loss:0.002006651072586707\n",
      "train loss:0.0005646913324207025\n",
      "train loss:0.0036531322596981973\n",
      "train loss:0.00012201984902156437\n",
      "train loss:7.629283430436989e-05\n",
      "train loss:0.0004695972994304354\n",
      "train loss:0.004162616220838876\n",
      "train loss:0.002516207916787833\n",
      "train loss:0.000230343714667604\n",
      "train loss:0.0021538899517549903\n",
      "train loss:0.0042330095359830126\n",
      "train loss:0.0031040893903523203\n",
      "train loss:0.0022981389155490046\n",
      "train loss:0.0021185448916634718\n",
      "train loss:0.0030051569820475806\n",
      "train loss:0.00229482776714406\n",
      "train loss:0.0004918841379193218\n",
      "train loss:0.00045897763111529024\n",
      "train loss:0.0020839375475699097\n",
      "train loss:0.00020498338479035344\n",
      "train loss:0.00016455598188187963\n",
      "train loss:0.003339423192442823\n",
      "train loss:0.00017610595053641078\n",
      "train loss:0.00019945775475327734\n",
      "train loss:0.0010745550696118604\n",
      "train loss:0.00031717653247883925\n",
      "train loss:0.0021920325889594142\n",
      "train loss:0.0031089514536590847\n",
      "train loss:0.0006865918268508822\n",
      "train loss:0.002688516727559403\n",
      "train loss:0.0019062960393515579\n",
      "train loss:0.000382818935004007\n",
      "train loss:0.000967965103699612\n",
      "train loss:0.0011432620803873055\n",
      "train loss:0.0019714894961174855\n",
      "train loss:0.004035106057822623\n",
      "train loss:0.001413095181509053\n",
      "train loss:0.002556386828123344\n",
      "train loss:0.0012140566531503854\n",
      "train loss:0.004186595398632162\n",
      "train loss:0.0015753687888047244\n",
      "train loss:0.00016900117870537112\n",
      "train loss:0.0013569625851434293\n",
      "train loss:0.0011904722143043346\n",
      "train loss:0.0019432689152879378\n",
      "train loss:0.0011017203468793098\n",
      "train loss:0.0024428959644898322\n",
      "train loss:0.00055626975569578\n",
      "train loss:0.0004670935340339098\n",
      "train loss:0.00014215626157745094\n",
      "train loss:0.0009757865994255545\n",
      "train loss:0.004279126318395362\n",
      "train loss:0.000383769845375602\n",
      "train loss:0.0004817827543029517\n",
      "train loss:0.0016832090575736181\n",
      "train loss:0.0004393658488759205\n",
      "train loss:0.004190673850097587\n",
      "train loss:0.0017955517420047507\n",
      "train loss:7.338959488835721e-05\n",
      "train loss:0.0011336263845602153\n",
      "train loss:0.0016211373862478314\n",
      "train loss:0.0018535256055376397\n",
      "train loss:0.001259239614998772\n",
      "train loss:7.706248893254479e-05\n",
      "train loss:0.0005944502891772\n",
      "train loss:0.0002125110137640625\n",
      "train loss:0.0003306044841925813\n",
      "train loss:1.656321752998499e-05\n",
      "train loss:0.006663586359882115\n",
      "train loss:0.0011156072030473617\n",
      "train loss:0.0003972669152881616\n",
      "train loss:0.0020327773169382373\n",
      "train loss:3.197857628901431e-05\n",
      "train loss:0.00014415320746226953\n",
      "train loss:0.0037742093336611813\n",
      "train loss:6.120190214872955e-05\n",
      "train loss:0.0008293381969630192\n",
      "train loss:0.0010080483399706789\n",
      "train loss:0.0012834661440152657\n",
      "train loss:0.009776114235866593\n",
      "train loss:0.002528938478846674\n",
      "train loss:0.0007495683737814037\n",
      "train loss:0.0005246124441383604\n",
      "train loss:0.002676482403548306\n",
      "train loss:0.003448105565384567\n",
      "train loss:0.0006513202313768993\n",
      "train loss:0.0013241621476471994\n",
      "train loss:0.005158798259488024\n",
      "train loss:0.00040103717734662434\n",
      "train loss:0.001592562729182719\n",
      "train loss:0.002610579557888536\n",
      "train loss:0.00034998865415166396\n",
      "train loss:0.0008944815635865701\n",
      "train loss:0.0003346522818859298\n",
      "train loss:0.004963084001455145\n",
      "train loss:0.0008591585105971772\n",
      "train loss:0.0013676962253617677\n",
      "train loss:0.0010284564975138585\n",
      "train loss:0.0012399975423962202\n",
      "train loss:0.006788997268887153\n",
      "train loss:0.0011662615018313296\n",
      "train loss:7.296915098757812e-05\n",
      "train loss:0.0010149852327047868\n",
      "train loss:0.0017318431478950246\n",
      "train loss:0.0014651099892621646\n",
      "train loss:0.00223776067816918\n",
      "train loss:4.369292381238822e-05\n",
      "train loss:0.0011489896872331033\n",
      "train loss:0.00051409844538896\n",
      "train loss:0.0005034627605330007\n",
      "train loss:0.0027121526083989005\n",
      "train loss:0.0015005085958096991\n",
      "train loss:0.0007688997457980656\n",
      "train loss:0.0012269371012549387\n",
      "train loss:0.0014463844502389965\n",
      "train loss:0.0015784689824115633\n",
      "train loss:0.017158430272068505\n",
      "train loss:0.005114443597232146\n",
      "train loss:0.00019333327206046288\n",
      "train loss:0.0012364467673264138\n",
      "train loss:0.0007100492191175613\n",
      "train loss:0.001433435269006202\n",
      "train loss:0.0007786159635512713\n",
      "train loss:0.006469483705811365\n",
      "train loss:0.00041229353682042133\n",
      "train loss:0.003919352091539802\n",
      "train loss:0.0002846742642155533\n",
      "train loss:0.00271553108316778\n",
      "train loss:7.710618489187184e-05\n",
      "train loss:0.0005079808320413269\n",
      "train loss:0.004409542025370947\n",
      "train loss:0.00046326694714313496\n",
      "train loss:0.00040706106021551493\n",
      "train loss:0.0013497715618433748\n",
      "train loss:0.0020912970058627896\n",
      "train loss:0.002811385371767457\n",
      "train loss:0.0006468441807517692\n",
      "train loss:0.0005809479385200265\n",
      "train loss:0.0005757033357289229\n",
      "train loss:0.0004920357279813916\n",
      "train loss:0.001457551967971717\n",
      "train loss:0.0002223048598550803\n",
      "train loss:0.0064864502320217165\n",
      "train loss:0.0024897059915906096\n",
      "train loss:0.0011312940014633023\n",
      "train loss:0.0026231063700962033\n",
      "train loss:5.749408147960585e-05\n",
      "train loss:0.00029923651063871445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0019530177686285944\n",
      "train loss:0.0014593483283658172\n",
      "train loss:0.00032021637459223056\n",
      "train loss:0.00010227294517083481\n",
      "train loss:0.0009809062001173397\n",
      "train loss:0.0004581530103134639\n",
      "train loss:2.681528197464862e-05\n",
      "train loss:0.0006491537680180872\n",
      "train loss:0.0002021950872006981\n",
      "train loss:0.0008242655265754827\n",
      "train loss:0.001444443912866328\n",
      "train loss:0.0015410855227167557\n",
      "train loss:0.0012477306818712908\n",
      "train loss:0.0024970477625220634\n",
      "train loss:0.0025977107869466554\n",
      "train loss:0.0008746964610877742\n",
      "train loss:7.438143062902275e-05\n",
      "train loss:0.0029858702167973356\n",
      "train loss:0.0005994995763540153\n",
      "train loss:0.0007937728380144962\n",
      "train loss:0.0002916944137080967\n",
      "train loss:0.0022452447673505815\n",
      "train loss:0.0021050659193803845\n",
      "train loss:0.0003545129528480017\n",
      "train loss:0.001015940479323931\n",
      "train loss:0.0002892187166685065\n",
      "train loss:0.002413360034139693\n",
      "train loss:0.0026403846386157392\n",
      "train loss:0.003763170862355205\n",
      "train loss:0.00032420606733795103\n",
      "train loss:0.0006190896664697602\n",
      "train loss:9.240516566570332e-05\n",
      "train loss:0.00010603011771859889\n",
      "train loss:0.0007889965220187891\n",
      "train loss:0.004990827558814939\n",
      "train loss:0.00019262525632487843\n",
      "train loss:0.0008657210175936604\n",
      "train loss:0.0005371763605438657\n",
      "train loss:0.0032383322990869236\n",
      "train loss:0.0005006201816377644\n",
      "train loss:0.00018210998069931984\n",
      "train loss:0.0015060161451101919\n",
      "train loss:0.0005655107607778584\n",
      "train loss:0.0010488986406555255\n",
      "train loss:0.0054721757275982205\n",
      "train loss:0.002221177573768265\n",
      "train loss:0.0005388078531707192\n",
      "train loss:0.0009921804189677247\n",
      "train loss:0.0011538428563839488\n",
      "train loss:0.00233965369179649\n",
      "train loss:0.006061732770489204\n",
      "train loss:0.0005385632053618934\n",
      "train loss:0.004648343141425617\n",
      "train loss:0.0004696769829757988\n",
      "train loss:0.0007523202718622865\n",
      "train loss:0.000646626140177222\n",
      "train loss:0.0017545307059126647\n",
      "train loss:0.00045556910979163115\n",
      "train loss:0.0067717080435037505\n",
      "train loss:0.001251957240670343\n",
      "train loss:0.0001298318035496732\n",
      "train loss:0.0005400223902251697\n",
      "train loss:0.0392208448652483\n",
      "train loss:0.0006490312848548603\n",
      "train loss:0.0035746830069055286\n",
      "train loss:0.0009109852540927495\n",
      "train loss:0.0037385912035004477\n",
      "train loss:0.005611494073737411\n",
      "train loss:0.001003906213177284\n",
      "train loss:0.00039692205926872607\n",
      "train loss:0.00046240405038319374\n",
      "train loss:0.002940473930197038\n",
      "train loss:0.002680137958895316\n",
      "train loss:0.006513393970824329\n",
      "train loss:0.016940307050194427\n",
      "train loss:8.611979475249543e-05\n",
      "train loss:0.0007905973494457149\n",
      "train loss:0.003378901142150011\n",
      "train loss:0.0007871266559715662\n",
      "train loss:8.220909240559508e-05\n",
      "train loss:0.0010339153793126597\n",
      "train loss:0.0004401463717440739\n",
      "train loss:0.00026725496051417994\n",
      "train loss:0.001381317595092211\n",
      "train loss:0.006512297116547307\n",
      "train loss:0.0004980553483773953\n",
      "train loss:0.0004844167964728219\n",
      "train loss:0.0015162239201372248\n",
      "train loss:0.008576552824686784\n",
      "train loss:0.0012963937227161236\n",
      "train loss:0.0024098590234013116\n",
      "train loss:0.00029804888926828735\n",
      "train loss:0.001966429873604646\n",
      "train loss:0.0013387315040704019\n",
      "train loss:0.0048754913625061016\n",
      "train loss:0.0010520411733964527\n",
      "train loss:0.001862880101187093\n",
      "train loss:0.0014246904823341081\n",
      "train loss:0.018715758394837526\n",
      "train loss:0.00043701866904074393\n",
      "train loss:0.000988651089017751\n",
      "train loss:0.0007418706324778279\n",
      "train loss:7.386732149759518e-05\n",
      "train loss:0.00078170750347112\n",
      "train loss:0.00026233415294317963\n",
      "train loss:0.0009924636510440588\n",
      "train loss:0.0007436080424250203\n",
      "train loss:0.0020032001756265082\n",
      "train loss:0.005818437635310458\n",
      "train loss:0.0008099244879476992\n",
      "train loss:0.001373672111951916\n",
      "train loss:0.002031393436805452\n",
      "train loss:0.0008235532539934285\n",
      "train loss:0.00021235544772337265\n",
      "train loss:0.0002119667453614729\n",
      "train loss:8.211413247306676e-05\n",
      "train loss:0.009878774282928894\n",
      "train loss:0.011037486291117565\n",
      "train loss:0.0007307483311081977\n",
      "train loss:0.0014087082494128073\n",
      "train loss:0.0004870143052238906\n",
      "train loss:0.0016404464883323846\n",
      "train loss:0.0005595763875788436\n",
      "train loss:0.00024865551014448424\n",
      "train loss:0.0005820180830130267\n",
      "train loss:0.0007704120465698228\n",
      "train loss:0.0005950778084778958\n",
      "train loss:0.0014580731618352098\n",
      "train loss:7.915923293642832e-05\n",
      "train loss:9.788024480955291e-05\n",
      "train loss:0.003512652531963707\n",
      "train loss:0.0030359599686747996\n",
      "train loss:0.0005774079537812785\n",
      "train loss:0.0022643722653267694\n",
      "train loss:0.0003278549261542734\n",
      "train loss:0.011559304743521636\n",
      "train loss:0.0019661329691367667\n",
      "train loss:0.000772654634298121\n",
      "train loss:0.00010617290486919175\n",
      "train loss:0.004215014302931321\n",
      "train loss:0.00017170443510687494\n",
      "train loss:0.0011965919833421504\n",
      "train loss:0.0008084294005129063\n",
      "train loss:0.0012825432043411917\n",
      "train loss:0.00030635000163772364\n",
      "train loss:0.0016519544385810861\n",
      "train loss:0.0005493150333673297\n",
      "train loss:0.0005144294102020439\n",
      "train loss:0.0007194135684955037\n",
      "train loss:0.0008979122527345923\n",
      "train loss:7.922797946456676e-05\n",
      "train loss:0.0008462941121475247\n",
      "train loss:0.008872326698399081\n",
      "train loss:0.0013778416093080687\n",
      "train loss:0.003396039093693705\n",
      "train loss:0.004167050602440338\n",
      "train loss:0.006065703330949584\n",
      "train loss:0.0029138948076851195\n",
      "train loss:0.001565656266377243\n",
      "train loss:0.0002917033536144494\n",
      "train loss:0.0006515149683966982\n",
      "train loss:0.0013208257053453642\n",
      "train loss:0.001698127213182729\n",
      "train loss:0.001579586483698725\n",
      "train loss:0.0003260515447038398\n",
      "train loss:0.004260418596227812\n",
      "train loss:0.0002509275310046904\n",
      "train loss:0.0002980571692931768\n",
      "train loss:0.000756257092807367\n",
      "train loss:0.0008196166005791584\n",
      "train loss:0.0001811214082101065\n",
      "train loss:0.006528754201436716\n",
      "train loss:0.0010363319587102032\n",
      "train loss:0.0007010347822781444\n",
      "train loss:0.0015197198918948207\n",
      "train loss:0.0026259305181808227\n",
      "train loss:0.0011037153528137237\n",
      "train loss:0.0017405682241495917\n",
      "train loss:6.837738162073798e-05\n",
      "train loss:0.00040568194418544014\n",
      "train loss:0.00010364278844891803\n",
      "train loss:0.0007056712374179473\n",
      "train loss:0.0013994899598292038\n",
      "train loss:0.0010298350845612707\n",
      "train loss:0.0013343744037948877\n",
      "train loss:0.0007231073142950504\n",
      "train loss:0.0016820521861613009\n",
      "train loss:0.0005935715713514442\n",
      "train loss:0.0004900315366713205\n",
      "train loss:0.011071078633904356\n",
      "train loss:0.0009016396256894755\n",
      "train loss:0.0005265018661777194\n",
      "train loss:0.00021566036316113452\n",
      "train loss:0.0025449944806385434\n",
      "train loss:0.0017481564227293687\n",
      "train loss:0.000943256314537423\n",
      "train loss:0.0009547109844545635\n",
      "train loss:0.0007811748368405626\n",
      "train loss:0.0011638470356998853\n",
      "train loss:0.0032969154458796857\n",
      "train loss:0.0007109103256354194\n",
      "train loss:0.001053115708310592\n",
      "train loss:0.00017835106588972292\n",
      "train loss:0.0018009145530123597\n",
      "train loss:0.0021122569722651008\n",
      "train loss:8.517369617207794e-05\n",
      "train loss:0.0036599540690083394\n",
      "train loss:0.004706944726745256\n",
      "train loss:0.00016920466437939563\n",
      "train loss:0.0006046623731396397\n",
      "train loss:0.0009611998802843304\n",
      "train loss:0.0005161848394990749\n",
      "train loss:0.00012117266327272513\n",
      "train loss:0.0020763685063865983\n",
      "train loss:0.0012510269970555925\n",
      "train loss:0.005494730580638327\n",
      "train loss:0.0006749110803364354\n",
      "train loss:0.00011928885615481305\n",
      "train loss:0.0013508248067166328\n",
      "train loss:0.0002972578016323202\n",
      "train loss:8.47479570052811e-05\n",
      "train loss:0.0031898064847256883\n",
      "train loss:0.0010938303755944456\n",
      "train loss:0.0013708648838474033\n",
      "train loss:0.004511388175190037\n",
      "train loss:0.00021727294072222523\n",
      "train loss:0.00016809106543944413\n",
      "train loss:0.000698747878044412\n",
      "train loss:0.0017887022595572228\n",
      "train loss:0.0015191949542535256\n",
      "train loss:0.004087972041907708\n",
      "train loss:0.0022110734621895896\n",
      "train loss:0.0006174061965579121\n",
      "train loss:0.00023421230224853005\n",
      "train loss:0.001853193631178508\n",
      "train loss:0.0007144053158253156\n",
      "train loss:0.0016735938754112922\n",
      "train loss:0.0003800675788915291\n",
      "train loss:0.00019011633157588417\n",
      "train loss:0.001828683796189477\n",
      "train loss:0.0004817469348149461\n",
      "train loss:0.003508340417129308\n",
      "train loss:0.00287300995426403\n",
      "train loss:0.0007007224899993149\n",
      "train loss:0.00017769747260213239\n",
      "train loss:0.0012945631658764132\n",
      "train loss:0.00029631170987358174\n",
      "train loss:0.0026264408859617123\n",
      "train loss:0.0038910632733107856\n",
      "train loss:0.0009723836516206594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002031351715063781\n",
      "train loss:0.00036935861905504694\n",
      "train loss:0.0005104799938764747\n",
      "train loss:0.00033918510446269396\n",
      "train loss:0.0033882617422670114\n",
      "train loss:0.00138233908690199\n",
      "train loss:0.0005573133984386422\n",
      "train loss:0.0004554668908896916\n",
      "train loss:0.0002929843410783094\n",
      "train loss:9.357071048364825e-05\n",
      "train loss:0.0006919960733836153\n",
      "train loss:0.0004582411604793928\n",
      "train loss:0.0008189351887855989\n",
      "train loss:0.0022619089036089277\n",
      "train loss:0.0005676807792452554\n",
      "train loss:0.0003277190817584758\n",
      "train loss:0.001210446265840889\n",
      "train loss:0.002202215467514691\n",
      "train loss:0.0005590795808218632\n",
      "train loss:0.0017187852466679946\n",
      "train loss:0.0009179551895614916\n",
      "train loss:0.0002666175933474169\n",
      "train loss:0.0015488650821789357\n",
      "train loss:0.0008628714106455891\n",
      "train loss:0.010093273778556438\n",
      "train loss:0.000347174431510749\n",
      "train loss:0.0017658791334993844\n",
      "train loss:0.0007133531046050446\n",
      "train loss:0.0005878022877425565\n",
      "train loss:0.0008981259327306686\n",
      "train loss:6.791937676191013e-05\n",
      "train loss:0.03500223719792104\n",
      "train loss:0.003217282811169696\n",
      "train loss:0.00048562766495336465\n",
      "train loss:0.0005682493360260601\n",
      "train loss:0.00017321881273757916\n",
      "train loss:0.0050676224029487715\n",
      "train loss:0.0016396371709556717\n",
      "train loss:8.007509729196144e-05\n",
      "train loss:0.00019842707337330547\n",
      "train loss:0.00039901700228049913\n",
      "train loss:0.0003394667071965746\n",
      "train loss:2.2730662259777817e-05\n",
      "train loss:0.0002923208602273938\n",
      "train loss:0.0014850168326705632\n",
      "train loss:0.0006239087887281313\n",
      "train loss:0.0010260243088006408\n",
      "train loss:0.0003597451551092801\n",
      "train loss:7.225475951490723e-05\n",
      "train loss:0.00041722786322025124\n",
      "train loss:0.0016046253239782593\n",
      "train loss:0.001356394207186594\n",
      "train loss:0.00019255174668971354\n",
      "train loss:0.00026698468654738557\n",
      "train loss:0.0019072485515931545\n",
      "train loss:0.0013535341508338012\n",
      "train loss:0.0015650061141736363\n",
      "train loss:0.0029177348455318984\n",
      "train loss:0.0013365917670207408\n",
      "train loss:0.000136792172447334\n",
      "train loss:0.001391144405854429\n",
      "train loss:0.00016137520835058668\n",
      "train loss:0.002204026746841524\n",
      "train loss:0.0006971095517002083\n",
      "train loss:0.00154017667733909\n",
      "train loss:0.006220989017419553\n",
      "train loss:0.00040614531063607893\n",
      "train loss:5.988368187959303e-05\n",
      "train loss:0.006659671900770349\n",
      "train loss:0.0015301860098067795\n",
      "train loss:0.0002105403402828172\n",
      "train loss:0.001990189227305857\n",
      "train loss:0.0010672264308550364\n",
      "train loss:0.00015490890055152448\n",
      "train loss:0.00039274854515710273\n",
      "train loss:0.0006120655847144144\n",
      "train loss:0.0010487718652377243\n",
      "train loss:0.000575068667346589\n",
      "train loss:0.0006974747920981252\n",
      "train loss:0.001311797323334105\n",
      "train loss:0.0002374589633932975\n",
      "train loss:0.0003322182790171595\n",
      "train loss:0.0004931439393058418\n",
      "train loss:0.0002625368437186265\n",
      "train loss:0.00015359782989079023\n",
      "train loss:8.002401995940508e-05\n",
      "train loss:0.002277824258913016\n",
      "train loss:0.0017938297079160145\n",
      "train loss:0.00010364137254265527\n",
      "train loss:0.0031275256606669373\n",
      "train loss:0.00154819412293356\n",
      "train loss:0.0019962577425902124\n",
      "train loss:0.002892630806515817\n",
      "train loss:0.0007466781340829585\n",
      "train loss:8.252956573880743e-05\n",
      "train loss:0.0018504111041146892\n",
      "train loss:0.00016800955655006878\n",
      "train loss:0.0005681706654355603\n",
      "train loss:0.0013006035317461543\n",
      "train loss:0.0002715565281459936\n",
      "train loss:0.0015538550725138944\n",
      "train loss:0.00024150530805096447\n",
      "train loss:3.729562213711784e-05\n",
      "train loss:0.00013662757315484426\n",
      "train loss:0.0006430763798243236\n",
      "train loss:2.4573174909845322e-05\n",
      "train loss:2.5055507748931506e-05\n",
      "train loss:0.00016975900488376875\n",
      "train loss:0.00017172814504156885\n",
      "train loss:0.0006155454191504702\n",
      "train loss:0.0010779608972007395\n",
      "train loss:0.0012455748455775534\n",
      "train loss:0.00045802078519779704\n",
      "train loss:0.0001471988785070374\n",
      "train loss:0.0001249187443416412\n",
      "train loss:0.00010400208953118361\n",
      "train loss:0.0001478115744118946\n",
      "train loss:0.0002678243529374109\n",
      "train loss:0.005179055286473868\n",
      "train loss:6.356444424830483e-05\n",
      "train loss:0.0001226090444710418\n",
      "train loss:0.0010117894491088874\n",
      "train loss:0.0001667233496605167\n",
      "train loss:0.0007767803496190394\n",
      "train loss:0.00012005992486812558\n",
      "train loss:9.864387346369529e-05\n",
      "train loss:0.0003001422062878891\n",
      "train loss:0.000271828538041716\n",
      "train loss:5.161120061025174e-05\n",
      "train loss:0.004186538215773126\n",
      "train loss:1.781220311642664e-05\n",
      "train loss:0.001437751550929249\n",
      "train loss:0.0002889179519976527\n",
      "train loss:0.0012865471985341018\n",
      "train loss:0.001827242056283475\n",
      "train loss:0.00036658153546209274\n",
      "train loss:0.0009091189343153484\n",
      "train loss:0.011186531315370736\n",
      "train loss:0.00018423608529205256\n",
      "train loss:0.00164661230634317\n",
      "train loss:0.00023180626384326002\n",
      "train loss:8.913509052274862e-05\n",
      "train loss:0.0023511534952764747\n",
      "train loss:0.0015947234248670683\n",
      "train loss:1.2572051839237529e-05\n",
      "train loss:0.00012900315456951565\n",
      "train loss:0.00046014020951339496\n",
      "train loss:3.928897230645638e-05\n",
      "train loss:0.0007616904395561166\n",
      "train loss:0.00030600737241211976\n",
      "train loss:0.0003589594729340285\n",
      "train loss:0.0010650491251229964\n",
      "train loss:0.0007615699268731325\n",
      "train loss:0.007858669216498209\n",
      "train loss:0.0010783590246789788\n",
      "train loss:0.0013401258100237407\n",
      "train loss:0.0011515803279809659\n",
      "train loss:0.00019848937632653543\n",
      "train loss:0.0002759936485339987\n",
      "train loss:0.001170445984536964\n",
      "train loss:0.0009732042842049906\n",
      "train loss:0.00012488324100064818\n",
      "train loss:0.000668032012468027\n",
      "train loss:0.0017692248745785463\n",
      "train loss:0.001086588986814418\n",
      "train loss:0.0008167211376237159\n",
      "train loss:7.484342174014198e-05\n",
      "train loss:0.0015467107345072527\n",
      "train loss:0.0012570231556966577\n",
      "train loss:0.0001331884837232509\n",
      "train loss:0.0022954095483904767\n",
      "train loss:2.425784228812755e-05\n",
      "train loss:0.0006791520918610898\n",
      "=== epoch:18, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.0003206786433396042\n",
      "train loss:0.00038317480423358035\n",
      "train loss:0.0014032697661168364\n",
      "train loss:0.0003894562311755515\n",
      "train loss:0.0005549321742143094\n",
      "train loss:8.980290882955799e-05\n",
      "train loss:0.00045642022225086243\n",
      "train loss:0.00024799200974813486\n",
      "train loss:0.0001615574518245135\n",
      "train loss:0.0003619121469211038\n",
      "train loss:0.0007531450157902526\n",
      "train loss:0.0006355521428818989\n",
      "train loss:0.0005840886527047745\n",
      "train loss:0.0001324546937219627\n",
      "train loss:0.0005244258325226962\n",
      "train loss:0.0036303470855425083\n",
      "train loss:0.0006752896612975925\n",
      "train loss:0.0012965618767191423\n",
      "train loss:0.002839200449725429\n",
      "train loss:0.0013066579446297756\n",
      "train loss:0.0009624572367706793\n",
      "train loss:0.0013643905087698616\n",
      "train loss:0.00020394278048728405\n",
      "train loss:0.00295108733765477\n",
      "train loss:0.0005042355212045889\n",
      "train loss:0.00012237703909780457\n",
      "train loss:0.0006167446796409401\n",
      "train loss:0.0007284576784808186\n",
      "train loss:0.0001151139390912071\n",
      "train loss:0.002007841381411901\n",
      "train loss:0.0006892003799912621\n",
      "train loss:0.002139265284819192\n",
      "train loss:0.009134300494624886\n",
      "train loss:0.0011045397363598738\n",
      "train loss:0.001019193853609034\n",
      "train loss:0.0010584503668548651\n",
      "train loss:0.00015775854903942168\n",
      "train loss:0.0018460091583885779\n",
      "train loss:0.021352339225687106\n",
      "train loss:0.004788188553642198\n",
      "train loss:0.0006032970371703407\n",
      "train loss:0.0006746608727540071\n",
      "train loss:0.010493979497639505\n",
      "train loss:0.0018604525462863107\n",
      "train loss:0.0010272252086597827\n",
      "train loss:0.00012071585291401097\n",
      "train loss:0.00042198378183333366\n",
      "train loss:0.0036664107574254307\n",
      "train loss:0.0029476341475685513\n",
      "train loss:0.004105668806459598\n",
      "train loss:0.005407226587390347\n",
      "train loss:0.0016128707391345394\n",
      "train loss:0.00021987940896418828\n",
      "train loss:0.0006751506004801526\n",
      "train loss:0.13099636001342818\n",
      "train loss:0.00041250689735090315\n",
      "train loss:0.0021409001289705086\n",
      "train loss:0.0009780290432496767\n",
      "train loss:0.0017172236137584103\n",
      "train loss:0.00024240206445808195\n",
      "train loss:0.0004603379005798943\n",
      "train loss:0.0018804379999311288\n",
      "train loss:0.0007337190901396784\n",
      "train loss:0.0012076266079008712\n",
      "train loss:0.0006434841991904182\n",
      "train loss:0.007821498258263468\n",
      "train loss:0.0010745802010312094\n",
      "train loss:0.0014909398789333442\n",
      "train loss:0.0015633902119051707\n",
      "train loss:0.002368091871979153\n",
      "train loss:0.0078090801564686865\n",
      "train loss:0.007241511247524022\n",
      "train loss:0.000711498126024424\n",
      "train loss:0.0009937067396151643\n",
      "train loss:0.0002034687351455805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0049904527434071946\n",
      "train loss:0.0018273052381595064\n",
      "train loss:0.002256893264140693\n",
      "train loss:0.0017522702347583846\n",
      "train loss:0.00132688783550938\n",
      "train loss:0.006539040837747844\n",
      "train loss:0.0005499527344403608\n",
      "train loss:0.0011164907196739983\n",
      "train loss:0.00029576085328214357\n",
      "train loss:0.000647364774037085\n",
      "train loss:0.0002889014490455945\n",
      "train loss:0.0031435480077183216\n",
      "train loss:0.008814643494662\n",
      "train loss:0.00023523030074944204\n",
      "train loss:0.0010649206314854453\n",
      "train loss:0.0010913589272787123\n",
      "train loss:0.030367510772900695\n",
      "train loss:0.0013688468704731362\n",
      "train loss:0.0011004670731562375\n",
      "train loss:0.00041432592298361174\n",
      "train loss:0.005641809353778901\n",
      "train loss:0.0005103526564164389\n",
      "train loss:0.006416521764784864\n",
      "train loss:0.005828505305294833\n",
      "train loss:0.001463199945443311\n",
      "train loss:0.0011667824349212948\n",
      "train loss:0.004874797488470178\n",
      "train loss:0.0022926350824332255\n",
      "train loss:0.0021181797502678678\n",
      "train loss:0.019721493439174568\n",
      "train loss:0.041810265307509586\n",
      "train loss:0.0029251578206787175\n",
      "train loss:0.0012227180863982829\n",
      "train loss:0.0034892533109504294\n",
      "train loss:0.005322780412688508\n",
      "train loss:0.000354198135334564\n",
      "train loss:0.0029764249453275125\n",
      "train loss:0.007589689491732622\n",
      "train loss:0.0010648551840589024\n",
      "train loss:0.004070642637127458\n",
      "train loss:0.003063131545381265\n",
      "train loss:0.0064387729552524585\n",
      "train loss:0.013603430371070386\n",
      "train loss:0.017226104363368824\n",
      "train loss:0.0010469837508327163\n",
      "train loss:0.0037731020796499164\n",
      "train loss:0.005260353476141143\n",
      "train loss:0.0011624120428350246\n",
      "train loss:0.0034247531629417027\n",
      "train loss:0.0025045834636153825\n",
      "train loss:0.0003020588878581433\n",
      "train loss:5.868845860940988e-05\n",
      "train loss:0.0021232239856013684\n",
      "train loss:0.0004872863308979261\n",
      "train loss:0.003197417294810584\n",
      "train loss:0.0009992053974587148\n",
      "train loss:0.0009910203628101869\n",
      "train loss:0.0009044209208445376\n",
      "train loss:0.0037277553610096615\n",
      "train loss:0.0021142891025913\n",
      "train loss:0.0008184141663944993\n",
      "train loss:0.0004192111108320773\n",
      "train loss:0.0013683125990098148\n",
      "train loss:0.0008309034647832457\n",
      "train loss:0.0023157094420488\n",
      "train loss:0.0034021643654102234\n",
      "train loss:0.0022004002176005603\n",
      "train loss:0.0009165066112764431\n",
      "train loss:0.004570979753204094\n",
      "train loss:0.005419258353995816\n",
      "train loss:0.0014338316942155696\n",
      "train loss:0.0040885314213350045\n",
      "train loss:0.00047978152387849926\n",
      "train loss:0.002380587347779899\n",
      "train loss:0.0006161819489463754\n",
      "train loss:0.00029541101561357866\n",
      "train loss:0.003914732438926906\n",
      "train loss:0.0015019630849542897\n",
      "train loss:0.002080412547336785\n",
      "train loss:0.0026993511046899303\n",
      "train loss:0.01548544530001147\n",
      "train loss:8.056962089688205e-05\n",
      "train loss:0.0008711279474243679\n",
      "train loss:0.00818755630866117\n",
      "train loss:0.0011364144657895177\n",
      "train loss:0.0020498374087757373\n",
      "train loss:0.0003839105444789455\n",
      "train loss:0.0002037523461393799\n",
      "train loss:0.0018351453233607857\n",
      "train loss:0.003891357510670761\n",
      "train loss:0.0003836579912256499\n",
      "train loss:0.0014929645874226486\n",
      "train loss:0.0075394878105121245\n",
      "train loss:2.1066997971547545e-05\n",
      "train loss:0.0015071984678798195\n",
      "train loss:0.0019330455124048768\n",
      "train loss:0.010470042294853646\n",
      "train loss:0.00038081150158329654\n",
      "train loss:0.0011477429674952345\n",
      "train loss:0.020934042829656302\n",
      "train loss:0.0013871196370897653\n",
      "train loss:0.004964000889676237\n",
      "train loss:0.0006424460293616132\n",
      "train loss:0.0034447349848128607\n",
      "train loss:7.140376611496012e-05\n",
      "train loss:0.001476152785582043\n",
      "train loss:0.002860379877867489\n",
      "train loss:0.02099828441076614\n",
      "train loss:0.002319126552569537\n",
      "train loss:0.0011367283275676256\n",
      "train loss:0.0005690734620413531\n",
      "train loss:0.0033336814723257933\n",
      "train loss:0.001686710210386587\n",
      "train loss:0.04598759383088893\n",
      "train loss:0.006640008461530793\n",
      "train loss:0.0018973876222004033\n",
      "train loss:0.0007979576390648049\n",
      "train loss:0.00046022837775771137\n",
      "train loss:0.006729343255679025\n",
      "train loss:0.0015791173981191773\n",
      "train loss:0.002514328946923672\n",
      "train loss:0.00815381584991278\n",
      "train loss:0.0065929726242494905\n",
      "train loss:0.0116359152562578\n",
      "train loss:0.002083452479115466\n",
      "train loss:0.0032497801995068744\n",
      "train loss:0.00019984414434041627\n",
      "train loss:0.001024293060736572\n",
      "train loss:0.0019002929805166928\n",
      "train loss:0.0026220998068357303\n",
      "train loss:0.00029162225376299907\n",
      "train loss:0.003190534425945107\n",
      "train loss:0.0023695970287023133\n",
      "train loss:0.001340206348739734\n",
      "train loss:0.0031131447703433585\n",
      "train loss:0.0023685435033794586\n",
      "train loss:0.002897411882940307\n",
      "train loss:0.0029654797252924403\n",
      "train loss:0.0039449722601915885\n",
      "train loss:0.00406166598108592\n",
      "train loss:0.001427961753801977\n",
      "train loss:0.01694221411647881\n",
      "train loss:0.0009818329391600908\n",
      "train loss:3.894879503467493e-05\n",
      "train loss:0.0006277395813487978\n",
      "train loss:0.0026150603408651068\n",
      "train loss:0.0010135703469598665\n",
      "train loss:0.00792529274001329\n",
      "train loss:0.005800187300268149\n",
      "train loss:0.005286329549072056\n",
      "train loss:0.004272101065049396\n",
      "train loss:0.003588659086132026\n",
      "train loss:0.00013031076765314208\n",
      "train loss:0.003191417188012301\n",
      "train loss:0.0007302281661809533\n",
      "train loss:0.016751609429597757\n",
      "train loss:0.000983047981056622\n",
      "train loss:0.003429134608152312\n",
      "train loss:0.026964415508387827\n",
      "train loss:0.0012848810839665638\n",
      "train loss:0.0025974661739808606\n",
      "train loss:0.0005808520693995137\n",
      "train loss:0.0022105392338677703\n",
      "train loss:0.002711248614658385\n",
      "train loss:0.008638334784598502\n",
      "train loss:0.0027847253075718977\n",
      "train loss:0.009482377131663656\n",
      "train loss:0.0039227398836124685\n",
      "train loss:0.017850725148361533\n",
      "train loss:0.001276021984641493\n",
      "train loss:0.0001952509370517134\n",
      "train loss:0.0029201181823589727\n",
      "train loss:0.0007882931188444341\n",
      "train loss:0.006157369659061213\n",
      "train loss:0.0014297481189761378\n",
      "train loss:0.0016466060114773773\n",
      "train loss:0.0021471365249153083\n",
      "train loss:0.005040840507638787\n",
      "train loss:9.605874129184631e-05\n",
      "train loss:0.01795716000094616\n",
      "train loss:0.0010653193741923931\n",
      "train loss:0.005557884469407985\n",
      "train loss:0.0012983136213167454\n",
      "train loss:0.001281720087959336\n",
      "train loss:0.0016856300721976986\n",
      "train loss:0.0017912059464108955\n",
      "train loss:0.001097299162179226\n",
      "train loss:0.0034180057082986233\n",
      "train loss:0.008316884700538308\n",
      "train loss:0.0005216683475997027\n",
      "train loss:0.0009064294508921388\n",
      "train loss:0.0009476448784659347\n",
      "train loss:0.0012631478751361023\n",
      "train loss:0.0037447076855456796\n",
      "train loss:0.00040170275190440363\n",
      "train loss:0.0005785602932231188\n",
      "train loss:0.017219155069119797\n",
      "train loss:0.0009901519522075122\n",
      "train loss:0.002165016269615587\n",
      "train loss:0.0029833688050001288\n",
      "train loss:0.0005691702771161278\n",
      "train loss:0.0019677937227165344\n",
      "train loss:0.0002834402984437364\n",
      "train loss:0.00020361037808331496\n",
      "train loss:0.0002983713031962415\n",
      "train loss:0.0004754528920353736\n",
      "train loss:0.00012500860084331214\n",
      "train loss:0.002728622569106895\n",
      "train loss:0.0008251273693462917\n",
      "train loss:0.0006596718756151603\n",
      "train loss:0.001561346850659654\n",
      "train loss:0.0026082957758602238\n",
      "train loss:0.00013750893877586266\n",
      "train loss:0.0030324583776522997\n",
      "train loss:0.0002488742721394534\n",
      "train loss:0.00078180362452425\n",
      "train loss:0.004691464938196531\n",
      "train loss:0.001367535913685685\n",
      "train loss:0.0002549754864127756\n",
      "train loss:0.0038737144250410665\n",
      "train loss:0.0005267082581394769\n",
      "train loss:0.0013505103842338642\n",
      "train loss:0.0025369698934689837\n",
      "train loss:0.0014175936235692732\n",
      "train loss:0.003082639230894286\n",
      "train loss:0.002231807440340829\n",
      "train loss:0.002338001661092778\n",
      "train loss:0.0026867493921153424\n",
      "train loss:0.005446678459286505\n",
      "train loss:0.00030354085626609946\n",
      "train loss:0.00010086148286775961\n",
      "train loss:0.006522021995460874\n",
      "train loss:0.0003977620706595974\n",
      "train loss:0.00014468542097266382\n",
      "train loss:0.0006590289952815156\n",
      "train loss:0.0005676661233942514\n",
      "train loss:0.0003548508933179468\n",
      "train loss:0.00023477221224562595\n",
      "train loss:0.0014159428224894805\n",
      "train loss:0.0001613077349985202\n",
      "train loss:0.00015196470246366692\n",
      "train loss:0.0032080426073290026\n",
      "train loss:0.0003715946211083073\n",
      "train loss:0.0004393736784745462\n",
      "train loss:0.004450068980023572\n",
      "train loss:0.00018100510505793672\n",
      "train loss:0.0006772418240179105\n",
      "train loss:0.002024453218047227\n",
      "train loss:0.010055863171198092\n",
      "train loss:0.0011056200977997064\n",
      "train loss:0.0008900206164119104\n",
      "train loss:0.0018512026508813834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014358861365975867\n",
      "train loss:0.0004752750183879422\n",
      "train loss:0.00030413008269932303\n",
      "train loss:0.001944172153467742\n",
      "train loss:0.0035557907602459097\n",
      "train loss:0.0004254048517432769\n",
      "train loss:0.0009917141710334017\n",
      "train loss:0.00033814193582532487\n",
      "train loss:0.001888252502265386\n",
      "train loss:0.018389339027697175\n",
      "train loss:0.0020505846136952386\n",
      "train loss:0.0002135604977365484\n",
      "train loss:0.003054740049268358\n",
      "train loss:0.02522894683843618\n",
      "train loss:0.004693034336844866\n",
      "train loss:0.000458258508873517\n",
      "train loss:0.07017728944184647\n",
      "train loss:0.001697919213875341\n",
      "train loss:0.0042752549060536115\n",
      "train loss:0.0011256630040583997\n",
      "train loss:0.0016945672697169256\n",
      "train loss:0.0004823481346519063\n",
      "train loss:0.001623795768228047\n",
      "train loss:0.0027366368380903204\n",
      "train loss:0.0008786840700125836\n",
      "train loss:0.002282941091946663\n",
      "train loss:0.005134936250933074\n",
      "train loss:0.003482872369805332\n",
      "train loss:0.0004349370722585103\n",
      "train loss:0.00016217663907677806\n",
      "train loss:0.001654867571346416\n",
      "train loss:0.0017656581205352467\n",
      "train loss:0.005257599262582885\n",
      "train loss:0.0007819216664706405\n",
      "train loss:0.007985657325028669\n",
      "train loss:0.0028579127848234864\n",
      "train loss:0.001582192044224145\n",
      "train loss:9.404176687864109e-05\n",
      "train loss:7.690389588660804e-05\n",
      "train loss:0.001498280933213615\n",
      "train loss:0.000315596110867811\n",
      "train loss:0.0004062752137262966\n",
      "train loss:0.005526219273959381\n",
      "train loss:0.0012421530954119244\n",
      "train loss:0.002412422602562599\n",
      "train loss:0.018223905928056828\n",
      "train loss:0.0006982475067340317\n",
      "train loss:0.0034156357126541087\n",
      "train loss:0.000983872240243531\n",
      "train loss:0.0009244492116739343\n",
      "train loss:0.0005861212921560988\n",
      "train loss:0.0004997871134121326\n",
      "train loss:0.004523628766466833\n",
      "train loss:0.0029051346973245754\n",
      "train loss:0.001216404567957148\n",
      "train loss:0.0035209475519286126\n",
      "train loss:0.005958307675381993\n",
      "train loss:0.012612528886925167\n",
      "train loss:0.0035964335888305516\n",
      "train loss:0.002249400683698473\n",
      "train loss:0.003043039389356382\n",
      "train loss:0.009828678230304099\n",
      "train loss:0.00035115078530041676\n",
      "train loss:0.003090990459835557\n",
      "train loss:0.0017047777416325568\n",
      "train loss:0.0017418984415031851\n",
      "train loss:0.00344490982264024\n",
      "train loss:0.018575637497173243\n",
      "train loss:0.0013841616689270158\n",
      "train loss:0.002516297261873444\n",
      "train loss:0.032325007233401384\n",
      "train loss:0.00752800819488103\n",
      "train loss:0.0019443389456227742\n",
      "train loss:0.0012473048730224936\n",
      "train loss:0.0019964764633722725\n",
      "train loss:0.0004424350971991091\n",
      "train loss:0.0021679902968201052\n",
      "train loss:0.027768448670136697\n",
      "train loss:0.0006507412049403189\n",
      "train loss:0.0029065484849610562\n",
      "train loss:0.0007090811048276731\n",
      "train loss:0.0013037704174492994\n",
      "train loss:0.004709406607732228\n",
      "train loss:0.00032140428277954985\n",
      "train loss:0.0002587914724270284\n",
      "train loss:0.0039339065819704476\n",
      "train loss:0.0002455426790179436\n",
      "train loss:0.00011720847427043844\n",
      "train loss:0.0012748891049754153\n",
      "train loss:0.007175145641092424\n",
      "train loss:0.0024800694036474476\n",
      "train loss:0.0005388465048305242\n",
      "train loss:0.0029389218243971067\n",
      "train loss:0.001612737113727371\n",
      "train loss:0.0009830887801931213\n",
      "train loss:0.022624272441807588\n",
      "train loss:0.005011016927385874\n",
      "train loss:0.0016063767721735264\n",
      "train loss:0.00024134759452482574\n",
      "train loss:0.001948237118024756\n",
      "train loss:0.0013142576911757953\n",
      "train loss:0.002204578193155711\n",
      "train loss:0.005717890472679918\n",
      "train loss:0.0011175384076634867\n",
      "train loss:0.00015052402745183927\n",
      "train loss:0.00044364082299830766\n",
      "train loss:0.00023443566423314417\n",
      "train loss:0.00011045666966207571\n",
      "train loss:0.004475228842903108\n",
      "train loss:0.018621613308580125\n",
      "train loss:0.0006593057631760749\n",
      "train loss:0.004423167694773904\n",
      "train loss:0.004741502071391769\n",
      "train loss:0.004358957334378625\n",
      "train loss:0.00064960145455152\n",
      "train loss:0.003701494992541078\n",
      "train loss:0.0001343614664774965\n",
      "train loss:0.00027523425749443746\n",
      "train loss:0.0012393412034622181\n",
      "train loss:0.004001420051223106\n",
      "train loss:0.009941096639027508\n",
      "train loss:0.004354391292576118\n",
      "train loss:0.001745896405284663\n",
      "train loss:0.0006743736480451607\n",
      "train loss:0.002935465854635551\n",
      "train loss:0.0029113601474103734\n",
      "train loss:0.0011155262857388054\n",
      "train loss:0.0001639582615782292\n",
      "train loss:0.005213933008113237\n",
      "train loss:0.004221322069749246\n",
      "train loss:0.0031749162285735276\n",
      "train loss:0.0003680225392104126\n",
      "train loss:0.002315026789359574\n",
      "train loss:0.0025114732079923856\n",
      "train loss:0.0009976765010171003\n",
      "train loss:0.0001621775973504218\n",
      "train loss:0.0052072541947377924\n",
      "train loss:7.68858746656324e-05\n",
      "train loss:0.01310309093093863\n",
      "train loss:0.0008749189411373821\n",
      "train loss:0.003020602727361747\n",
      "train loss:0.011630972895125878\n",
      "train loss:0.00026356955141333785\n",
      "train loss:0.002617586524984965\n",
      "train loss:0.00016622378809939302\n",
      "train loss:0.00013572086915346576\n",
      "train loss:0.001614201636239447\n",
      "train loss:8.257465661306608e-05\n",
      "train loss:0.000355792912092322\n",
      "train loss:0.0004345999811065319\n",
      "train loss:0.0035042081516973383\n",
      "train loss:0.002670706628203123\n",
      "train loss:0.004368215836889452\n",
      "train loss:0.0014437813162229685\n",
      "train loss:0.0012810687277990218\n",
      "train loss:0.0005749247232447734\n",
      "train loss:0.0018658310054979871\n",
      "train loss:0.0022913343760891953\n",
      "train loss:0.0013954247858320129\n",
      "train loss:0.0004141741797146823\n",
      "train loss:0.0008447689531642415\n",
      "train loss:0.0009345900532571295\n",
      "train loss:0.003171270937370346\n",
      "train loss:0.003213586835535095\n",
      "train loss:0.007596501191934832\n",
      "train loss:0.007312210122361535\n",
      "train loss:0.0016612210210346608\n",
      "train loss:0.001871980274033545\n",
      "train loss:0.0011654276851304286\n",
      "train loss:0.0005247347678761847\n",
      "train loss:0.0004243617497670536\n",
      "train loss:0.0007874055063847578\n",
      "train loss:0.004050958934939062\n",
      "train loss:0.01784861395057469\n",
      "train loss:0.0008991556957538055\n",
      "train loss:0.0001594101523410672\n",
      "train loss:0.004774884863953375\n",
      "train loss:0.0012982392193527403\n",
      "train loss:0.0004992804246594383\n",
      "train loss:0.0017347917477008817\n",
      "train loss:0.0005809433180861817\n",
      "train loss:0.003293159704564867\n",
      "train loss:0.0003091596528737075\n",
      "train loss:0.0004971855217682019\n",
      "train loss:5.9933105076533734e-05\n",
      "train loss:0.0009663205535341944\n",
      "train loss:0.0027598100627583572\n",
      "train loss:0.013245901933335217\n",
      "train loss:0.0008180995497936587\n",
      "train loss:0.002103017335977832\n",
      "train loss:0.0004327962058065084\n",
      "train loss:0.0004927833911298267\n",
      "train loss:0.0009058759191560802\n",
      "train loss:0.002587943974651353\n",
      "train loss:0.0005084200473331734\n",
      "train loss:0.0007333565948328424\n",
      "train loss:0.0005672322251890948\n",
      "train loss:0.0027708201147680195\n",
      "train loss:0.0051706375551052505\n",
      "train loss:0.012681788847525082\n",
      "train loss:0.0001654897892235906\n",
      "train loss:0.0021968899049527833\n",
      "train loss:0.000285978590966687\n",
      "train loss:0.00030375569015760257\n",
      "train loss:0.0007624402805063006\n",
      "train loss:0.003069838791116207\n",
      "train loss:0.0776814496846075\n",
      "train loss:9.533034160340635e-05\n",
      "train loss:0.0015796756521205995\n",
      "train loss:0.0014704461370274966\n",
      "train loss:0.00018705338733485195\n",
      "train loss:0.003407255240747151\n",
      "train loss:0.0011275992417017404\n",
      "train loss:0.004207262932043101\n",
      "train loss:0.00331252399107586\n",
      "train loss:0.002082975648393567\n",
      "train loss:0.0012135220091265698\n",
      "train loss:0.0008371372053827806\n",
      "train loss:0.00022576531881917332\n",
      "train loss:0.005837524631186407\n",
      "train loss:0.002937281538397828\n",
      "train loss:0.002599030596310793\n",
      "train loss:0.00035261490440054665\n",
      "train loss:0.0015295002733365923\n",
      "train loss:0.0381194536294657\n",
      "train loss:0.0005604674180730688\n",
      "train loss:0.0003572090852181586\n",
      "train loss:0.0008148279325430528\n",
      "train loss:0.0034033260732418908\n",
      "train loss:0.005116852671207301\n",
      "train loss:0.0014383472370452875\n",
      "train loss:0.004999100643686338\n",
      "train loss:0.0063495506117061526\n",
      "train loss:0.0009850098338433997\n",
      "train loss:0.0017124745268171585\n",
      "train loss:0.00196124933467927\n",
      "train loss:0.0004256708245059313\n",
      "train loss:0.0002907264547908226\n",
      "train loss:0.015254951665530219\n",
      "train loss:0.006329321369872051\n",
      "train loss:0.0013516399777876772\n",
      "train loss:0.010185909722102253\n",
      "train loss:0.001981853567700978\n",
      "train loss:0.003229938279138478\n",
      "train loss:0.00019247941170473003\n",
      "train loss:0.0007506476217054778\n",
      "train loss:0.0010124325601984755\n",
      "train loss:0.00012939144727791368\n",
      "train loss:0.000422605024318784\n",
      "train loss:0.001487386971796127\n",
      "train loss:0.004615025575108126\n",
      "train loss:0.00013931391973845704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0018432453605853368\n",
      "train loss:0.00040055960267246004\n",
      "train loss:0.0031303190277847353\n",
      "train loss:5.7582393405222304e-05\n",
      "train loss:0.01008363760415794\n",
      "train loss:0.005784856103918871\n",
      "train loss:0.0004073337743844946\n",
      "train loss:0.000335553531619112\n",
      "train loss:1.2766182501563325e-05\n",
      "train loss:0.0015232032197781697\n",
      "train loss:0.00034325316552439916\n",
      "train loss:0.00023062531955954135\n",
      "train loss:0.00021499706102218405\n",
      "train loss:0.0027822810290766315\n",
      "train loss:8.906200744955387e-05\n",
      "train loss:0.00569418269020763\n",
      "train loss:0.0009602827133819001\n",
      "train loss:0.00210512341325142\n",
      "train loss:0.0006234400350641067\n",
      "train loss:0.003188724324444765\n",
      "train loss:0.0018159353159545697\n",
      "=== epoch:19, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.002207783252871684\n",
      "train loss:0.0020603887975138265\n",
      "train loss:0.002280041520018392\n",
      "train loss:0.028046706436859598\n",
      "train loss:0.0008125774575409163\n",
      "train loss:0.015827083407924408\n",
      "train loss:0.0002590723375761507\n",
      "train loss:0.00017754680532491073\n",
      "train loss:0.003120421497064696\n",
      "train loss:0.001996219008439877\n",
      "train loss:0.002535399085103825\n",
      "train loss:0.0004487218373455771\n",
      "train loss:0.001978425632486617\n",
      "train loss:0.001019891245109262\n",
      "train loss:0.0006127287941959352\n",
      "train loss:0.0020515270574517634\n",
      "train loss:0.00847360314759689\n",
      "train loss:0.0009366151231982374\n",
      "train loss:0.0035947967175743267\n",
      "train loss:0.00211396386183116\n",
      "train loss:0.0034162548201303864\n",
      "train loss:0.0003498374963834662\n",
      "train loss:0.0005306484973021915\n",
      "train loss:0.001316601626290152\n",
      "train loss:5.464553613431441e-05\n",
      "train loss:0.0011079110965261604\n",
      "train loss:0.0017181174044549174\n",
      "train loss:0.0014622748692285428\n",
      "train loss:0.0030954403657084363\n",
      "train loss:0.0014304893142444638\n",
      "train loss:0.0021564329918992296\n",
      "train loss:0.00014647424714079576\n",
      "train loss:0.0005974914222068304\n",
      "train loss:0.0023133964032291516\n",
      "train loss:0.0012200852390190009\n",
      "train loss:0.004610773488619303\n",
      "train loss:0.0018342602388830387\n",
      "train loss:0.005185908994494535\n",
      "train loss:0.0008588219346962879\n",
      "train loss:0.000369210921973224\n",
      "train loss:0.0027829681202569878\n",
      "train loss:8.695552974677208e-05\n",
      "train loss:0.0017491256388684373\n",
      "train loss:0.00041220706621858047\n",
      "train loss:0.00126794590367085\n",
      "train loss:0.00021374085037852714\n",
      "train loss:0.0002719751405339213\n",
      "train loss:0.0006835332735357337\n",
      "train loss:0.0029789965041459466\n",
      "train loss:0.0025018941650227413\n",
      "train loss:0.001196655144791387\n",
      "train loss:0.0019071498529272801\n",
      "train loss:0.0001448800489840648\n",
      "train loss:0.0018090821417765326\n",
      "train loss:0.0023362433137968613\n",
      "train loss:0.0024742486854791535\n",
      "train loss:0.00031750765409718247\n",
      "train loss:0.00013679675906082554\n",
      "train loss:0.00016888454007985495\n",
      "train loss:0.0026136091121877992\n",
      "train loss:0.0002625234767694594\n",
      "train loss:0.019933576579094767\n",
      "train loss:0.0001640117899057166\n",
      "train loss:0.006076876425510926\n",
      "train loss:0.00018596792121458618\n",
      "train loss:0.0001463377983496791\n",
      "train loss:0.003236746658692547\n",
      "train loss:0.0014427608823545102\n",
      "train loss:0.001191875028233415\n",
      "train loss:0.00013219972507805627\n",
      "train loss:0.005118336828471921\n",
      "train loss:0.0005043627327590006\n",
      "train loss:0.0003769536026704584\n",
      "train loss:0.0001373319172649692\n",
      "train loss:0.0008290975188502083\n",
      "train loss:0.0007140524852025887\n",
      "train loss:0.0003723161947167245\n",
      "train loss:0.0006535690193690506\n",
      "train loss:0.0009804012418573942\n",
      "train loss:8.542801630143111e-05\n",
      "train loss:0.0002739703133923372\n",
      "train loss:0.0006943183202586645\n",
      "train loss:0.00229657078611363\n",
      "train loss:0.0017347572756628003\n",
      "train loss:0.0021360952029466944\n",
      "train loss:0.003174485491020654\n",
      "train loss:0.0010155930368627916\n",
      "train loss:0.009977212650783393\n",
      "train loss:0.0011603235935209663\n",
      "train loss:0.0160394017670668\n",
      "train loss:0.008983624154495684\n",
      "train loss:0.014790504699991523\n",
      "train loss:7.84750874483829e-05\n",
      "train loss:0.0010137355555218893\n",
      "train loss:0.00021428277125559072\n",
      "train loss:7.40305421998937e-05\n",
      "train loss:0.0032706938116731877\n",
      "train loss:0.001651254019020892\n",
      "train loss:0.00026736531763841653\n",
      "train loss:8.282905422193589e-05\n",
      "train loss:0.0010254914191779772\n",
      "train loss:0.011485431970370845\n",
      "train loss:0.001113753455593373\n",
      "train loss:0.0031630829323729456\n",
      "train loss:0.000984269464435331\n",
      "train loss:0.0014180782383874859\n",
      "train loss:0.0008374528183392873\n",
      "train loss:0.00020914006147624588\n",
      "train loss:0.0005465818021467465\n",
      "train loss:0.002980009508920826\n",
      "train loss:0.0006511001107767861\n",
      "train loss:0.0010693661416916994\n",
      "train loss:0.0008770899607788761\n",
      "train loss:0.00010672434164940053\n",
      "train loss:0.001759612854517753\n",
      "train loss:0.0015751202070024258\n",
      "train loss:0.0014662766200195438\n",
      "train loss:0.0011768290589277337\n",
      "train loss:0.0022597900734733912\n",
      "train loss:0.0008376234144066628\n",
      "train loss:0.0009201278392686114\n",
      "train loss:0.0005123614727340186\n",
      "train loss:0.00021454228968654317\n",
      "train loss:0.0003679190686728063\n",
      "train loss:0.0008418600583309261\n",
      "train loss:0.0013011422529843357\n",
      "train loss:0.00029570876476491936\n",
      "train loss:0.00022838067389137904\n",
      "train loss:0.0011468124714006525\n",
      "train loss:0.0012461995246015921\n",
      "train loss:0.0003004408896997899\n",
      "train loss:0.0006179297754030798\n",
      "train loss:0.0028274652239591276\n",
      "train loss:0.005711845438287911\n",
      "train loss:0.00038802573221869823\n",
      "train loss:0.00021044095841139522\n",
      "train loss:0.0005006632700192132\n",
      "train loss:8.661835139158575e-05\n",
      "train loss:6.063958155306862e-05\n",
      "train loss:0.0013608443303317849\n",
      "train loss:0.002645993841446907\n",
      "train loss:0.00047965665665384167\n",
      "train loss:0.00022197828545496485\n",
      "train loss:0.0007693922325166068\n",
      "train loss:0.0007208469591142095\n",
      "train loss:0.000821588004727873\n",
      "train loss:0.0020470234517035927\n",
      "train loss:0.0006719917266951363\n",
      "train loss:0.0011753151078626608\n",
      "train loss:0.003454136380826754\n",
      "train loss:0.003043797665651998\n",
      "train loss:0.006151019024601575\n",
      "train loss:0.0010507696023045585\n",
      "train loss:0.0011203001944776131\n",
      "train loss:9.333639556299481e-05\n",
      "train loss:0.001259964980551048\n",
      "train loss:0.00041874149727058434\n",
      "train loss:0.0013053793937093817\n",
      "train loss:0.00252924160754115\n",
      "train loss:0.0003548981088487414\n",
      "train loss:0.0012650304992007507\n",
      "train loss:2.892074203642543e-05\n",
      "train loss:0.0005493785260182141\n",
      "train loss:0.002077561579759087\n",
      "train loss:0.0005814122414583866\n",
      "train loss:0.000336387295266034\n",
      "train loss:0.0004232339717477716\n",
      "train loss:0.0011041371440189127\n",
      "train loss:0.0008670377480976213\n",
      "train loss:0.0026951727146873384\n",
      "train loss:0.0030904195231961943\n",
      "train loss:0.0004594928116961174\n",
      "train loss:0.000506917658179663\n",
      "train loss:0.00039687434736980135\n",
      "train loss:0.00017129281773583003\n",
      "train loss:0.002146667833224896\n",
      "train loss:0.0007541118293885713\n",
      "train loss:0.00098870286504998\n",
      "train loss:0.00037115499399213275\n",
      "train loss:0.0007892402347524545\n",
      "train loss:0.03061810569291883\n",
      "train loss:0.0011119478225623514\n",
      "train loss:0.0010675557277633058\n",
      "train loss:0.001084804921959391\n",
      "train loss:0.008320472460546102\n",
      "train loss:0.0003060083737754324\n",
      "train loss:0.00025497905871105524\n",
      "train loss:0.01460700092575547\n",
      "train loss:0.0010719893506848286\n",
      "train loss:0.0025579564554804378\n",
      "train loss:0.0015826429423169766\n",
      "train loss:0.0017020311964117583\n",
      "train loss:0.00012553713631484494\n",
      "train loss:0.0007476744134570115\n",
      "train loss:0.0034596134809571875\n",
      "train loss:0.0009177900087131651\n",
      "train loss:0.00017330591354121515\n",
      "train loss:0.0011043978296786214\n",
      "train loss:0.00033376798433691515\n",
      "train loss:0.00036084036279127453\n",
      "train loss:0.004804584730584953\n",
      "train loss:0.00032250854474050086\n",
      "train loss:0.0002166161059422108\n",
      "train loss:0.0016882236565002675\n",
      "train loss:0.00012159078028821827\n",
      "train loss:0.0001313225047558361\n",
      "train loss:0.00030838659326215176\n",
      "train loss:0.00016378651802694658\n",
      "train loss:0.0037186535158790918\n",
      "train loss:0.0019265866908670449\n",
      "train loss:0.0011381142993804989\n",
      "train loss:0.0005249933146809021\n",
      "train loss:0.002842557822215589\n",
      "train loss:0.003963769780703677\n",
      "train loss:0.002331356789756461\n",
      "train loss:0.00014791063115090263\n",
      "train loss:0.003940565970562381\n",
      "train loss:0.0012327508039303966\n",
      "train loss:0.0014590094297076339\n",
      "train loss:0.0011877623178606423\n",
      "train loss:0.0060589821464973334\n",
      "train loss:0.0026196186899805963\n",
      "train loss:0.0005067138281686642\n",
      "train loss:0.006863584913698726\n",
      "train loss:0.0015548712642455187\n",
      "train loss:0.0009315202706744547\n",
      "train loss:0.0005415864654827252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011353054865804668\n",
      "train loss:0.0001483384383244872\n",
      "train loss:0.0007834169410291297\n",
      "train loss:0.00037303544548499115\n",
      "train loss:0.00012073611741074819\n",
      "train loss:0.0013315606574741156\n",
      "train loss:0.003230098202755047\n",
      "train loss:0.0013551900427349877\n",
      "train loss:0.003974650190872862\n",
      "train loss:0.00016263277158220127\n",
      "train loss:0.001825276254254997\n",
      "train loss:8.397171055044986e-05\n",
      "train loss:0.001354438433671065\n",
      "train loss:0.00038683765150735643\n",
      "train loss:0.0018083262035642508\n",
      "train loss:0.004785840255492555\n",
      "train loss:0.004114904811771274\n",
      "train loss:0.0020280800430573973\n",
      "train loss:0.0006685501155447534\n",
      "train loss:0.0021723028507671482\n",
      "train loss:0.0016167574814252616\n",
      "train loss:0.0008071198846363923\n",
      "train loss:0.00160135451640665\n",
      "train loss:2.4211127301578905e-05\n",
      "train loss:0.00045379636970809873\n",
      "train loss:0.00040743332907277046\n",
      "train loss:0.005833817495479208\n",
      "train loss:0.0043609498650431615\n",
      "train loss:0.002708296913924963\n",
      "train loss:0.0002812521092475486\n",
      "train loss:0.001242480851918742\n",
      "train loss:0.0013780981427219238\n",
      "train loss:0.0009305853283901462\n",
      "train loss:0.0003266284689333237\n",
      "train loss:0.0002489799966639342\n",
      "train loss:0.0020881856239419743\n",
      "train loss:0.0005127378633971319\n",
      "train loss:0.0022304053108025\n",
      "train loss:0.0006346126997166458\n",
      "train loss:0.0024034229777697234\n",
      "train loss:0.00012833305638610898\n",
      "train loss:0.0038163666687490295\n",
      "train loss:0.001094826023934737\n",
      "train loss:0.00395444368847299\n",
      "train loss:0.00019106914970093831\n",
      "train loss:0.000520881253854621\n",
      "train loss:0.0010261566104747073\n",
      "train loss:0.0027222972412935535\n",
      "train loss:0.0008673257931872584\n",
      "train loss:0.00013369526361653534\n",
      "train loss:0.00030050518663998966\n",
      "train loss:0.0014522590812930242\n",
      "train loss:0.002113683299599566\n",
      "train loss:0.0018805529632603393\n",
      "train loss:0.0004740471029221755\n",
      "train loss:0.0003498845364868407\n",
      "train loss:0.00022962209684136445\n",
      "train loss:9.053377877008708e-05\n",
      "train loss:0.005521901896719528\n",
      "train loss:0.00255305625128581\n",
      "train loss:0.0006955150190364498\n",
      "train loss:0.000900782391832884\n",
      "train loss:8.270967600292485e-05\n",
      "train loss:0.00013702159850276265\n",
      "train loss:0.0009692156919674074\n",
      "train loss:6.572923292913324e-05\n",
      "train loss:0.02670878197471014\n",
      "train loss:0.008733008290394402\n",
      "train loss:0.0024861276998528192\n",
      "train loss:0.0005325228696789057\n",
      "train loss:0.0004957584942839259\n",
      "train loss:0.0005330877134643089\n",
      "train loss:0.001019872390731153\n",
      "train loss:0.0026109971104419515\n",
      "train loss:0.0004102937704162175\n",
      "train loss:0.0013674015206992765\n",
      "train loss:0.00020176952019262045\n",
      "train loss:0.0002892959269838561\n",
      "train loss:0.00022300488987813953\n",
      "train loss:0.0010691215044053065\n",
      "train loss:0.0012419741125148916\n",
      "train loss:0.0012827196326004402\n",
      "train loss:0.0013417069974258227\n",
      "train loss:0.0001263513717690547\n",
      "train loss:0.0018982234358565567\n",
      "train loss:0.006000452051824299\n",
      "train loss:0.0002531551530113459\n",
      "train loss:0.003832900983764835\n",
      "train loss:0.000359153049708188\n",
      "train loss:0.0003173059692285992\n",
      "train loss:0.0010166628301586183\n",
      "train loss:3.554903007670841e-05\n",
      "train loss:0.00060379650993634\n",
      "train loss:0.00035903929025064884\n",
      "train loss:0.0007712745464395561\n",
      "train loss:0.002386683146731015\n",
      "train loss:0.0004925955640981794\n",
      "train loss:0.0006248808462358603\n",
      "train loss:2.2849128734103738e-05\n",
      "train loss:0.0017921606348428312\n",
      "train loss:0.002650026348027797\n",
      "train loss:4.6384031086952614e-05\n",
      "train loss:0.015034340854978618\n",
      "train loss:0.00033268914209349805\n",
      "train loss:8.787401941993635e-05\n",
      "train loss:0.0020948352864238557\n",
      "train loss:0.0006368888559071649\n",
      "train loss:0.0007222823598252037\n",
      "train loss:0.0024352892337106435\n",
      "train loss:0.00100573203295876\n",
      "train loss:0.0010617666419884863\n",
      "train loss:0.0007690829369204577\n",
      "train loss:0.0009067058518040356\n",
      "train loss:0.0012226030976349752\n",
      "train loss:0.010969731170918042\n",
      "train loss:0.0014136137361002005\n",
      "train loss:9.85887977936366e-05\n",
      "train loss:0.00023578464254780807\n",
      "train loss:0.0002477175875404482\n",
      "train loss:0.0008504959492407963\n",
      "train loss:0.00023867872019581396\n",
      "train loss:0.00015489175900771932\n",
      "train loss:0.00023037501646461486\n",
      "train loss:0.001293331235920435\n",
      "train loss:0.00017044920515610438\n",
      "train loss:0.0005522885106199677\n",
      "train loss:0.00794316898371562\n",
      "train loss:4.765594928417636e-05\n",
      "train loss:0.00041262972104589706\n",
      "train loss:0.0042355865126864735\n",
      "train loss:0.0006242595126084448\n",
      "train loss:0.002287266429810738\n",
      "train loss:0.006556232875060966\n",
      "train loss:0.00013798548922320562\n",
      "train loss:0.0008597692715182595\n",
      "train loss:0.00015369458983420948\n",
      "train loss:0.000376684927905994\n",
      "train loss:0.0005412871456263462\n",
      "train loss:0.007953122151410303\n",
      "train loss:0.0009854612752368415\n",
      "train loss:0.002608558081910899\n",
      "train loss:0.00020383952303256397\n",
      "train loss:0.0006914638286614881\n",
      "train loss:8.717924643332955e-05\n",
      "train loss:0.0006189413583745792\n",
      "train loss:0.002705244910384634\n",
      "train loss:0.002785622066560269\n",
      "train loss:0.0008940773753503289\n",
      "train loss:0.0005324676730830686\n",
      "train loss:0.0010359496747354344\n",
      "train loss:0.0010891774787334912\n",
      "train loss:0.0009101303394391171\n",
      "train loss:3.429458287840606e-05\n",
      "train loss:0.0010141073311219424\n",
      "train loss:0.00015149177063265656\n",
      "train loss:0.0008996179681852929\n",
      "train loss:0.00016373850513668256\n",
      "train loss:0.0003625444932791909\n",
      "train loss:0.0012233270248846583\n",
      "train loss:0.0011801943837724028\n",
      "train loss:0.00015195586246254743\n",
      "train loss:0.00030064019007919476\n",
      "train loss:0.0010753940369340868\n",
      "train loss:0.00046175987640812344\n",
      "train loss:0.0009778743598198038\n",
      "train loss:0.0011716881030390599\n",
      "train loss:0.0007454945816175917\n",
      "train loss:0.0001043416906739381\n",
      "train loss:0.0001644659623054965\n",
      "train loss:0.0006455673194058148\n",
      "train loss:0.00014717328624154686\n",
      "train loss:6.388658214861006e-05\n",
      "train loss:0.000455852741466628\n",
      "train loss:0.0009763889887724912\n",
      "train loss:0.0034697395504238704\n",
      "train loss:0.002846146575401563\n",
      "train loss:0.0005462835062541974\n",
      "train loss:7.078034844892433e-05\n",
      "train loss:0.0035765332028838124\n",
      "train loss:0.0001992945825187789\n",
      "train loss:0.000945555741803587\n",
      "train loss:0.00022734472215039003\n",
      "train loss:0.00019367202103522482\n",
      "train loss:0.0012917450929975688\n",
      "train loss:0.0004865371117809332\n",
      "train loss:0.00026865644313248495\n",
      "train loss:0.0028733752803077523\n",
      "train loss:0.0014048510824301837\n",
      "train loss:0.00046629262753676245\n",
      "train loss:0.000970035704413714\n",
      "train loss:0.0011839691307921503\n",
      "train loss:8.464408118257466e-05\n",
      "train loss:4.1326739755926685e-05\n",
      "train loss:0.0038251042279411752\n",
      "train loss:0.00016290590569052895\n",
      "train loss:0.00043299311791073213\n",
      "train loss:0.0005654621134464433\n",
      "train loss:0.0018847248935971348\n",
      "train loss:0.0033548664855253514\n",
      "train loss:0.0003067241756084374\n",
      "train loss:0.002507083652570081\n",
      "train loss:0.0039486771923075165\n",
      "train loss:0.002049989921543817\n",
      "train loss:9.570135278218015e-05\n",
      "train loss:0.00021562978057301777\n",
      "train loss:0.0015937165093258016\n",
      "train loss:0.0025949707974214542\n",
      "train loss:0.00018286475010972068\n",
      "train loss:0.0003695785778921298\n",
      "train loss:0.00011470360112810543\n",
      "train loss:0.0005609342375194195\n",
      "train loss:7.124236020602074e-05\n",
      "train loss:0.0011024945471054327\n",
      "train loss:0.0036602511553847717\n",
      "train loss:0.0004111124003533264\n",
      "train loss:0.00239880177338111\n",
      "train loss:0.0013941810959110167\n",
      "train loss:0.0018575207745662558\n",
      "train loss:0.0012119259392847337\n",
      "train loss:0.00047280794481203617\n",
      "train loss:0.0001310582159470658\n",
      "train loss:0.001968761308284476\n",
      "train loss:0.0011657362632013666\n",
      "train loss:3.2716116014591905e-05\n",
      "train loss:2.0063616689236844e-05\n",
      "train loss:0.002571320471096511\n",
      "train loss:0.0029193399744638932\n",
      "train loss:0.0003111817984791751\n",
      "train loss:0.00023084855242155606\n",
      "train loss:0.002573439461274841\n",
      "train loss:0.001427011629002948\n",
      "train loss:0.0029067456248235233\n",
      "train loss:0.0009203795066241914\n",
      "train loss:0.0024299475919008595\n",
      "train loss:0.00015416144142841283\n",
      "train loss:0.00031808241219452143\n",
      "train loss:0.022677428772764015\n",
      "train loss:0.00023387496463690146\n",
      "train loss:0.00047313495738454474\n",
      "train loss:2.509285976707931e-05\n",
      "train loss:0.0009442355448755521\n",
      "train loss:0.00019544492305093543\n",
      "train loss:0.00019752030844023266\n",
      "train loss:0.0005132968531861307\n",
      "train loss:0.0027139065427068255\n",
      "train loss:0.0023353818902614254\n",
      "train loss:0.0009981498705265409\n",
      "train loss:0.0002427778063799407\n",
      "train loss:0.0001530847206713924\n",
      "train loss:0.004177160413633949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006043185147195037\n",
      "train loss:0.0001768121516243479\n",
      "train loss:0.00017653289210944968\n",
      "train loss:0.0005695213688529339\n",
      "train loss:0.00015891385971375787\n",
      "train loss:0.002037704470378494\n",
      "train loss:0.00027729705806096356\n",
      "train loss:0.0028702894615018986\n",
      "train loss:0.002462088115044897\n",
      "train loss:0.00010076034948774562\n",
      "train loss:0.002974018990748546\n",
      "train loss:0.0002981140703358246\n",
      "train loss:0.0007638692695519356\n",
      "train loss:0.00187419150423887\n",
      "train loss:0.00032979023333719814\n",
      "train loss:0.003370388404923155\n",
      "train loss:0.0005540505027596228\n",
      "train loss:0.00013939266771920036\n",
      "train loss:0.00030926899923117227\n",
      "train loss:0.0007236455095121855\n",
      "train loss:0.00017710517089863546\n",
      "train loss:0.0008531427257263231\n",
      "train loss:0.00015713442116938197\n",
      "train loss:4.224042171773192e-05\n",
      "train loss:0.0026853421390050165\n",
      "train loss:0.0006241244216974268\n",
      "train loss:0.00302388149260944\n",
      "train loss:0.0010931164300462392\n",
      "train loss:0.00038718096604276677\n",
      "train loss:0.0012691140615266338\n",
      "train loss:0.0005132321689713964\n",
      "train loss:0.000627467391499575\n",
      "train loss:0.0003888490337098188\n",
      "train loss:0.00033291976838285375\n",
      "train loss:0.0003752519696151568\n",
      "train loss:0.0004206455539169822\n",
      "train loss:0.0001940809698207412\n",
      "train loss:0.00019271355876510895\n",
      "train loss:0.0015259420328305375\n",
      "train loss:0.0003380634649885078\n",
      "train loss:0.0015449093448120577\n",
      "train loss:0.0004639539321138317\n",
      "train loss:0.0021204877856028826\n",
      "train loss:0.0008791501267314656\n",
      "train loss:0.0014872970668281722\n",
      "train loss:0.0003993874585341209\n",
      "train loss:0.00023438346936939143\n",
      "train loss:0.0014277555227097376\n",
      "train loss:0.00022719572394938156\n",
      "train loss:4.313757176779405e-05\n",
      "train loss:0.0002001709484903804\n",
      "train loss:0.0002647801077741007\n",
      "train loss:0.0008780830813251256\n",
      "train loss:0.0003239147542606518\n",
      "train loss:6.205098806332916e-05\n",
      "train loss:0.0002141183787777386\n",
      "train loss:0.00017347144948408666\n",
      "train loss:0.00011875658057741617\n",
      "train loss:0.00015561280828720126\n",
      "train loss:0.00026825949658356276\n",
      "train loss:9.382241459543216e-05\n",
      "train loss:0.0005643017786881019\n",
      "train loss:0.00012563106316537058\n",
      "train loss:0.00129672521646608\n",
      "train loss:0.0004002402832429941\n",
      "train loss:0.0010219616604289284\n",
      "train loss:0.00023309502230700306\n",
      "train loss:0.001414603402129746\n",
      "train loss:0.00032564040563207587\n",
      "train loss:8.078234305395422e-05\n",
      "train loss:0.00014592222867815233\n",
      "train loss:0.000709207319871399\n",
      "train loss:9.795082432982018e-05\n",
      "train loss:0.0017979208827804442\n",
      "train loss:0.0008355776163918027\n",
      "train loss:4.866499567435612e-05\n",
      "train loss:0.0012177227740920364\n",
      "train loss:0.0003296265971172864\n",
      "train loss:0.00044941407463292633\n",
      "train loss:0.000980039538366065\n",
      "train loss:0.0003310282807041889\n",
      "train loss:0.0001971118074409194\n",
      "train loss:0.0008238244738181949\n",
      "train loss:0.0006922701277082706\n",
      "train loss:0.001018851534958546\n",
      "train loss:0.00022554605312732694\n",
      "train loss:0.000371227342543875\n",
      "train loss:0.0001577053707066036\n",
      "train loss:0.00045176600878680693\n",
      "train loss:0.0003050382319032955\n",
      "train loss:0.0003247957258448393\n",
      "train loss:0.0010501149277707402\n",
      "train loss:0.0014581894931009836\n",
      "train loss:0.001008946894511279\n",
      "train loss:0.00213251721539052\n",
      "train loss:0.0008177227887538216\n",
      "train loss:8.83021305423368e-05\n",
      "train loss:0.00042164654423586327\n",
      "train loss:0.0011046598678529785\n",
      "train loss:0.002191815335633348\n",
      "train loss:1.3037049131363034e-05\n",
      "train loss:6.618196685774165e-05\n",
      "train loss:0.0005222352415726132\n",
      "train loss:0.00020863027240794767\n",
      "train loss:3.790163284107338e-05\n",
      "train loss:0.00011761524814112382\n",
      "train loss:1.924109828093899e-05\n",
      "train loss:2.9068828507686743e-05\n",
      "train loss:0.0008429355124765955\n",
      "train loss:0.00011061264869952842\n",
      "train loss:1.0756609304849205e-05\n",
      "train loss:0.0005669010549034302\n",
      "train loss:0.00036576466849684493\n",
      "train loss:9.84711369988533e-05\n",
      "train loss:0.0009945824269015574\n",
      "train loss:0.0001469068714098847\n",
      "train loss:0.0005056253304861151\n",
      "train loss:0.0006132822622295635\n",
      "train loss:0.00013134549728921848\n",
      "train loss:0.0006704824522519798\n",
      "train loss:0.0028618569996228197\n",
      "train loss:0.0007179436239966721\n",
      "train loss:0.00015274211621659706\n",
      "=== epoch:20, train acc:0.999, test acc:0.987 ===\n",
      "train loss:0.00014367356796211547\n",
      "train loss:0.0003547383779218922\n",
      "train loss:0.0024254466748255387\n",
      "train loss:0.0005839360548964185\n",
      "train loss:0.0013762917150627718\n",
      "train loss:3.3031994081303184e-05\n",
      "train loss:0.0015054173610615606\n",
      "train loss:0.0001491843047716136\n",
      "train loss:0.0002524867265818879\n",
      "train loss:0.0012798729117759395\n",
      "train loss:0.0006386179545178482\n",
      "train loss:0.00033421176680385983\n",
      "train loss:0.0020917844050995175\n",
      "train loss:0.0003692648980737844\n",
      "train loss:5.63074992222265e-05\n",
      "train loss:0.00042166068634856053\n",
      "train loss:9.659118979718965e-05\n",
      "train loss:0.0030149330812570835\n",
      "train loss:0.00014645776270156375\n",
      "train loss:0.002086483008721227\n",
      "train loss:0.00041715985365942836\n",
      "train loss:0.0014988469476867354\n",
      "train loss:0.0006775109965966804\n",
      "train loss:0.0008642313105688306\n",
      "train loss:0.00010730532658123709\n",
      "train loss:0.0018848086065834423\n",
      "train loss:0.00045634607705697663\n",
      "train loss:0.0011020966513030776\n",
      "train loss:0.0007842370346403886\n",
      "train loss:0.00030778694749440173\n",
      "train loss:0.0041248068976910334\n",
      "train loss:0.002838933799411088\n",
      "train loss:0.002948464988232652\n",
      "train loss:0.0003469984082100761\n",
      "train loss:0.0010919527006360203\n",
      "train loss:0.0026039246503250135\n",
      "train loss:0.001392309590156345\n",
      "train loss:0.00026321156954705997\n",
      "train loss:0.0011100713869791265\n",
      "train loss:0.0006771719112155304\n",
      "train loss:3.1565068458273284e-05\n",
      "train loss:0.00011146668244496734\n",
      "train loss:4.983371715968057e-05\n",
      "train loss:0.002790457430815861\n",
      "train loss:0.0020118883583516173\n",
      "train loss:0.00040173877100147854\n",
      "train loss:0.0005208420146530628\n",
      "train loss:0.002639232032222546\n",
      "train loss:0.00019821914921875906\n",
      "train loss:0.003770164609211557\n",
      "train loss:0.00047866941284061026\n",
      "train loss:0.0017708264449188666\n",
      "train loss:0.0004829401475413485\n",
      "train loss:0.000218298757703988\n",
      "train loss:0.0002795175783735684\n",
      "train loss:0.000953761283755098\n",
      "train loss:0.0003115862133547253\n",
      "train loss:0.0007251906082955023\n",
      "train loss:0.0007396060766976395\n",
      "train loss:0.004310075759684741\n",
      "train loss:0.0002239579257386059\n",
      "train loss:0.0003051460612410607\n",
      "train loss:0.00015814677407792195\n",
      "train loss:0.0008400438466665645\n",
      "train loss:0.001266134585985571\n",
      "train loss:0.0008145130562154671\n",
      "train loss:0.0032691922362088014\n",
      "train loss:0.00019166917713728043\n",
      "train loss:0.01010152783348398\n",
      "train loss:0.0022289463713523576\n",
      "train loss:0.0018970353177289636\n",
      "train loss:0.0007299612222569897\n",
      "train loss:0.0003984683554806771\n",
      "train loss:0.0005679943067726143\n",
      "train loss:0.01420243478218615\n",
      "train loss:0.0014949727830398318\n",
      "train loss:0.0020533859905823974\n",
      "train loss:0.004863762625210825\n",
      "train loss:4.7070301095535875e-05\n",
      "train loss:0.007192051737018571\n",
      "train loss:0.0007400183403920954\n",
      "train loss:0.00029094645727198947\n",
      "train loss:0.0007368273730590229\n",
      "train loss:0.00030286223749903535\n",
      "train loss:0.000589221903784541\n",
      "train loss:0.001271714066714145\n",
      "train loss:6.70833889195476e-05\n",
      "train loss:0.0008660628532900534\n",
      "train loss:0.0007507859979276877\n",
      "train loss:0.0007256786418220544\n",
      "train loss:4.531703708640132e-05\n",
      "train loss:0.0010077471659026413\n",
      "train loss:4.5752955625443854e-05\n",
      "train loss:0.009072184534741639\n",
      "train loss:0.0006977566278009262\n",
      "train loss:0.00021680424868231283\n",
      "train loss:0.0023788991304490308\n",
      "train loss:0.0007539729216264824\n",
      "train loss:0.00010650044539506996\n",
      "train loss:0.0016609744791876403\n",
      "train loss:0.00011354858565253007\n",
      "train loss:0.00011147953511046146\n",
      "train loss:0.000708039864598447\n",
      "train loss:0.001620991433195197\n",
      "train loss:0.007384158648159461\n",
      "train loss:0.00010633566565469946\n",
      "train loss:0.0020855649663710663\n",
      "train loss:0.001336816954488943\n",
      "train loss:0.00047391807953444206\n",
      "train loss:0.002360655394385675\n",
      "train loss:0.001499240416439924\n",
      "train loss:7.839766266653474e-05\n",
      "train loss:0.0030357641994582353\n",
      "train loss:0.005689452730491117\n",
      "train loss:0.0012690928724469277\n",
      "train loss:0.00041037214079611445\n",
      "train loss:0.002390278493811358\n",
      "train loss:0.002368701127682655\n",
      "train loss:0.004643987642802384\n",
      "train loss:0.0015496210165825714\n",
      "train loss:0.0013947873508818353\n",
      "train loss:0.0022831378516998168\n",
      "train loss:0.000966306303438412\n",
      "train loss:0.0008516374281059318\n",
      "train loss:0.001422330239850466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016465196150519795\n",
      "train loss:0.00040933798432338806\n",
      "train loss:0.0014435307298622166\n",
      "train loss:0.0011775175436458086\n",
      "train loss:0.006325093282690001\n",
      "train loss:0.00037711006031798634\n",
      "train loss:0.00013274158338958991\n",
      "train loss:0.0002049303020232623\n",
      "train loss:0.0007945952968604851\n",
      "train loss:5.5901276479106135e-05\n",
      "train loss:0.0005321773955526569\n",
      "train loss:0.00015884249886572517\n",
      "train loss:8.241500318861638e-05\n",
      "train loss:0.005388883806632823\n",
      "train loss:0.0024035723343700595\n",
      "train loss:0.0003627362192023593\n",
      "train loss:0.042340195500663605\n",
      "train loss:0.0001597460513054359\n",
      "train loss:0.0008248279165405236\n",
      "train loss:0.0009425760916604347\n",
      "train loss:5.382323175895431e-05\n",
      "train loss:0.00023669527005906396\n",
      "train loss:0.0027275459769407233\n",
      "train loss:0.0009437122547242379\n",
      "train loss:0.003089476979960075\n",
      "train loss:0.0007671983828726812\n",
      "train loss:0.000927755648958373\n",
      "train loss:0.002359321482380366\n",
      "train loss:0.00040559443292901247\n",
      "train loss:0.008962378407681805\n",
      "train loss:0.0020293592372682555\n",
      "train loss:0.0014773657204395687\n",
      "train loss:0.0010068342989573214\n",
      "train loss:0.0005750234981750027\n",
      "train loss:0.0005160954738234447\n",
      "train loss:0.0029474453094783487\n",
      "train loss:0.0007375384410612562\n",
      "train loss:0.0010662051188820626\n",
      "train loss:0.0017587975005584104\n",
      "train loss:0.0014935236658861143\n",
      "train loss:0.0012164825222227005\n",
      "train loss:0.0004540551576255876\n",
      "train loss:0.001139091403109024\n",
      "train loss:0.0010368706301062888\n",
      "train loss:0.0030898772742352894\n",
      "train loss:0.0006758796109853845\n",
      "train loss:0.00034659402368072305\n",
      "train loss:0.0006691135129172729\n",
      "train loss:0.00012533982364861684\n",
      "train loss:0.0013105239209431681\n",
      "train loss:0.00046192123321718776\n",
      "train loss:0.00033690971193954403\n",
      "train loss:0.013945621822481553\n",
      "train loss:0.0001381089876323569\n",
      "train loss:0.0005713460723176353\n",
      "train loss:0.0019803304625369963\n",
      "train loss:0.0041127412044024035\n",
      "train loss:0.0014553174618201518\n",
      "train loss:0.0004435045039631351\n",
      "train loss:0.00042017495722879655\n",
      "train loss:0.0018315283097066442\n",
      "train loss:0.0009280998938187687\n",
      "train loss:0.0019024760494192688\n",
      "train loss:0.0016820273156064273\n",
      "train loss:0.0012150351173494892\n",
      "train loss:4.192023321260326e-05\n",
      "train loss:0.0001033670260296805\n",
      "train loss:0.0021317756085586234\n",
      "train loss:0.001084852661569845\n",
      "train loss:0.0024215082637061695\n",
      "train loss:0.011372764456766415\n",
      "train loss:8.797106229896696e-05\n",
      "train loss:0.0019527963196834786\n",
      "train loss:0.0017957626582521024\n",
      "train loss:4.710150433039363e-05\n",
      "train loss:0.00028503240671483873\n",
      "train loss:0.000956671155552933\n",
      "train loss:0.0005689956878040558\n",
      "train loss:0.00048433653457215215\n",
      "train loss:0.00034866121839745626\n",
      "train loss:0.0038035450600597803\n",
      "train loss:0.0025574404421972678\n",
      "train loss:0.0006707497170050247\n",
      "train loss:0.003187441281537994\n",
      "train loss:0.002807873149800969\n",
      "train loss:0.00029611654060226946\n",
      "train loss:0.0002796584442307826\n",
      "train loss:0.0019873157825030046\n",
      "train loss:0.006675205385590746\n",
      "train loss:0.00024670460187929823\n",
      "train loss:4.950816711265872e-05\n",
      "train loss:0.00011297939601790445\n",
      "train loss:0.0003284552612177216\n",
      "train loss:0.0002733450923427392\n",
      "train loss:0.0005386734593642288\n",
      "train loss:0.0029177176799127587\n",
      "train loss:0.0005566711351037459\n",
      "train loss:0.0014984507490136292\n",
      "train loss:1.043032687633085e-05\n",
      "train loss:0.0020874359787695796\n",
      "train loss:0.00018584012606295822\n",
      "train loss:7.393024047882543e-05\n",
      "train loss:0.0019416996730929627\n",
      "train loss:0.003029439885080978\n",
      "train loss:0.00035330080891115526\n",
      "train loss:5.612558645768279e-05\n",
      "train loss:0.0022134306156612886\n",
      "train loss:0.00022895893980603977\n",
      "train loss:0.000837701855048949\n",
      "train loss:0.0028944773340033613\n",
      "train loss:0.01660147705892534\n",
      "train loss:0.0012467153384942366\n",
      "train loss:0.0015664493092453391\n",
      "train loss:0.00015170117421644137\n",
      "train loss:8.033670287056593e-05\n",
      "train loss:0.00041134883309887506\n",
      "train loss:0.000574062359027766\n",
      "train loss:0.00024558301139307866\n",
      "train loss:0.0011058835474291931\n",
      "train loss:4.414208756626815e-05\n",
      "train loss:0.00040201159215863313\n",
      "train loss:0.0005171480528243737\n",
      "train loss:0.004428400846277483\n",
      "train loss:0.0005558975941488651\n",
      "train loss:0.005219117488240844\n",
      "train loss:0.0064418774658635295\n",
      "train loss:0.008418115054636324\n",
      "train loss:0.001546556343276414\n",
      "train loss:0.01310931070050819\n",
      "train loss:0.021558695303803763\n",
      "train loss:0.00012486830919331473\n",
      "train loss:0.00018567260167827676\n",
      "train loss:0.0002630163419405717\n",
      "train loss:0.0007995461090615374\n",
      "train loss:0.0006312573578412886\n",
      "train loss:0.001530209165040681\n",
      "train loss:0.0002653947478367752\n",
      "train loss:0.0018341294729342433\n",
      "train loss:0.0026841950496711542\n",
      "train loss:0.008090201444721857\n",
      "train loss:0.0021838742416875915\n",
      "train loss:0.000799594301134936\n",
      "train loss:0.0033629437625692115\n",
      "train loss:0.0029581209145573594\n",
      "train loss:0.002027431698372764\n",
      "train loss:0.0003884244393436955\n",
      "train loss:0.00015010909922184273\n",
      "train loss:0.001260980604783926\n",
      "train loss:0.00028388928231740275\n",
      "train loss:0.006394954870073166\n",
      "train loss:0.0008710863891049784\n",
      "train loss:0.0015668555708118423\n",
      "train loss:0.0008037317114145532\n",
      "train loss:0.002249333731797423\n",
      "train loss:0.0014583183444818824\n",
      "train loss:0.00041498096993052686\n",
      "train loss:0.0030200068431618576\n",
      "train loss:0.003700736947274388\n",
      "train loss:0.0032231962768673513\n",
      "train loss:0.0006217899343843414\n",
      "train loss:0.0013887157207009154\n",
      "train loss:0.0020816298031954973\n",
      "train loss:0.0005638127327638684\n",
      "train loss:0.0002155161371092007\n",
      "train loss:0.0010073915734620607\n",
      "train loss:0.0002518333607223037\n",
      "train loss:0.003401307322725185\n",
      "train loss:0.0021154614448211893\n",
      "train loss:0.0031386964424788954\n",
      "train loss:0.0008231149548229139\n",
      "train loss:0.001442784985824488\n",
      "train loss:0.0022704387272243494\n",
      "train loss:0.00020762822088895788\n",
      "train loss:0.002695155600876323\n",
      "train loss:0.00019817156716619457\n",
      "train loss:0.002193738471494207\n",
      "train loss:6.614465125981223e-05\n",
      "train loss:0.0002098580129756274\n",
      "train loss:0.00480385504633646\n",
      "train loss:0.001138520905917512\n",
      "train loss:0.004700826947209777\n",
      "train loss:0.0007224413805913776\n",
      "train loss:4.560678723291551e-05\n",
      "train loss:0.0005199907206285787\n",
      "train loss:0.00025069089525359947\n",
      "train loss:0.0022464188010615127\n",
      "train loss:0.007833914234694615\n",
      "train loss:0.0005227599271959258\n",
      "train loss:0.003871154410143498\n",
      "train loss:0.0019787150677713656\n",
      "train loss:0.00019954561833626237\n",
      "train loss:0.0032663969404749054\n",
      "train loss:0.0024890178749473447\n",
      "train loss:0.0009146633196892638\n",
      "train loss:0.0019321899680962836\n",
      "train loss:0.0015832086724422414\n",
      "train loss:0.00038715613366225443\n",
      "train loss:0.0008375044330628477\n",
      "train loss:0.0006103536232977752\n",
      "train loss:4.668886837195203e-05\n",
      "train loss:0.00946300554653232\n",
      "train loss:0.00015371069434969055\n",
      "train loss:0.009669153999198163\n",
      "train loss:6.879380493173028e-05\n",
      "train loss:0.00026033171077168466\n",
      "train loss:0.0007618336740251526\n",
      "train loss:0.0005290322868071783\n",
      "train loss:0.0011025026932733482\n",
      "train loss:0.0015552081853289477\n",
      "train loss:0.0006937865914003502\n",
      "train loss:0.0007939980043530494\n",
      "train loss:0.0016440906740200895\n",
      "train loss:0.002973468899300899\n",
      "train loss:0.00010674980355817218\n",
      "train loss:0.00019667929019518307\n",
      "train loss:0.0014828226035488448\n",
      "train loss:0.0006434760322489505\n",
      "train loss:0.003745234708848767\n",
      "train loss:0.003927379272398457\n",
      "train loss:0.00042879323508282057\n",
      "train loss:0.0001439977131711455\n",
      "train loss:0.0005336433221438714\n",
      "train loss:0.0009758701801310801\n",
      "train loss:0.0008742900246653046\n",
      "train loss:0.0003183240733968048\n",
      "train loss:0.0003287282890338532\n",
      "train loss:0.0006730392327354246\n",
      "train loss:0.009659818787845813\n",
      "train loss:0.0003725493598567961\n",
      "train loss:0.0005575920699216439\n",
      "train loss:0.0011353045693899657\n",
      "train loss:0.002953424652549635\n",
      "train loss:0.0002801507070936967\n",
      "train loss:0.0037363618483275698\n",
      "train loss:0.0014746363952722378\n",
      "train loss:0.0007431009863032334\n",
      "train loss:0.0005763609184718012\n",
      "train loss:0.0002714195683335526\n",
      "train loss:0.00029465151801545474\n",
      "train loss:0.01585516887246884\n",
      "train loss:0.0009910078218909107\n",
      "train loss:0.0003258560817447975\n",
      "train loss:0.0017981852712052855\n",
      "train loss:0.000583007370939106\n",
      "train loss:0.003898206577801871\n",
      "train loss:0.0030426623645156896\n",
      "train loss:2.785386551730393e-05\n",
      "train loss:0.04450195882837742\n",
      "train loss:0.0018369458235598932\n",
      "train loss:0.0036940373603408416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009745410997471981\n",
      "train loss:9.130273222520312e-05\n",
      "train loss:0.004228219284662351\n",
      "train loss:0.0010092428071093414\n",
      "train loss:0.00031760982181981023\n",
      "train loss:9.408583038137998e-05\n",
      "train loss:0.00040757794392523106\n",
      "train loss:0.0010181347145621603\n",
      "train loss:9.441810202720758e-05\n",
      "train loss:0.00022146653945544442\n",
      "train loss:0.0015446679742394495\n",
      "train loss:0.0031588645771096586\n",
      "train loss:0.0024888513857396753\n",
      "train loss:0.00013533921451420043\n",
      "train loss:0.0015218750119695395\n",
      "train loss:0.0023472668486588188\n",
      "train loss:0.0004944321219562166\n",
      "train loss:0.0009711154453489197\n",
      "train loss:0.0003045960130305833\n",
      "train loss:0.0009973574661541848\n",
      "train loss:0.0009650994068279107\n",
      "train loss:0.0004258462370533309\n",
      "train loss:0.00030513592518958147\n",
      "train loss:0.0008029477660267362\n",
      "train loss:7.662757925896139e-05\n",
      "train loss:0.0014794338181227853\n",
      "train loss:0.0042333436338244275\n",
      "train loss:0.0005289575349122387\n",
      "train loss:0.0006271200391312999\n",
      "train loss:0.0005290867443364645\n",
      "train loss:1.9601753359426482e-05\n",
      "train loss:0.002747141849285575\n",
      "train loss:0.002573839867490302\n",
      "train loss:0.0013689738861042671\n",
      "train loss:0.0027949864424730575\n",
      "train loss:0.0017584461903575963\n",
      "train loss:0.003308796934019874\n",
      "train loss:0.00011551259259186742\n",
      "train loss:0.0003100469015595863\n",
      "train loss:0.0005938722467612927\n",
      "train loss:0.00033967973265127104\n",
      "train loss:0.0023816290998961427\n",
      "train loss:0.0005282707802220153\n",
      "train loss:0.0004430777754361882\n",
      "train loss:0.0017440701403786945\n",
      "train loss:0.0012389060266224346\n",
      "train loss:0.00022471393240210168\n",
      "train loss:8.292837937506084e-05\n",
      "train loss:0.000948762535565469\n",
      "train loss:0.0021091995509691566\n",
      "train loss:0.0006805795911522145\n",
      "train loss:9.086045502279872e-05\n",
      "train loss:0.0020746483322090113\n",
      "train loss:0.0003527117860126724\n",
      "train loss:0.002674248873277062\n",
      "train loss:0.0016551240763716844\n",
      "train loss:0.0032941143177230028\n",
      "train loss:0.0007428675404120634\n",
      "train loss:0.0002624425122863495\n",
      "train loss:0.00043107692289340717\n",
      "train loss:0.0003433718642083553\n",
      "train loss:0.0015668029977891163\n",
      "train loss:0.001559008196098139\n",
      "train loss:0.00019982037797706417\n",
      "train loss:0.0007956562314284159\n",
      "train loss:0.0012718228593940725\n",
      "train loss:0.002589494269020329\n",
      "train loss:0.00032161448874901805\n",
      "train loss:0.0002861803157486842\n",
      "train loss:0.000234727343686307\n",
      "train loss:0.00015168454097227858\n",
      "train loss:0.0006118048754499315\n",
      "train loss:0.00014074336924609386\n",
      "train loss:8.725981869383538e-05\n",
      "train loss:0.00016813394828315168\n",
      "train loss:0.0003077251488454748\n",
      "train loss:0.000286617734828628\n",
      "train loss:2.442608493485238e-05\n",
      "train loss:0.00010463135965429377\n",
      "train loss:0.0017916707213966434\n",
      "train loss:0.007757131146259978\n",
      "train loss:0.00029540619731963173\n",
      "train loss:0.00012419060505655376\n",
      "train loss:0.0038042432575026825\n",
      "train loss:0.0003240880293034142\n",
      "train loss:0.002003914906675793\n",
      "train loss:0.0004704491869129685\n",
      "train loss:0.000752005314486556\n",
      "train loss:0.000424350538119951\n",
      "train loss:0.0037704370734165478\n",
      "train loss:0.0032159213084383322\n",
      "train loss:0.0038824872895426798\n",
      "train loss:0.0021916636402391563\n",
      "train loss:0.0028305872399082177\n",
      "train loss:0.0022535360521954363\n",
      "train loss:0.0006864409235730037\n",
      "train loss:0.00045789455598674935\n",
      "train loss:0.0005102263980747035\n",
      "train loss:0.0009546670794886203\n",
      "train loss:0.0016352107226237525\n",
      "train loss:0.002204646276007043\n",
      "train loss:0.00033486836420578667\n",
      "train loss:0.00025837865651493337\n",
      "train loss:0.002047900815023617\n",
      "train loss:0.0004432739733028669\n",
      "train loss:0.0018098638648000288\n",
      "train loss:0.0006176763319478406\n",
      "train loss:0.0021140418448201467\n",
      "train loss:0.0003605285261026521\n",
      "train loss:0.00023598586728467357\n",
      "train loss:0.0011804887460210114\n",
      "train loss:0.00013955247517570744\n",
      "train loss:0.0005858928123130037\n",
      "train loss:0.0013329007109951457\n",
      "train loss:0.00022443890336455694\n",
      "train loss:0.00015506900994401312\n",
      "train loss:0.0007807723100876115\n",
      "train loss:0.003017265015750445\n",
      "train loss:0.0005949870721551689\n",
      "train loss:0.0011906892743411793\n",
      "train loss:0.00011975274324226597\n",
      "train loss:0.000249815005012003\n",
      "train loss:0.0012433846942462292\n",
      "train loss:0.001455360760475882\n",
      "train loss:0.0006395174362941717\n",
      "train loss:0.0040351375759840515\n",
      "train loss:0.0010044160631312853\n",
      "train loss:0.0005682403087423733\n",
      "train loss:0.0006245450050123036\n",
      "train loss:0.0005978671661653928\n",
      "train loss:0.0003333900572581973\n",
      "train loss:6.11958051150051e-05\n",
      "train loss:0.0002132662245034689\n",
      "train loss:0.0008486785396824034\n",
      "train loss:0.0035603407930512314\n",
      "train loss:0.0014421307988606712\n",
      "train loss:0.00010488158174445473\n",
      "train loss:0.00619043787332355\n",
      "train loss:0.0006451869430787971\n",
      "train loss:0.001149496943110079\n",
      "train loss:0.00022440799269893665\n",
      "train loss:0.00014891287136057342\n",
      "train loss:0.0007743264195775887\n",
      "train loss:0.01179348824255928\n",
      "train loss:0.0011913732339709588\n",
      "train loss:0.00012969432183562786\n",
      "train loss:0.0008670025694472514\n",
      "train loss:0.00246863539927864\n",
      "train loss:0.00010778347574330529\n",
      "train loss:0.00020692792795031216\n",
      "train loss:0.006992080045009521\n",
      "train loss:0.00030772171016326056\n",
      "train loss:0.0011342237621457295\n",
      "train loss:0.00182292506999101\n",
      "train loss:0.0016838768815635816\n",
      "train loss:0.0015286830066726942\n",
      "train loss:0.000257509104458462\n",
      "train loss:0.002442696339987475\n",
      "train loss:0.0007118299186553217\n",
      "train loss:0.0005495108491608205\n",
      "train loss:0.002693137343426512\n",
      "train loss:0.0018303351871901668\n",
      "train loss:0.0004696543642112251\n",
      "train loss:0.0012285774260955725\n",
      "train loss:0.0001009685717387752\n",
      "train loss:0.0005460617962863779\n",
      "train loss:0.002473332894620939\n",
      "train loss:0.0007788329080914636\n",
      "train loss:0.00508668282456677\n",
      "train loss:0.0029859195946655044\n",
      "train loss:0.00020231873203849156\n",
      "train loss:0.012956298231251821\n",
      "train loss:0.0019815765239644604\n",
      "train loss:0.00021491890853544867\n",
      "train loss:0.0018167100082331423\n",
      "train loss:0.00015202123751469125\n",
      "train loss:0.0039783546437671055\n",
      "train loss:0.005866472188128465\n",
      "train loss:0.00040053904255971155\n",
      "train loss:0.00031371086030446626\n",
      "train loss:0.00037338152017990766\n",
      "train loss:0.002298492149206278\n",
      "train loss:0.0015834373774684452\n",
      "train loss:0.0026846579921147424\n",
      "train loss:0.001106725135602156\n",
      "train loss:0.0002937895514146286\n",
      "train loss:0.0023598774690553152\n",
      "train loss:0.0003683083262709374\n",
      "train loss:6.060838730075431e-05\n",
      "train loss:0.0006547807686654406\n",
      "train loss:0.00017894945722223994\n",
      "train loss:0.0010937087351711044\n",
      "train loss:0.0018183319160051112\n",
      "train loss:0.00030320850817505446\n",
      "train loss:0.00022463474113503735\n",
      "train loss:0.005763922513334221\n",
      "train loss:0.0006359139568001961\n",
      "train loss:0.0007106230621886411\n",
      "train loss:0.001070296331199947\n",
      "train loss:0.00020406332217924302\n",
      "train loss:0.00044643082982134753\n",
      "train loss:0.0005244304740074742\n",
      "train loss:0.0009546874315393862\n",
      "train loss:0.000986215431364606\n",
      "train loss:0.002169909946625099\n",
      "train loss:0.001764168228037843\n",
      "train loss:0.002167933010191965\n",
      "train loss:0.00039085496907658997\n",
      "train loss:0.0008667769554993658\n",
      "train loss:0.0006210398243784716\n",
      "train loss:0.0030793075252671777\n",
      "train loss:0.0017819639679630076\n",
      "train loss:3.634128151959873e-05\n",
      "train loss:0.0007065311889549783\n",
      "train loss:0.0009637854760058093\n",
      "train loss:0.0008961576962181259\n",
      "train loss:0.00014992205042901543\n",
      "train loss:0.0002930922704017229\n",
      "train loss:0.00014167416802174642\n",
      "train loss:0.0012915549270381015\n",
      "train loss:0.002069846029579008\n",
      "train loss:0.0017995777932696205\n",
      "train loss:0.0015877339678103777\n",
      "train loss:0.0008369118130120073\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9889\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e00526b",
   "metadata": {},
   "source": [
    "### CNN 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138eecd1",
   "metadata": {},
   "source": [
    "### 1번째 층의 가중치 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edfe219",
   "metadata": {},
   "source": [
    "학습 전과 후의 가중치 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "feb46d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 학습 전 >\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 학습 후 >\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "print('< 학습 전 >')\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "print('< 학습 후 >')\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f6907",
   "metadata": {},
   "source": [
    "- 학습 전 필터는 무작위로 초기화되어 흑백의 정도에 규칙성이 없음  \n",
    "- 한편, 학습을 마친 필터는 규칙성이 있음  \n",
    "    흰색에서 검은색으로 점차 변화하는 필터와 덩어리(블롭 blob)가 진 필터 등, 규칙을 띄는 필터로 바뀜  \n",
    "    규칙성이 있는 필터는 에지(색상이 바뀐 경계선)나 블롭(국소적으로 덩어리진 영역) 등의 원시적인 정보를 추출할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dca67",
   "metadata": {},
   "source": [
    "### 층 깊이에 따른 추출 정보 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5538ca",
   "metadata": {},
   "source": [
    "합성곱 계층을 여러 겹 쌓으면,  \n",
    "층이 깊어지면서 더 복잡하고 추상화된 정보가 추출됨  \n",
    "  \n",
    "처음 층은 단순한 에지에 반응하고, 이어서 텍스처에 반응하고, 더 복잡한 사물의 일부에 반응하도록 변화  \n",
    "즉, 층이 깊어지면서 뉴런이 반응하는 대상이 단순한 모양에서 '고급'정보로 변화함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77949e9",
   "metadata": {},
   "source": [
    "### 대표적인 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d2ed7",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790ada5",
   "metadata": {},
   "source": [
    "<img src='./img/LeNet_1.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b26ca3",
   "metadata": {},
   "source": [
    "LeNet은 손글시 숫자를 인식하는 네트워크로, 1988년에 제안됨  \n",
    "합성곱 계층과 풀링 계층(정확히는 단순히 '원소를 줄이기'만 하는 서브샘플링 계층)을 반복하고, 마지막으로 완전연결 계층을 거치면서 결과를 출력  \n",
    "  \n",
    "LeNet은 시그모이드 함수를 사용(현재는 주로 ReLU를 사용)  \n",
    "LeNet은 서브샘플링을 하여 중간 데이터의 크기를 줄임(현재는 최대 풀링이 주류)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1bed98",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c17bdf",
   "metadata": {},
   "source": [
    "<img src='./img/AlexNet_1.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11408a",
   "metadata": {},
   "source": [
    "AlexNet은 2012년에 발표  \n",
    "합성곱 계층과 풀링 계층을 거듭하며 마지막으로 완전연결 계층을 거쳐 결과를 출력  \n",
    "  \n",
    "활성화 함수로 ReLU를 이용  \n",
    "LRN(Local Response Normalization)이라는 국소적 정규화를 실시하는 계층을 이용  \n",
    "드롭아웃 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda54a8",
   "metadata": {},
   "source": [
    "참고 : https://compmath.korea.ac.kr/appmath2021/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
